---  
layout: post   
title: Stock Research || 2.1 주가 데이터셋 보조지표 추가
image: 03.thumbnail.png  
tags:  
categories: stock-research
---

# 2. Data Preprocessing  
## 2.1. 주가 데이터셋 보조지표  추가  

이전 글 [[Stock Research] 1.2. 머신러닝 모델 비교](https://ag-su.github.io/myblog/2022/07/06/model-selection/)까지 주가 데이터셋 생성과 머신러닝 모델 비교를 통해 baseline model을 생성했다. 
이번 글 부터는 데이터 전처리를 진행한다. 모델을 이전 글에서 선택했던 baseline 모델로 fix의 질을 높임으로써 성능을 향상시킨다. 그 첫번째로 주가데이터셋에 보조지표를 추가하여 설명변수의 크기를 늘린다.




### 목차 
- (1) 주식 데이터의 보조지표
- (2) 보조지표 추가   
- (3) 모델 학습 


```python
import pandas as pd
import numpy as np
from tqdm import tqdm
import FinanceDataReader as fdr
import pymysql

import warnings
warnings.filterwarnings('ignore')
    
import ta

from ipywidgets import interact, interact_manual
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.graph_objects as go
import plotly.offline as pyo
%matplotlib inline
%pylab inline
pylab.rcParams['figure.figsize'] = (12,5)
```

    %pylab is deprecated, use %matplotlib inline and import the required libraries.
    Populating the interactive namespace from numpy and matplotlib


## (1) 주식데이터의 보조지표 
주식데이터에서 보조지표란 기술적지표라고도 불리며, 다양한 각도와 계산식, 통계 등을 바탕으로 기본적 분석 방법들과 조합하여 보다 폭 넓은 시장 예측을 가능하게 도와주는 차트 분석 도구이다. 

[참고]  
-[01 보조지표란?](https://www.nanumtrading.com/fx-%eb%b0%b0%ec%9a%b0%ea%b8%b0/%ec%b0%a8%ed%8a%b8-%eb%b3%b4%ec%a1%b0%ec%a7%80%ed%91%9c-%ec%9d%b4%ed%95%b4/01-%eb%b3%b4%ec%a1%b0%ec%a7%80%ed%91%9c%eb%9e%80/)

주식 시장에서 많이 알려져 있고, 주가 예측에 자주 사용되는 보조지표로는 이동평균선을 예로들 수 있다. 이동평균선을 캔들차트와 함께 시각화 하고, 각 종목과 날짜에 대해 어떻게 나타나는지 직접 확인해본다. 

- **데이터 불러오기**  
시간 단축을 위해 `2018-01-01 ~ 2020-12-31` 기간 동안의 모든 데이터를 미리 저장해 놓은 주가 데이터셋을 불러 온다. 


```python
df_stock = pd.read_csv("stock_data_2018_2020.csv")
df_stock['Code'] = df_stock['Code'].apply(lambda x : str(x).zfill(6))
df_stock
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Code</th>
      <th>Date</th>
      <th>Open</th>
      <th>High</th>
      <th>Low</th>
      <th>Close</th>
      <th>Volume</th>
      <th>Change</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>050120</td>
      <td>2018-01-02</td>
      <td>10250</td>
      <td>12050</td>
      <td>10150</td>
      <td>11800</td>
      <td>26086769</td>
      <td>0.145631</td>
    </tr>
    <tr>
      <th>1</th>
      <td>050120</td>
      <td>2018-01-03</td>
      <td>11950</td>
      <td>12450</td>
      <td>10900</td>
      <td>11750</td>
      <td>20460474</td>
      <td>-0.004237</td>
    </tr>
    <tr>
      <th>2</th>
      <td>050120</td>
      <td>2018-01-04</td>
      <td>11850</td>
      <td>14150</td>
      <td>11600</td>
      <td>12600</td>
      <td>60663854</td>
      <td>0.072340</td>
    </tr>
    <tr>
      <th>3</th>
      <td>050120</td>
      <td>2018-01-05</td>
      <td>12800</td>
      <td>13200</td>
      <td>12000</td>
      <td>12200</td>
      <td>13935258</td>
      <td>-0.031746</td>
    </tr>
    <tr>
      <th>4</th>
      <td>050120</td>
      <td>2018-01-08</td>
      <td>12450</td>
      <td>13400</td>
      <td>12350</td>
      <td>12850</td>
      <td>16471707</td>
      <td>0.053279</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>1152013</th>
      <td>000540</td>
      <td>2020-12-23</td>
      <td>2880</td>
      <td>2945</td>
      <td>2835</td>
      <td>2870</td>
      <td>87318</td>
      <td>-0.010345</td>
    </tr>
    <tr>
      <th>1152014</th>
      <td>000540</td>
      <td>2020-12-24</td>
      <td>2850</td>
      <td>2875</td>
      <td>2845</td>
      <td>2860</td>
      <td>28350</td>
      <td>-0.003484</td>
    </tr>
    <tr>
      <th>1152015</th>
      <td>000540</td>
      <td>2020-12-28</td>
      <td>2860</td>
      <td>3000</td>
      <td>2805</td>
      <td>2820</td>
      <td>66036</td>
      <td>-0.013986</td>
    </tr>
    <tr>
      <th>1152016</th>
      <td>000540</td>
      <td>2020-12-29</td>
      <td>2820</td>
      <td>2920</td>
      <td>2705</td>
      <td>2775</td>
      <td>83187</td>
      <td>-0.015957</td>
    </tr>
    <tr>
      <th>1152017</th>
      <td>000540</td>
      <td>2020-12-30</td>
      <td>2835</td>
      <td>2835</td>
      <td>2755</td>
      <td>2830</td>
      <td>33270</td>
      <td>0.019820</td>
    </tr>
  </tbody>
</table>
<p>1152018 rows × 8 columns</p>
</div>



- **이동평균선 캔들차트 시각화**  


```python
IF = open('../data/code_list.txt')
lst_code = IF.readlines()

for idx, code in enumerate(lst_code):
    lst_code[idx] = code.strip()
```


```python
@interact
def show_label_dist(code = lst_code):
    df = df_stock[df_stock['Code']==code]    
    ma_ls = [5, 20, 60, 120]
    for i in range(len(ma_ls)):
        sr1 = df['Close'].rolling(window=ma_ls[i]).mean()
        df['MA'+str(ma_ls[i])] = sr1
    df = df.dropna(axis=0)
    
    # 캔들 차트 
    candle = go.Candlestick(x=df['Date'],
                open=df['Open'],
                high=df['High'],
                low=df['Low'],
                close=df['Close'], increasing_line_color= 'red', decreasing_line_color= 'blue')
    
    # 이동평균선
    line_ma5 = go.Scatter(x=df['Date'], y=df['MA5'], mode='lines', name='MA5', line=dict(color='magenta', width=0.5))
    line_ma20 = go.Scatter(x=df['Date'], y=df['MA20'], mode='lines', name='MA20', line=dict(color='blue', width=0.5))
    line_ma60 = go.Scatter(x=df['Date'], y=df['MA60'], mode='lines', name='MA60', line=dict(color='green', width=0.5))
    line_ma120 = go.Scatter(x=df['Date'], y=df['MA120'], mode='lines', name='MA120', line=dict(color='red', width=0.5))
    
    # 제목 추가
    layout = go.Layout(title='{} 캔들차트'.format(code), titlefont=dict(size=20, color='black'))
    
    fig = go.Figure(data=[candle, line_ma5, line_ma20, line_ma60, line_ma120], layout=layout)
    
    fig.show()
```


    interactive(children=(Dropdown(description='code', options=('050120', '095340', '067290', '024120', '060720', …


위의 캔들차트에서 원하는 코드를 선택하여 4일, 20일, 60일, 120일 이동평균선을 확인할 수 있다. 

## (2) 보조지표 추가

현재 baseline 모델에서는 10일치의 시가, 고가, 저가, 종가, 거래대금을 독립변수로 하여 학습을 진행했다. 

![image.png]({{site.baseurl}}/images/03.add_index_1.png)출처-네이버 증권

하지만 10일간의 주가 차트 예시 사진을 보면, 너무 적은 정보만을 담고 있어 주가 예측을 위한 패턴을 찾아내기란 매우 어렵다. 따라서 주식의 여러 보조지표를 사용해서 해당 주식에 대한 압축된 정보를 독립변수에 추가해준다. 


앞서 시각화 해보았던 이동평균선 말고도 다양한 주식 보조지표들이 존재한다. 보조지표들을 모두 수동으로 계산하기에는 어려움이 있으므로 TA 라이브러리를 사용하여 총 49개의 보조지표를 추가한다. (+ trading_value) 

-[TA library github](https://github.com/mrjbq7/ta-lib)

- 보조지표 추가 코드 


```python
df_index = pd.DataFrame()
for code, stock_df in tqdm(df_stock.groupby('Code')):
    
    # 이평선 생성
    ma = [5,20,60,120]
    for days in ma:
        stock_df['ma_'+str(days)] = stock_df['Close'].rolling(window = days).mean()
    
    # 여러 보조 지표 생성
    H, L, C, V = stock_df['High'], stock_df['Low'], stock_df['Close'], stock_df['Volume']
    
    stock_df['trading_value'] = stock_df['Close']*stock_df['Volume']
    
    stock_df['MFI'] = ta.volume.money_flow_index(
        high=H, low=L, close=C, volume=V, fillna=True)
    
    stock_df['ADI'] = ta.volume.acc_dist_index(
        high=H, low=L, close=C, volume=V, fillna=True)
    
    stock_df['OBV'] = ta.volume.on_balance_volume(close=C, volume=V, fillna=True)
    stock_df['CMF'] = ta.volume.chaikin_money_flow(
        high=H, low=L, close=C, volume=V, fillna=True)
    
    stock_df['FI'] = ta.volume.force_index(close=C, volume=V, fillna=True)
    stock_df['EOMEMV'] = ta.volume.ease_of_movement(
        high=H, low=L, volume=V, fillna=True)
    
    stock_df['VPT'] = ta.volume.volume_price_trend(close=C, volume=V, fillna=True)
    stock_df['NVI'] = ta.volume.negative_volume_index(close=C, volume=V, fillna=True)
    stock_df['VMAP'] = ta.volume.volume_weighted_average_price(
        high=H, low=L, close=C, volume=V, fillna=True)
    
    # Volatility
    stock_df['ATR'] = ta.volatility.average_true_range(
        high=H, low=L, close=C, fillna=True)
    stock_df['BHB'] = ta.volatility.bollinger_hband(close=C, fillna=True)
    stock_df['BLB'] = ta.volatility.bollinger_lband(close=C, fillna=True)
    stock_df['KCH'] = ta.volatility.keltner_channel_hband(
        high=H, low=L, close=C, fillna=True)
    stock_df['KCL'] = ta.volatility.keltner_channel_lband(
        high=H, low=L, close=C, fillna=True)
    stock_df['KCM'] = ta.volatility.keltner_channel_mband(
        high=H, low=L, close=C, fillna=True)
    stock_df['DCH'] = ta.volatility.donchian_channel_hband(
        high=H, low=L, close=C, fillna=True)
    stock_df['DCL'] = ta.volatility.donchian_channel_lband(
        high=H, low=L, close=C, fillna=True)
    stock_df['DCM'] = ta.volatility.donchian_channel_mband(
        high=H, low=L, close=C, fillna=True)
    stock_df['UI'] = ta.volatility.ulcer_index(close=C, fillna=True)
    # Trend
    stock_df['SMA'] = ta.trend.sma_indicator(close=C, fillna=True)
    stock_df['EMA'] = ta.trend.ema_indicator(close=C, fillna=True)
    stock_df['WMA'] = ta.trend.wma_indicator(close=C, fillna=True)
    stock_df['MACD'] = ta.trend.macd(close=C, fillna=True)
    stock_df['ADX'] = ta.trend.adx(high=H, low=L, close=C, fillna=True)
    stock_df['VIneg'] = ta.trend.vortex_indicator_neg(
        high=H, low=L, close=C, fillna=True)
    stock_df['VIpos'] = ta.trend.vortex_indicator_pos(
        high=H, low=L, close=C, fillna=True)
    stock_df['TRIX'] = ta.trend.trix(close=C, fillna=True)
    stock_df['MI'] = ta.trend.mass_index(high=H, low=L, fillna=True)
    stock_df['CCI'] = ta.trend.cci(high=H, low=L, close=C, fillna=True)
    stock_df['DPO'] = ta.trend.dpo(close=C, fillna=True)
    stock_df['KST'] = ta.trend.kst(close=C, fillna=True)
    stock_df['Ichimoku'] = ta.trend.ichimoku_a(high=H, low=L, fillna=True)
    stock_df['ParabolicSAR'] = ta.trend.psar_down(
        high=H, low=L, close=C, fillna=True)
    stock_df['STC'] = ta.trend.stc(close=C, fillna=True)
    # Momentum
    stock_df['RSI'] = ta.momentum.rsi(close=C, fillna=True)
    stock_df['SRSI'] = ta.momentum.stochrsi(close=C, fillna=True)
    stock_df['TSI'] = ta.momentum.tsi(close=C, fillna=True)
    stock_df['UO'] = ta.momentum.ultimate_oscillator(
        high=H, low=L, close=C, fillna=True)
    stock_df['SR'] = ta.momentum.stoch(close=C, high=H, low=L, fillna=True)
    stock_df['WR'] = ta.momentum.williams_r(high=H, low=L, close=C, fillna=True)
    stock_df['AO'] = ta.momentum.awesome_oscillator(high=H, low=L, fillna=True)
    stock_df['KAMA'] = ta.momentum.kama(close=C, fillna=True)
    stock_df['ROC'] = ta.momentum.roc(close=C, fillna=True)
    stock_df['PPO'] = ta.momentum.ppo(close=C, fillna=True)
    stock_df['PVO'] = ta.momentum.pvo(volume=V, fillna=True)
    
    df_index = df_index.append(stock_df) 

# 저장
df_index.to_csv("stock_data_2018_2020_add_index.csv", index=False)
df_index
```

    100%|██████████████████████████████████████████| 1561/1561 [07:35<00:00,  3.42it/s]





<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Code</th>
      <th>Date</th>
      <th>Open</th>
      <th>High</th>
      <th>Low</th>
      <th>Close</th>
      <th>Volume</th>
      <th>Change</th>
      <th>ma_5</th>
      <th>ma_20</th>
      <th>...</th>
      <th>SRSI</th>
      <th>TSI</th>
      <th>UO</th>
      <th>SR</th>
      <th>WR</th>
      <th>AO</th>
      <th>KAMA</th>
      <th>ROC</th>
      <th>PPO</th>
      <th>PVO</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>862985</th>
      <td>000020</td>
      <td>2018-01-02</td>
      <td>9750</td>
      <td>9900</td>
      <td>9700</td>
      <td>9870</td>
      <td>120676</td>
      <td>0.012308</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>...</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>85.000000</td>
      <td>-15.000000</td>
      <td>0.000000</td>
      <td>9870.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>862986</th>
      <td>000020</td>
      <td>2018-01-03</td>
      <td>9900</td>
      <td>10250</td>
      <td>9820</td>
      <td>10000</td>
      <td>268220</td>
      <td>0.013171</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>...</td>
      <td>0.000000</td>
      <td>100.000000</td>
      <td>28.571429</td>
      <td>54.545455</td>
      <td>-45.454545</td>
      <td>0.000000</td>
      <td>9925.471999</td>
      <td>0.000000</td>
      <td>0.104967</td>
      <td>8.943334</td>
    </tr>
    <tr>
      <th>862987</th>
      <td>000020</td>
      <td>2018-01-04</td>
      <td>10050</td>
      <td>10050</td>
      <td>9680</td>
      <td>9750</td>
      <td>161342</td>
      <td>-0.025000</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>...</td>
      <td>0.000000</td>
      <td>95.815900</td>
      <td>25.000000</td>
      <td>12.280702</td>
      <td>-87.719298</td>
      <td>0.000000</td>
      <td>9854.744908</td>
      <td>0.000000</td>
      <td>-0.015865</td>
      <td>9.215678</td>
    </tr>
    <tr>
      <th>862988</th>
      <td>000020</td>
      <td>2018-01-05</td>
      <td>9750</td>
      <td>9980</td>
      <td>9750</td>
      <td>9910</td>
      <td>116604</td>
      <td>0.016410</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>...</td>
      <td>0.000000</td>
      <td>92.627651</td>
      <td>33.333333</td>
      <td>40.350877</td>
      <td>-59.649123</td>
      <td>0.000000</td>
      <td>9882.663078</td>
      <td>0.000000</td>
      <td>0.018877</td>
      <td>6.837356</td>
    </tr>
    <tr>
      <th>862989</th>
      <td>000020</td>
      <td>2018-01-08</td>
      <td>10000</td>
      <td>10150</td>
      <td>9940</td>
      <td>9950</td>
      <td>158326</td>
      <td>0.004036</td>
      <td>9896.0</td>
      <td>NaN</td>
      <td>...</td>
      <td>0.000000</td>
      <td>90.156386</td>
      <td>30.612245</td>
      <td>47.368421</td>
      <td>-52.631579</td>
      <td>0.000000</td>
      <td>9935.876263</td>
      <td>0.000000</td>
      <td>0.078152</td>
      <td>7.233628</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>43418</th>
      <td>950130</td>
      <td>2020-12-22</td>
      <td>23950</td>
      <td>23950</td>
      <td>22800</td>
      <td>22900</td>
      <td>978011</td>
      <td>-0.043841</td>
      <td>23490.0</td>
      <td>22212.5</td>
      <td>...</td>
      <td>0.601825</td>
      <td>-1.890990</td>
      <td>29.641945</td>
      <td>41.379310</td>
      <td>-58.620690</td>
      <td>577.058824</td>
      <td>22725.390944</td>
      <td>17.737789</td>
      <td>-0.505568</td>
      <td>-12.450728</td>
    </tr>
    <tr>
      <th>43419</th>
      <td>950130</td>
      <td>2020-12-23</td>
      <td>23000</td>
      <td>23300</td>
      <td>21000</td>
      <td>21450</td>
      <td>1239228</td>
      <td>-0.063319</td>
      <td>23080.0</td>
      <td>22310.0</td>
      <td>...</td>
      <td>0.353271</td>
      <td>-3.660151</td>
      <td>28.338277</td>
      <td>23.963134</td>
      <td>-76.036866</td>
      <td>353.382353</td>
      <td>22679.784965</td>
      <td>-15.049505</td>
      <td>-1.064724</td>
      <td>-16.358507</td>
    </tr>
    <tr>
      <th>43420</th>
      <td>950130</td>
      <td>2020-12-24</td>
      <td>21500</td>
      <td>21800</td>
      <td>19600</td>
      <td>21700</td>
      <td>857865</td>
      <td>0.011655</td>
      <td>22700.0</td>
      <td>22382.5</td>
      <td>...</td>
      <td>0.083197</td>
      <td>-4.812902</td>
      <td>38.852203</td>
      <td>20.792079</td>
      <td>-79.207921</td>
      <td>-58.235294</td>
      <td>22583.248771</td>
      <td>-12.323232</td>
      <td>-1.408773</td>
      <td>-20.829146</td>
    </tr>
    <tr>
      <th>43421</th>
      <td>950130</td>
      <td>2020-12-28</td>
      <td>21750</td>
      <td>21800</td>
      <td>19500</td>
      <td>19650</td>
      <td>1523257</td>
      <td>-0.094470</td>
      <td>21930.0</td>
      <td>22322.5</td>
      <td>...</td>
      <td>0.000000</td>
      <td>-7.972071</td>
      <td>33.462925</td>
      <td>1.470588</td>
      <td>-98.529412</td>
      <td>-402.647059</td>
      <td>22055.737842</td>
      <td>-13.245033</td>
      <td>-2.394064</td>
      <td>-22.448964</td>
    </tr>
    <tr>
      <th>43422</th>
      <td>950130</td>
      <td>2020-12-29</td>
      <td>19950</td>
      <td>22450</td>
      <td>19900</td>
      <td>21500</td>
      <td>1568505</td>
      <td>0.094148</td>
      <td>21440.0</td>
      <td>22392.5</td>
      <td>...</td>
      <td>0.526558</td>
      <td>-8.199398</td>
      <td>40.132825</td>
      <td>28.169014</td>
      <td>-71.830986</td>
      <td>-759.852941</td>
      <td>22026.178902</td>
      <td>-9.473684</td>
      <td>-2.489633</td>
      <td>-23.522675</td>
    </tr>
  </tbody>
</table>
<p>1149377 rows × 58 columns</p>
</div>



보조지표를 추가하여 8개였던 컬럼이 58개의 컬럼이 된 것을 볼 수 있다. 

## (3) 모델 학습

- **데이터셋 생성 함수** 

시간 단축을 위해, 위에서 보조지표를 추가 했던 방법과 동일하게 미리 생성해 놓은 보조지표 추가 데이터셋을 서버 DB에서 불러온다.  baseline 모델에서 진행했던 데이터셋을 더 늘려 train 2017-2020, test 2021 기간 동안의 데이터를 사용한다. 


```python
def make_dataset(train=True):
    
    IF = open('../data/code_list.txt')
    lst_code = IF.readlines()

    lst_X = []
    lst_Y = []
    lst_code_date = []
    
    db_dsml = pymysql.connect(
        host = 'localhost', 
        port = 3306, 
        user = '[db username]', 
        passwd = '[db password]', 
        db = '[db name]', 
        charset = 'utf8'
    )
    cursor = db_dsml.cursor()
    
    
    for code in tqdm(lst_code): 
        code = code.strip()
        
        if train: 
            sql_query = '''
                        SELECT *
                        FROM stock_{}
                        WHERE Date BETWEEN '2017-01-01' AND '2020-12-31'
                        '''.format(code)
        else:
            sql_query = '''
                        SELECT *
                        FROM stock_{}
                        WHERE Date BETWEEN '2021-01-01' AND '2021-12-31'
                        '''.format(code)
        
        stock = pd.read_sql(sql = sql_query, con = db_dsml)   

        lst_stock = stock.values.tolist()


        for idx, row in enumerate(lst_stock): 
            date, trading_value = row[0].date().strftime("%Y%m%d"), row[4]*row[5]
            if trading_value >= 100000000000:
                if (idx < 9) or (idx >= len(lst_stock)-1): # 예외 처리 
                    continue 
                
                # D-9 ~ D0 데이터만 담기 
                sub_stock = lst_stock[idx-9:idx+1] 

                # 10일간의 데이터 
                lst_result = []
                for row2 in sub_stock:
                    lst_prices, lst_index = row2[1:6], row2[8:]
                    lst_result += lst_prices + lst_index + [trading_value]

                # D+1 종가 2% 상승 여부 
                label = int(row[7] >= 0.02)
                
                # 종속변수, 독립변수, 종목코드, 날짜 리스트에 추가 
                lst_X.append(lst_result)
                lst_Y.append(label)
                lst_code_date.append([code, date])
            
    return np.array(lst_X), np.array(lst_Y), np.array(lst_code_date)
```

- **train dataset 생성** 


```python
trainX, trainY, lst_code_date = make_dataset(train=True)
```

    100%|██████████████████████████████████████████| 1561/1561 [02:16<00:00, 11.44it/s]


- **test dataset 생성** 


```python
testX, testY, lst_code_date_test = make_dataset(train=False)
```

    100%|██████████████████████████████████████████| 1561/1561 [00:40<00:00, 38.37it/s]


pickle 저장 


```python
#collapse-hide
import pickle

dic_result = {
    'train': [trainX, trainY, lst_code_date],
    'test': [testX, testY, lst_code_date_test]
}

with open('dataset_2020_2021.pickle', 'wb') as handle:
    pickle.dump(dic_result, handle, protocol=pickle.HIGHEST_PROTOCOL)
```

pickle 불러오기 


```python
#collapse-hide
with open('dataset_2020_2021.pickle', 'rb') as handle:
    dataset = pickle.load(handle)
```


```python
trainX, trainY, lst_code_date = dataset['train'][0], dataset['train'][1], dataset['train'][2]
testX, testY, lst_code_date_test = dataset['test'][0], dataset['test'][1], dataset['test'][2]

print('train dataset: ', trainX.shape, trainY.shape)
print('test dataset: ', testX.shape, testY.shape)
```

    train dataset:  (13870, 550) (13870,)
    test dataset:  (8341, 550) (8341,)


- **XGBoost 모델 학습**


```python
from xgboost import XGBClassifier
xgb = XGBClassifier(
                   n_jobs=40,
                   scale_pos_weight=4,
                   learning_rate=0.01,
                   max_depth=3,
                   n_estimators=500,
                   ) 

xgb.fit(trainX, trainY)
```

    [17:26:28] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.





    XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,
                  colsample_bynode=1, colsample_bytree=1, enable_categorical=False,
                  gamma=0, gpu_id=-1, importance_type=None,
                  interaction_constraints='', learning_rate=0.01, max_delta_step=0,
                  max_depth=3, min_child_weight=1, missing=nan,
                  monotone_constraints='()', n_estimators=500, n_jobs=40,
                  num_parallel_tree=1, predictor='auto', random_state=0,
                  reg_alpha=0, reg_lambda=1, scale_pos_weight=4, subsample=1,
                  tree_method='exact', validate_parameters=1, verbosity=None)



- **모델 평가지표 시각화 함수**  
train, test 데이터셋에 대하여 Accuracy, AUC, f1_score, precision, recall 평가지표를 구하고, 시각화 한다. 


```python
def plot_evauate(trainX, trainY, testX, testY, model):
    from sklearn.metrics import roc_curve, roc_auc_score, f1_score, f1_score, accuracy_score, recall_score, precision_score
    
    train_pred = model.predict(trainX)
    train_prob = model.predict_proba(trainX)[:, 1]
    
    test_pred = model.predict(testX) 
    test_prob = model.predict_proba(testX)[:, 1]
    
    
    # ROC Curve 시각화 
    fpr, tpr, thresholds = roc_curve(testY, test_prob) 
    
    plt.plot(fpr, tpr, color='red', label='ROC')
    plt.plot([0, 1], [0, 1], color='green', linestyle='--')
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title('test ROC : {}'.format(round(roc_auc_score(testY, test_prob),3)),fontsize=25)
    plt.legend()
    plt.show()
    
    
    
    # 여러 평가지표 시각화 
    dic_name2func = { 'F1-score': f1_score, 
                     'Recall': recall_score, 
                     'Precision': precision_score, 
                     'Accuracy': accuracy_score, 
                     'ROCAUC': roc_auc_score }
    
    lst_result = []
    for name, func in dic_name2func.items():
        if name == 'ROCAUC':
            train = func(trainY, train_prob)
            test = func(testY, test_prob)
            
        else:
            train = func(trainY, train_pred)
            test = func(testY, test_pred)
        
        lst_result.append([name, train, test])
    
    df = pd.DataFrame(data=lst_result,
                columns=['name', 'train', 'test'])
    df = df.melt(id_vars='name')    
        
    ax = sns.barplot(data=df, x='name', y='value', hue='variable')
    ax.set_ylim(0, 1)
    
    # 텍스트 추가 
    for p in ax.patches:
        height = p.get_height()
        ax.text(p.get_x() + p.get_width() / 2., height + 0.01, round(height, 3), ha = 'center', size = 10)

    plt.show()
```

- **성능 평가** 


```python
plot_evauate(trainX, trainY, testX, testY, xgb)
```


    
![png]({{site.baseurl}}/images/output_33_0.png)
    



    
![png]({{site.baseurl}}/images/output_33_1.png)
    


rocauc score는 0.595가 나왔다. 데이터의 기간을 늘리고, 보조지표를 추가함으로써 지난 글의 Baseline Model보다 성능이 향상되었음을 알 수 있다.      
다음 글에서는 현재 사용하고 있는 통합 종목 주가 데이터셋의 종목별 가격이 모두 다른 점을 보완하기 위해 데이터를 표준화하는 시간을 가진다. 
