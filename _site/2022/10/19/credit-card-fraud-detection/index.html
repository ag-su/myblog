<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset='utf-8'>
  <meta http-equiv='X-UA-Compatible' content='IE=edge'>
  <meta name='viewport' content='width=device-width, initial-scale=1'>

  <title>Transcription || [Kaggle] Credit card Fraud Detection</title>
  <meta name='description' content="[필사 코드 링크]-Credit Fraud || Dealing with Imbalanced Datasets">
  <link rel='canonical' href="https://ag-su.github.io/myblog/2022/10/19/credit-card-fraud-detection/">
  <link rel='alternate' type='application/rss+xml' title='agsu BLOG' href="https://ag-su.github.io/myblog/feed.xml">
  <!-- Fonts -->
  <link href="https://fonts.googleapis.com/css?family=Volkhov:400,700" rel="stylesheet">
  <link href="https://fonts.googleapis.com/css?family=Open+Sans:400,700" rel="stylesheet">

  <style>
    
    @font-face{font-family:'Cafe24Oneprettynight';src:url("https://cdn.jsdelivr.net/gh/projectnoonnu/noonfonts_twelve@1.1/Cafe24Oneprettynight.woff") format("woff");font-weight:normal;font-style:normal}/*! normalize.css v7.0.0 | MIT License | github.com/necolas/normalize.css */html{line-height:1.15;-ms-text-size-adjust:100%;-webkit-text-size-adjust:100%}body{margin:0}article,aside,footer,header,nav,section{display:block}h1{font-size:2em;margin:0.67em 0}figcaption,figure,main{display:block}figure{margin:1em 40px}hr{box-sizing:content-box;height:0;overflow:visible}pre{font-family:monospace, monospace;font-size:1em}a{background-color:transparent;-webkit-text-decoration-skip:objects}abbr[title]{border-bottom:none;text-decoration:underline;text-decoration:underline dotted}b,strong{font-weight:inherit}b,strong{font-weight:bolder}code,kbd,samp{font-family:monospace, monospace;font-size:1em}dfn{font-style:italic}mark{background-color:#ff0;color:#000}small{font-size:80%}sub,sup{font-size:75%;line-height:0;position:relative;vertical-align:baseline}sub{bottom:-0.25em}sup{top:-0.5em}audio,video{display:inline-block}audio:not([controls]){display:none;height:0}img{border-style:none}svg:not(:root){overflow:hidden}button,input,optgroup,select,textarea{font-family:sans-serif;font-size:100%;line-height:1.15;margin:0}button,input{overflow:visible}button,select{text-transform:none}button,html [type="button"],[type="reset"],[type="submit"]{-webkit-appearance:button}button::-moz-focus-inner,[type="button"]::-moz-focus-inner,[type="reset"]::-moz-focus-inner,[type="submit"]::-moz-focus-inner{border-style:none;padding:0}button:-moz-focusring,[type="button"]:-moz-focusring,[type="reset"]:-moz-focusring,[type="submit"]:-moz-focusring{outline:1px dotted ButtonText}fieldset{padding:0.35em 0.75em 0.625em}legend{box-sizing:border-box;color:inherit;display:table;max-width:100%;padding:0;white-space:normal}progress{display:inline-block;vertical-align:baseline}textarea{overflow:auto}[type="checkbox"],[type="radio"]{box-sizing:border-box;padding:0}[type="number"]::-webkit-inner-spin-button,[type="number"]::-webkit-outer-spin-button{height:auto}[type="search"]{-webkit-appearance:textfield;outline-offset:-2px}[type="search"]::-webkit-search-cancel-button,[type="search"]::-webkit-search-decoration{-webkit-appearance:none}::-webkit-file-upload-button{-webkit-appearance:button;font:inherit}details,menu{display:block}summary{display:list-item}canvas{display:inline-block}template{display:none}[hidden]{display:none}body,h1,h2,h3,h4,h5,h6,p,blockquote,pre,dl,dd,ol,ul,fieldset,legend,figure,hr{margin:0;padding:0}li>ul,li>ol{margin-bottom:0}table{border-collapse:collapse;border-spacing:0}@-webkit-keyframes spin{100%{-webkit-transform:rotate(360deg);transform:rotate(360deg)}}@keyframes spin{100%{-webkit-transform:rotate(360deg);transform:rotate(360deg)}}.icon{position:relative;display:inline-block;width:25px;height:25px;overflow:hidden;fill:currentColor}.icon__cnt{width:100%;height:100%;background:inherit;fill:inherit;pointer-events:none;transform:translateX(0);-ms-transform:translate(0.5px, -0.3px)}.icon--m{width:50px;height:50px}.icon--l{width:100px;height:100px}.icon--xl{width:150px;height:150px}.icon--xxl{width:200px;height:200px}.icon__spinner{position:absolute;top:0;left:0;width:100%;height:100%}.icon--ei-spinner .icon__spinner,.icon--ei-spinner-2 .icon__spinner{-webkit-animation:spin 1s steps(12) infinite;animation:spin 1s steps(12) infinite}.icon--ei-spinner-3 .icon__spinner{-webkit-animation:spin 1.5s linear infinite;animation:spin 1.5s linear infinite}.icon--ei-sc-facebook{fill:#3b5998}.icon--ei-sc-github{fill:#333}.icon--ei-sc-google-plus{fill:#dd4b39}.icon--ei-sc-instagram{fill:#3f729b}.icon--ei-sc-linkedin{fill:#0976b4}.icon--ei-sc-odnoklassniki{fill:#ed812b}.icon--ei-sc-skype{fill:#00aff0}.icon--ei-sc-soundcloud{fill:#f80}.icon--ei-sc-tumblr{fill:#35465c}.icon--ei-sc-twitter{fill:#55acee}.icon--ei-sc-vimeo{fill:#1ab7ea}.icon--ei-sc-vk{fill:#45668e}.icon--ei-sc-youtube{fill:#e52d27}.icon--ei-sc-pinterest{fill:#bd081c}.icon--ei-sc-telegram{fill:#0088cc}*,*::after,*::before{box-sizing:border-box}h1,h2,h3,h4,h5,h6,ul,ol,dl,blockquote,p,address,hr,table,fieldset,figure,pre{margin-bottom:15px}ul,ol,dd{margin-left:15px}@font-face{font-family:'D2 coding';src:url("http://cdn.jsdelivr.net/gh/joungkyun/font-d2coding/d2coding.css") format("text/css");font-weight:normal;font-style:normal}.highlight{background:#f0f0f082;font-family:'D2 coding'}.highlighter-rouge .highlight{background:#f0f0f082}.highlight .c{color:#998;font-style:italic}.highlight .err{color:#a61717;background-color:#e3d2d2}.highlight .k{color:#29843b;font-weight:bold}.highlight .o{color:#c917ed;font-weight:bold}.highlight .cm{color:#998;font-style:italic}.highlight .cp{color:#999;font-weight:bold}.highlight .c1{color:#416373;font-style:italic}.highlight .cs{color:#999;font-weight:bold;font-style:italic}.highlight .gd{color:#000;background-color:#fdd}.highlight .gd .x{color:#000;background-color:#faa}.highlight .ge{font-style:italic}.highlight .gr{color:#a00}.highlight .gh{color:#999}.highlight .gi{color:#000;background-color:#dfd}.highlight .gi .x{color:#000;background-color:#afa}.highlight .go{color:#888}.highlight .gp{color:#555}.highlight .gs{font-weight:bold}.highlight .gu{color:#aaa}.highlight .gt{color:#a00}.highlight .kn{color:#29843b;font-weight:bold}.highlight .kc{font-weight:bold}.highlight .kd{font-weight:bold}.highlight .kp{font-weight:bold}.highlight .kr{font-weight:bold}.highlight .kt{color:#458;font-weight:bold}.highlight .m{color:#099}.highlight .s{color:#bc0202}.highlight .n{color:#000}.highlight .na{color:#008080}.highlight .nb{color:#29843b}.highlight .nc{color:#458;font-weight:bold}.highlight .no{color:#008080}.highlight .ni{color:#800080}.highlight .ne{color:#900;font-weight:bold}.highlight .nf{color:#150dff;font-weight:500}.highlight .nn{color:#555}.highlight .nt{color:#000080}.highlight .nv{color:#008080}.highlight .ow{font-weight:bold;color:#7590b7}.highlight .w{color:#bbb}.highlight .mf{color:#29843b}.highlight .mh{color:#099}.highlight .mi{color:#29843b}.highlight .mo{color:#099}.highlight .sa{color:#bc0202}.highlight .sb{color:#d14}.highlight .sc{color:#d14}.highlight .sd{color:#d14}.highlight .s2{color:#d14}.highlight .se{color:#d14}.highlight .sh{color:#d14}.highlight .si{color:#bc0202}.highlight .sx{color:#d14}.highlight .sr{color:#009926}.highlight .s1{color:#d14}.highlight .ss{color:#990073}.highlight .bp{color:#29843b;font-weight:bold}.highlight .vc{color:#008080}.highlight .vg{color:#008080}.highlight .vi{color:#008080}.highlight .il{color:#099}.highlight .p{color:#000}body{font-family:"Cafe24Oneprettynight";font-size:19px;line-height:28px;color:#404040;background-color:#ffffff;-webkit-font-smoothing:antialiased;-moz-osx-font-smoothing:grayscale}*::selection{color:#fff;background-color:#d86e89}h1,h2,h3,h4,h5,h6{font-family:"Cafe24Oneprettynight";font-weight:400;line-height:initial}h1{font-size:32px}h2{font-size:28px}h3{font-size:24px}h4{font-size:20px}h5{font-size:18px}h6{font-size:16px}img{max-width:100%;height:auto;vertical-align:middle}a{text-decoration:none;color:#3af;transition:.35s}a:hover{color:#0086e6}blockquote{padding-left:15px;border-left:3px solid #3af;font-family:'Volkhov', 'Times New Roman', Times, serif;font-style:normal;font-size:18px;background-color:rgba(220,235,245,0.2)}blockquote p{padding:10px}hr{height:1px;margin:30px 0;border:0;background-color:#f0f0f0}pre{overflow:auto;padding:25px;font-size:14px;white-space:pre-wrap;word-wrap:break-word;word-break:break-all;font-family:Courier, monospace}code{color:#928b8b;overflow:auto;white-space:pre-wrap;word-wrap:break-word;word-break:break-all;font-family:Courier, monospace;font-size:14px}p code,li code{padding:3px 5px}.o-wrapper{max-width:1440px;position:relative}.o-opacity{animation-duration:0.7s;animation-delay:0.2s;animation-fill-mode:both;animation-name:opacity}@keyframes opacity{from{opacity:0}to{opacity:1}}.c-btn{display:inline-block;white-space:nowrap;vertical-align:middle;font-family:'Volkhov', serif;font-size:12px;text-align:center;padding:8px 15px;cursor:pointer;transition:.35s}.c-btn--primary{color:#fff;background-color:#3af;background:linear-gradient(135deg, #3af 0%, #62d5ff 100%)}.c-btn--secondary{color:#fff;background-color:#cfcfdd;background:linear-gradient(135deg, #f1577d 0%, #cfcfdd 100%)}.c-btn--round{border-radius:30px}.c-btn--shadow{box-shadow:8px 10px 20px 0 rgba(46,61,73,0.15)}.c-btn--shadow:hover{box-shadow:2px 4px 8px 0px rgba(46,61,73,0.2)}.c-btn--middle{display:block;width:300px;max-width:100%}.c-btn--big{display:block;width:100%}.c-btn:hover{color:#fff;transition:.35s}.c-btn:active{transform:translateY(2px)}.c-sidebar{display:flex;flex-direction:column;justify-content:space-between;position:fixed;top:0;left:0;bottom:0;width:360px;padding:40px 20px 20px;text-align:center;box-shadow:1px 1px 0 rgba(31,35,46,0.15);background-color:#fff}.c-sidebar-author .c-author__cover{width:100px;height:100px;margin:0 auto 10px;border-radius:50%;overflow:hidden;background-color:#cfcfdd;font-family:'Cafe24Oneprettynight'}.c-sidebar-author .c-author__cover img{width:100%;height:100%;border-radius:50%;transition:.35s}.c-sidebar-author .c-author__cover img:hover{transform:scale3d(0.9, 0.9, 1)}.c-sidebar-author .c-contact-menu .c-btn{min-width:110px}.c-sidebar-author .c-contact-menu .c-btn .icon{width:18px;height:18px;vertical-align:text-bottom;fill:#fff}.c-sidebar-author .c-author__info{font-family:"Cafe24Oneprettynight"}.c-sidebar-author .c-author__name{font-size:18px;font-weight:700;line-height:21px}.c-sidebar-author .c-author__job{font-size:12px;color:#a0a0a0;margin:5px 0 0}.c-sidebar-author .c-contact-menu{margin:30px 0}.c-sidebar-author .c-contact-menu .c-btn--secondary{margin-right:10px}.c-sidebar-author .c-author__about{max-width:400px;margin:0 auto 15px;font-size:13px}.c-sidebar-footer .c-social__title{position:relative;font-family:'Volkhov', serif;font-size:15px;font-weight:700;color:#444}.c-sidebar-footer .c-social__title::before{content:"";display:block;height:2px;width:calc(50% - 40px);transform:translateY(-50%);position:absolute;top:50%;left:0;background-color:#444}.c-sidebar-footer .c-social__title::after{content:"";display:block;height:2px;width:calc(50% - 40px);transform:translateY(-50%);position:absolute;top:50%;right:0;background-color:#444}.c-sidebar-footer .c-social__list{list-style-type:none;padding:0;margin:15px 0}.c-sidebar-footer .c-social__list .c-social__item{display:inline-block;width:27px;height:27px}.c-sidebar-footer .c-social__list .icon{width:27px;height:27px;fill:#444;vertical-align:middle;transition:.35s}.c-sidebar-footer .c-social__list .icon:hover{fill:#3af;transform:scale(1.2);transition:.35s}.c-sidebar-footer .c-copyright p{font-size:13px;margin:0}@media only screen and (max-width: 900px){.c-sidebar{position:relative;width:100%;padding:20px}.c-sidebar .c-contact-menu{margin:20px 0}.c-sidebar-footer .c-social .c-social__title{clip:rect(1px, 1px, 1px, 1px);height:1px;overflow:hidden;position:absolute !important;width:1px;word-wrap:normal !important}.c-sidebar-footer .c-social__list{margin:0}.c-sidebar-footer .c-copyright{clip:rect(1px, 1px, 1px, 1px);height:1px;overflow:hidden;position:absolute !important;width:1px;word-wrap:normal !important}}@media only screen and (max-width: 480px){.c-sidebar-author .c-author__cover{width:80px;height:80px}.c-sidebar-author .c-author__cover img{width:100%;height:100%}.c-sidebar-author .c-contact-menu{margin:15px 0}.c-sidebar-author .c-contact-menu .c-btn{min-width:80px;font-size:10px;padding:4px 15px;margin-right:5px}.c-sidebar-author .c-contact-menu .c-btn .icon{width:16px;height:16px}.c-sidebar-footer .c-social .c-social__title{clip:rect(1px, 1px, 1px, 1px);height:1px;overflow:hidden;position:absolute !important;width:1px;word-wrap:normal !important}.c-sidebar-footer .c-social__list{margin:0}.c-sidebar-footer .c-social__list .icon{width:25px;height:25px}.c-sidebar-footer .c-copyright{clip:rect(1px, 1px, 1px, 1px);height:1px;overflow:hidden;position:absolute !important;width:1px;word-wrap:normal !important}}.c-content{position:relative;display:flex;flex-direction:row;flex-wrap:wrap;align-items:stretch;padding:0 20px 0;margin-left:360px}@media only screen and (max-width: 900px){.c-content{position:static;padding:0 15px 0;margin-left:0}}.c-posts{width:100%;display:flex;flex-direction:row;flex-wrap:wrap}.c-post{width:100%;max-width:100%;margin-bottom:20px;display:flex;flex-direction:row;align-items:stretch;min-height:180px;border-radius:10px;overflow:hidden;transition:.35s;background-color:#fff;box-shadow:0 1px 1px 0 rgba(31,35,46,0.15)}.c-post:hover{transform:translate(0px, -2px);box-shadow:0 15px 45px -10px rgba(10,16,34,0.2)}.c-post .c-post-thumbnail{display:block;width:30%;max-width:100%;min-height:180px;border-radius:10px 0 0 10px;background-color:rgba(220,235,245,0.2);background-size:cover;background-position:50% 50%}.c-post .c-post-content{padding:15px;width:70%}.c-post .c-post-content .c-post-title{font-size:25px;font-weight:400;margin:0 0 15px}.c-post .c-post-content .c-post-title a{text-decoration:none;color:#263959}.c-post .c-post-content .c-post-date,.c-post .c-post-content .c-post-words{font-size:12px}.c-load-more{padding:20px;margin:20px auto 40px;font-size:13px;color:#fff;border:none;background-color:#d0a9ae;outline:none}.c-load-more:hover{background-color:#0086e6}@media only screen and (max-width: 1200px){.c-post{width:48%;max-width:100%;margin:0 1% 20px;flex-direction:column}.c-post .c-post-thumbnail{width:100%;border-radius:10px 10px 0 0}.c-post .c-post-content{width:100%}.c-post .c-post-content .c-post-title{font-size:21px;margin:15px 0}}@media only screen and (max-width: 480px){.c-post{width:100%;max-width:100%;margin:0 0 20px}.c-post .c-post-content{width:100%}.c-post .c-post-content .c-post-title{font-size:21px;margin:15px 0}}.c-article{width:100%;margin:20px 0}.c-wrap-content{padding:20px;background-color:#fff}.c-article__image{position:relative;background-color:rgba(220,235,245,0.2);background-position:center;background-size:cover;background-repeat:no-repeat}.c-article__image:after{content:"";display:block;padding-top:56%}.c-article__header{margin-bottom:20px;text-align:center}.c-article__header .c-article__title{margin-bottom:10px}.c-article__date span{font-size:13px;text-transform:uppercase;color:#a0a0a0}.c-article__footer{margin:30px 0 0;padding-bottom:30px;text-align:center;border-bottom:1px solid #f0f0f0}.c-article__footer .c-article__share{transition:.35s}.c-article__footer .c-article__share a .icon{vertical-align:middle;transition:.35s}.c-article__footer .c-article__share a .icon:hover{opacity:.7;transition:.35s}.c-article__footer .c-article__tag{margin-bottom:5px}.c-article__footer .c-article__tag a{display:inline-block;vertical-align:middle;padding:5px 10px;font-family:'Volkhov', 'Times New Roman', Times, serif;font-size:10px;line-height:10px;text-transform:uppercase;background-color:rgba(115,138,160,0.6);color:#fff}.c-article__footer .c-article__tag a:hover{background-color:rgba(80,100,118,0.6)}.c-article__footer .c-article__tag a:last-child{margin-right:0}.c-recent-post{padding:30px 0}.c-recent-post .c-recent__title{font-size:14px;text-align:center;text-transform:uppercase;margin-bottom:30px}.c-recent-post .c-recent__box{display:flex;flex-direction:row;flex-wrap:wrap}.c-recent-post .c-recent__item{max-width:23%;flex-basis:23%;margin:0 1% 20px;border-radius:10px;overflow:hidden;text-align:center;background-color:#fff;box-shadow:0 1px 1px 0 rgba(31,35,46,0.15);transition:.35s}.c-recent-post .c-recent__item h4{margin-bottom:5px;font-size:12px;text-transform:uppercase}.c-recent-post .c-recent__item h4 a{color:#444}.c-recent-post .c-recent__item:hover{box-shadow:2px 4px 8px 0px rgba(46,61,73,0.2)}.c-recent-post .c-recent__footer{padding:15px}.c-recent-post .c-recent__image{display:block;width:100%;min-height:180px;background-color:rgba(220,235,245,0.2);background-size:cover;background-position:center;background-repeat:no-repeat}.c-recent-post .c-recent__date{color:#a0a0a0;font-size:12px}@media only screen and (max-width: 1200px){.c-recent-post .c-recent__item{max-width:48%;flex-basis:48%}}@media only screen and (max-width: 900px){.c-article{margin:15px 0}}@media only screen and (max-width: 480px){.c-wrap-content{padding:15px}.c-article__header{margin-bottom:5px}.c-article__header .c-article__title{font-size:24px;margin-bottom:5px}.c-recent-post .c-recent__item{max-width:100%;flex-basis:100%;margin:0 0 20px}}.c-blog-tags{width:100%;padding:20px;margin:20px 0 40px;background-color:#fff}.c-blog-tags h1{text-align:center;margin-bottom:0}.c-blog-tags h2{font-size:18px;text-transform:uppercase;margin:30px 0;color:#757575}.c-tag__list{list-style:none;padding:0 0 40px;margin:40px 0 0;border-bottom:1px solid #f0f0f0}.c-tag__list li{display:inline-block;margin-right:15px}.c-tag__list li a{color:#404040;text-transform:uppercase;font-size:12px}.c-tag__list li a:hover{color:#000}.c-tag__item{margin-bottom:15px}.c-tag__image{width:50px;height:50px;border-radius:50%;margin-right:5px}@media only screen and (max-width: 480px){.c-blog-tags{padding:15px}.c-blog-tags h1{font-size:27px}.c-blog-tags h2{font-size:16px;margin:15px 0}.c-tag__list{padding:0 0 30px;margin:30px 0 0}.c-tag__item{margin-bottom:5px}.c-tag__image{display:none}}.c-header{position:relative;width:100%;margin:20px 0}.c-header__box{position:relative;display:flex;flex-direction:row;justify-content:space-between;align-items:center}.c-header__box .icon--ei-search{position:absolute;top:7px;left:15px;fill:#ccc}.c-search{width:80%}.c-search .c-search__box{display:flex;align-items:center}.c-search .c-search__text{position:relative;width:100%;padding:10px 10px 10px 40px;border:1px solid #dce4ea;border-radius:30px;outline:none;color:#a0a0a0}.c-search .c-search__text::placeholder{color:#ccc}.c-search .c-search__text:hover{box-shadow:0 1px 0px rgba(132,135,138,0.1);transition:.35s}.c-search .c-search-results-list{position:absolute;width:100%;margin:10px 0 0;list-style-type:none;background-color:#fff;z-index:1}.c-search .c-search-results-list li{display:flex;flex-wrap:wrap;align-items:center;margin:0;padding:20px 25px 0;background-color:#fff;line-height:1.4;border-left:solid 1px #edeeee;border-right:solid 1px #edeeee}.c-search .c-search-results-list li:first-child{border-top-left-radius:5px;border-top-right-radius:5px;border-top:solid 1px #edeeee}.c-search .c-search-results-list li:last-child{border-bottom-left-radius:5px;border-bottom-right-radius:5px;padding-bottom:25px;border-bottom:solid 1px #edeeee}.c-search .c-search-results-list li a{font-size:16px}.c-nav{flex-grow:1;padding-left:20px}.c-nav .c-nav__list{display:flex;justify-content:flex-end}.c-nav .c-nav__list .c-nav__item{display:flex;align-items:center;float:left;padding:4px 10px;font-size:10px;text-transform:uppercase;white-space:nowrap;border:1px solid #dce4ea;box-shadow:0 1px 0px rgba(132,135,138,0.4);will-change:transform;transform:translateY(0px);cursor:pointer}.c-nav .c-nav__list .c-nav__item:hover{color:#222;background-color:#fff}.c-nav .c-nav__list .c-nav__item.is-active{box-shadow:0 0 0 rgba(132,135,138,0.5);transform:translateY(1px);color:#cfcfdd}.c-nav .c-nav__list .c-nav__item.is-active:hover{background-color:#fbfbfb}.c-nav .c-nav__list .c-nav__item:first-child{border-radius:10px 0 0 10px}.c-nav .c-nav__list .c-nav__item:last-child{border-radius:0 10px 10px 0}.c-nav .c-nav__list .c-nav__item .icon{width:18px;height:18px;margin-right:3px}@media only screen and (max-width: 900px){.c-header{margin:15px 0}}@media only screen and (max-width: 480px){.c-header .c-header__box{flex-direction:column}.c-header .c-search{width:100%}.c-header .c-search .c-search__text{padding:8px 8px 8px 40px}.c-header .c-nav{margin-top:15px}.c-header .c-nav .c-nav__list{justify-content:center}.c-header .c-nav .c-nav__item{padding:4px 8px}}.c-categories{width:100%}.c-categories__list{width:100%;display:flex;flex-direction:row;flex-wrap:wrap}.c-categories__item{max-width:25%;flex-basis:25%;padding:0 10px 20px}.c-categories__link{height:100%;display:flex;flex-direction:column;align-items:center;padding:20px 10px;border-radius:5px;box-shadow:5px 5px 25px rgba(46,61,73,0.15);background-color:#fff;transition:.35s}.c-categories__link:hover{box-shadow:2px 4px 8px 0px rgba(46,61,73,0.2)}.c-categories__link:hover .c-categories__img .c-categories__more{opacity:1;transition:.35s}.c-categories__link .c-categories__container{width:100%;word-wrap:break-word}.c-categories__link .c-categories__container.c-empty-figure{display:flex;flex-direction:column;justify-content:center;flex-grow:1}.c-categories__img{position:relative;max-width:100%}.c-categories__img figure{position:relative;width:200px;max-width:100%;margin-bottom:20px;overflow:hidden;background-size:cover;background-repeat:no-repeat;background-position:center;border-radius:50%;box-shadow:inset 0 1px 3px rgba(141,165,185,0.3)}.c-categories__img figure:after{content:"";display:block;padding-top:100%}.c-categories__img figure:before{content:"";position:absolute;top:0;bottom:0;left:0;right:0;background-color:rgba(0,0,0,0.15)}.c-categories__img .c-categories__more{display:inline-block;position:absolute;top:50%;left:50%;transform:translate(-50%, -50%);font-weight:700;color:#fff;text-transform:uppercase;text-shadow:0 1px 0 rgba(104,172,191,0.3);opacity:0;transition:.35s}.c-categories__container{text-align:center}.c-categories__container .c-categories__header{font-size:13px;margin-bottom:10px;font-weight:normal;text-transform:uppercase;color:#404040}.c-categories__container .c-categories__count{font-family:'Volkhov', serif;font-size:12px;color:#404040;margin-bottom:0}.c-categories__container .c-categories__count span{display:inline-block;width:20px;height:20px;line-height:20px;vertical-align:baseline;margin-right:5px;border-radius:50%;color:#fff;background-color:#ee6c6c}@media only screen and (max-width: 1200px){.c-categories .c-categories__item{max-width:33.333%;flex-basis:33.333%}}@media only screen and (max-width: 1050px){.c-categories .c-categories__item{max-width:50%;flex-basis:50%}}@media only screen and (max-width: 480px){.c-categories .c-categories__item{max-width:100%;flex-basis:100%;padding:0 0 20px}}.c-form-box{position:absolute;top:0;width:calc(100% - 40px);min-height:100vh;padding:0 20px;background-color:#fff;z-index:1}.c-form-bnt__close{position:absolute;top:0px;left:0;width:30px;height:30px;cursor:pointer;transition:.35s}.c-form-bnt__close:hover{transform:scale(0.8);opacity:.8}.c-form{position:relative;width:750px;max-width:100%;margin:40px auto}.c-form .c-form__title{margin:0 0 40px;min-width:0;border:0;padding:0;font-family:"Cafe24Oneprettynight";text-transform:uppercase;text-align:center}.c-form a{color:#404040}.c-form__group{margin-bottom:20px}.c-form__group label{display:block;text-transform:uppercase;font-size:10px}.c-form__group input,.c-form__group textarea{width:100%;padding:10px 15px;color:#404040;border:1px solid #dce4ea;outline:none;transition:.35s}.c-form__group input:focus,.c-form__group textarea:focus{box-shadow:0 4px 25px rgba(132,135,138,0.1)}.c-form__group button{padding:20px;text-transform:uppercase;outline:none;border:none}.c-thank-you p{position:relative;padding:20px 40px;width:750px;max-width:100%;text-transform:uppercase;font-size:12px;line-height:18px;font-weight:700;margin:40px auto 0;text-align:center;color:#fff;background:linear-gradient(135deg, #55b5ad 0%, #5ec9c5 100%)}.c-thank-you p .c-form-bnt__close{width:25px;height:25px;background:transparent}.c-thank-you p a{color:#fff}@media only screen and (max-width: 900px){.c-form-box{width:100%;left:0;right:0}}@media only screen and (max-width: 480px){.c-form-bnt__close{width:25px;height:25px}}.c-newsletter{padding:30px 0 60px;margin:0 auto;border-bottom:1px solid #f0f0f0}.c-newsletter__header{text-align:center}.c-newsletter__header .c-newsletter__title{font-size:14px;text-transform:uppercase;text-align:center}.c-newsletter__header .c-newsletter__subtitle{margin-bottom:15px}.c-newsletter-form{width:100%;max-width:750px;margin:0 auto}.c-newsletter-form .c-newsletter-form__group{display:flex}.c-newsletter__email{width:70%;height:40px;padding:10px 15px;border:1px solid #ddd;border-right-color:transparent;outline:none;transition:.35s}.c-newsletter__email:focus{box-shadow:0 4px 25px rgba(132,135,138,0.1)}.c-newsletter__button{width:30%;height:40px;color:#fff;background-color:#3af;transition:.35s;border:none;outline:none;cursor:pointer}.c-newsletter__button:hover{background-color:#0086e6}@media only screen and (max-width: 480px){.c-newsletter__button{font-size:13px}}.c-comments{padding:30px 0;border-top:1px solid #f0f0f0}.c-top{position:fixed;width:40px;height:40px;bottom:20px;color:#757575;cursor:pointer;transition:.35s;right:-100px;z-index:10;opacity:.5}.c-top--active{right:15px}.c-top:hover{color:#757575;opacity:1}.u-text-left{text-align:left}.u-text-right{text-align:right}.u-text-center{text-align:center}.u-text-justify{text-align:justify}.u-block{display:block}.u-inline-block{display:inline-block}.u-inline{display:inline}.u-full-width{display:block;width:100%}.u-vertical-center{display:flex;align-items:center;justify-content:center}.u-responsive-image{max-width:100%;height:auto;vertical-align:middle}.u-show{display:block !important}.u-hide{display:none !important}.u-invisible{visibility:hidden}.u-float-left{float:left}.u-float-right{float:right}.u-no-padding-top{padding-top:0}.u-no-padding-bottom{padding-bottom:0}.u-no-padding-left{padding-left:0}.u-no-padding-right{padding-right:0}.u-no-padding{padding:0}.u-no-margin-top{margin-top:0}.u-no-margin-bottom{margin-bottom:0}.u-no-margin-left{margin-left:0}.u-no-margin-right{margin-right:0}.u-no-margin{margin:0}.u-lists-reset{list-style-type:none;margin:0;padding:0}.u-clearfix::before,.u-clearfix::after{content:"";display:table;clear:both}.u-screen-reader-text{clip:rect(1px, 1px, 1px, 1px);height:1px;overflow:hidden;position:absolute !important;width:1px;word-wrap:normal !important}

  </style>
</head>

<body>
  
  <div class="o-wrapper">
    <aside class="c-sidebar">
  <div class="c-sidebar-author">
    <div class="c-author__cover">
      <a href="/myblog/">
        <img src="/myblog/images/toetoe.jpg" alt="agsu">
      </a>
    </div>
    <div class="c-author__info">
      <div class="c-author__name">agsu</div>
      <span class="c-author__job">Devision of Data Science</span>
    </div>
    <div class="c-contact-menu">
      
      <a href="/contact" class="c-contact-btn c-btn c-btn--secondary c-btn--round c-btn--shadow"><span data-icon='ei-envelope' data-size='s'></span> Send me</a>
      
      
      
    </div>
    <p class="c-author__about">블로그</p>
  </div>

  <div class="c-sidebar-footer">
    <div class="c-social">
      <div class="c-social__title">Social</div>
      <ul class="c-social__list u-lists-reset">
        
        
        
        
        
          <li class="c-social__item"><a href="https://github.com/artemsheludko" target="_blank"><div data-icon='ei-sc-github' data-size='s'></div></a></li>
        
        
        
        
          <li class="c-social__item"><a href="https://instagram.com/artemsheludko_" target="_blank"><div data-icon='ei-sc-instagram' data-size='s'></div></a></li>
        
        
        
        
        
        
        
      </ul>
    </div>
    <div class="c-copyright">
      <p>2022 &copy; agsu</p>
    </div>
  </div>
</aside> <!-- /.c-sidebar -->

<main class="c-content">
  <article class="c-article">
  <div class="c-article__content">
    <header class="c-header u-hide u-no-margin-top">
      <div class="c-header__box">
        <div class="c-search u-full-width">
          <div class="c-search__box">
            <label for="js-search-input" class="u-screen-reader-text">Search for Blog</label>
            <input type="text" id="js-search-input" class="c-search__text" autocomplete="off" placeholder="Type to search...">
            <div data-icon='ei-search' data-size='s'></div>
          </div>
          <ul id="js-results-container" class="c-search-results-list"></ul>
        </div>
      </div>
    </header>
    
    <div class="c-article__image o-opacity" style="background-image: url( /myblog/images/01.credit_thumbnail.png )"></div>
    
    <div class="c-wrap-content">
      <header class="c-article__header">
        <h1 class="c-article__title">Transcription || [Kaggle] Credit card Fraud Detection</h1>
        <div class="c-article__date">
          <span>2022, Oct 19</span>
        </div>
      </header>
      <p><strong>[필사 코드 링크]</strong><br />
-<a href="https://www.kaggle.com/code/janiobachmann/credit-fraud-dealing-with-imbalanced-datasets/notebook">Credit Fraud || Dealing with Imbalanced Datasets</a></p>

<p><strong>[데이터셋 링크]</strong><br />
-<a href="https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud">Credit Card Fraud Detection</a></p>

<ul>
  <li>캐글에서 Credit Card Fraud Detection 데이터 불러오기</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># install kaggle 
# !pip install kaggle --upgrade
</span></code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># API Token 업로드
</span><span class="kn">from</span> <span class="nn">google.colab</span> <span class="kn">import</span> <span class="n">files</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="n">files</span><span class="p">.</span><span class="n">upload</span><span class="p">()</span>

<span class="c1"># json 파일 ~/.kaggle로 이동시키기
</span><span class="err">!</span><span class="n">mkdir</span> <span class="o">-</span><span class="n">p</span> <span class="o">~/</span><span class="p">.</span><span class="n">kaggle</span>
<span class="err">!</span><span class="n">cp</span> <span class="n">kaggle</span><span class="p">.</span><span class="n">json</span> <span class="o">~/</span><span class="p">.</span><span class="n">kaggle</span><span class="o">/</span>

<span class="c1"># Permission Warning 방지
</span><span class="err">!</span><span class="n">chmod</span> <span class="mi">600</span> <span class="o">~/</span><span class="p">.</span><span class="n">kaggle</span><span class="o">/</span><span class="n">kaggle</span><span class="p">.</span><span class="n">json</span>

<span class="c1"># 데이터셋 다운로드
</span><span class="err">!</span><span class="n">kaggle</span> <span class="n">datasets</span> <span class="n">download</span> <span class="o">-</span><span class="n">d</span> <span class="n">mlg</span><span class="o">-</span><span class="n">ulb</span><span class="o">/</span><span class="n">creditcardfraud</span>
<span class="err">!</span><span class="n">unzip</span>  <span class="n">creditcardfraud</span><span class="p">.</span><span class="nb">zip</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s">'creditcard.csv'</span><span class="p">)</span>
</code></pre></div></div>

<p><br />
<br /></p>

<p><strong>Introduction</strong></p>
<ul>
  <li>우리는 다양한 예측 모델을 사용하여 거래가 정상적인 지불인지 사기인지 탐지하는 데 얼마나 정확한지 확인한다. 데이터 세트에서 볼 수 있듯, 개인 정보 보호의 이유로 인해  변수의 크기가 표준화되었고, 변수의 이름도 V1~V28로 되어있다. 하지만 우리는 이 데이터셋을 사용하여 몇 가지 중요한 측면을 분석할 수 있다.</li>
</ul>

<p><br /></p>

<p><strong>목표</strong></p>
<ul>
  <li>우리에게 제공된 “작은” 데이터의 작은 분포를 이해한다.</li>
  <li>“사기” 트랜잭션과 “비사기” 트랜잭션의 50/50 하위 데이터 프레임 비율을 만든다. (Near Miss 알고리즘)</li>
  <li>사용할 분류기를 결정하고 정확도가 높은 분류기를 결정한다.</li>
  <li>신경망(neural network)을 만들고 정확도를 우리의 최고 분류기와 비교한다.</li>
  <li>불균형 데이터셋에서 흔히 발생하는 실수를 이해한다.</li>
</ul>

<p><br /></p>

<p><strong>개요</strong></p>
<ul>
  <li>1.데이터 이해
    <ul>
      <li>1.1 데이터에 대한 정보 수집</li>
    </ul>
  </li>
  <li>2.전처리
    <ul>
      <li>2.1 표준화(Scaling)와 분포(Distributing)</li>
      <li>2.2 데이터 분할 (Spliting the Data)</li>
    </ul>
  </li>
  <li>3.랜덤 언더 샘플링(Under Sampling) 및 오버 샘플링(Over Sampling)
    <ul>
      <li>3.1 분포(Distributing) 및 상관 관계(Correlating)</li>
      <li>3.2 이상 탐지(Anomaly Detection)</li>
      <li>3.3 차원 축소 및 클러스터링(t-SNE)</li>
      <li>3.4 Classifiers</li>
      <li>3.5 로지스틱 회귀 분석</li>
      <li>3.6 SMOTE를 사용한 오버샘플링(Over Smpling)</li>
    </ul>
  </li>
  <li>4.테스팅
    <ul>
      <li>4.1 로지스틱 회귀 분석을 사용한 검정(Testing)</li>
      <li>4.2 신경망 테스팅(언더샘플링 vs 오버샘플링)</li>
    </ul>
  </li>
</ul>

<h1 id="1-데이터-이해">1. 데이터 이해</h1>

<h2 id="11-데이터에-대한-정보-수집">1.1 데이터에 대한 정보 수집</h2>
<p>우리가 가장 먼저 해야 할 일은 데이터에 대한 기본적인 감각을 익히는 것이다. 개인 정보 보호 상의 이유로, 거래 및 금액을 제외하고 다른 컬럼에 대한 정보는 알 수 없다. 우리가 아는 유일한 것은 그 컬럼들은 이미 <code class="language-plaintext highlighter-rouge">표준화</code>되어있다는 점이다.</p>

<p><strong>변수에 적용된 세부적인 기술</strong></p>
<ul>
  <li>
    <p>PCA 변환: 데이터의 설명에 따르면, time, amount 변수를 제외한 모든 변수는 PCA 변환(Dimensionality Reduction technique)을 거쳤다.</p>
  </li>
  <li>
    <p>스케일링: PCA 변환을 구현하려면 변수를 미리 스케일링해야 한다.</p>
  </li>
</ul>

<p>library import</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span> <span class="c1"># linear algebra
</span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="n">pd</span> <span class="c1"># data processing, CSV file I/O (e.g. pd.read_csv)
</span><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="n">tf</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="n">sns</span>
<span class="kn">from</span> <span class="nn">sklearn.manifold</span> <span class="kn">import</span> <span class="n">TSNE</span>
<span class="kn">from</span> <span class="nn">sklearn.decomposition</span> <span class="kn">import</span> <span class="n">PCA</span><span class="p">,</span> <span class="n">TruncatedSVD</span>
<span class="kn">import</span> <span class="nn">matplotlib.patches</span> <span class="k">as</span> <span class="n">mpatches</span>
<span class="kn">import</span> <span class="nn">time</span>

<span class="c1"># Classifier Libraries
</span><span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LogisticRegression</span>
<span class="kn">from</span> <span class="nn">sklearn.svm</span> <span class="kn">import</span> <span class="n">SVC</span>
<span class="kn">from</span> <span class="nn">sklearn.neighbors</span> <span class="kn">import</span> <span class="n">KNeighborsClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.tree</span> <span class="kn">import</span> <span class="n">DecisionTreeClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestClassifier</span>
<span class="kn">import</span> <span class="nn">collections</span>


<span class="c1"># Other Libraries
</span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="nn">sklearn.pipeline</span> <span class="kn">import</span> <span class="n">make_pipeline</span>
<span class="kn">from</span> <span class="nn">imblearn.pipeline</span> <span class="kn">import</span> <span class="n">make_pipeline</span> <span class="k">as</span> <span class="n">imbalanced_make_pipeline</span>
<span class="kn">from</span> <span class="nn">imblearn.over_sampling</span> <span class="kn">import</span> <span class="n">SMOTE</span>
<span class="kn">from</span> <span class="nn">imblearn.under_sampling</span> <span class="kn">import</span> <span class="n">NearMiss</span>
<span class="kn">from</span> <span class="nn">imblearn.metrics</span> <span class="kn">import</span> <span class="n">classification_report_imbalanced</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">precision_score</span><span class="p">,</span> <span class="n">recall_score</span><span class="p">,</span> <span class="n">f1_score</span><span class="p">,</span> <span class="n">roc_auc_score</span><span class="p">,</span> <span class="n">accuracy_score</span><span class="p">,</span> <span class="n">classification_report</span>
<span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">Counter</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">KFold</span><span class="p">,</span> <span class="n">StratifiedKFold</span>
<span class="kn">import</span> <span class="nn">warnings</span>
<span class="n">warnings</span><span class="p">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s">"ignore"</span><span class="p">)</span>
</code></pre></div></div>

<ul>
  <li>데이터 확인</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">df</span><span class="p">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div></div>

<div id="df-1a8212d1-eee1-4c64-b0d4-64b317ab7d1d">
    <div class="colab-df-container">
      <div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Time</th>
      <th>V1</th>
      <th>V2</th>
      <th>V3</th>
      <th>V4</th>
      <th>V5</th>
      <th>V6</th>
      <th>V7</th>
      <th>V8</th>
      <th>V9</th>
      <th>...</th>
      <th>V21</th>
      <th>V22</th>
      <th>V23</th>
      <th>V24</th>
      <th>V25</th>
      <th>V26</th>
      <th>V27</th>
      <th>V28</th>
      <th>Amount</th>
      <th>Class</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0.0</td>
      <td>-1.359807</td>
      <td>-0.072781</td>
      <td>2.536347</td>
      <td>1.378155</td>
      <td>-0.338321</td>
      <td>0.462388</td>
      <td>0.239599</td>
      <td>0.098698</td>
      <td>0.363787</td>
      <td>...</td>
      <td>-0.018307</td>
      <td>0.277838</td>
      <td>-0.110474</td>
      <td>0.066928</td>
      <td>0.128539</td>
      <td>-0.189115</td>
      <td>0.133558</td>
      <td>-0.021053</td>
      <td>149.62</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.0</td>
      <td>1.191857</td>
      <td>0.266151</td>
      <td>0.166480</td>
      <td>0.448154</td>
      <td>0.060018</td>
      <td>-0.082361</td>
      <td>-0.078803</td>
      <td>0.085102</td>
      <td>-0.255425</td>
      <td>...</td>
      <td>-0.225775</td>
      <td>-0.638672</td>
      <td>0.101288</td>
      <td>-0.339846</td>
      <td>0.167170</td>
      <td>0.125895</td>
      <td>-0.008983</td>
      <td>0.014724</td>
      <td>2.69</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1.0</td>
      <td>-1.358354</td>
      <td>-1.340163</td>
      <td>1.773209</td>
      <td>0.379780</td>
      <td>-0.503198</td>
      <td>1.800499</td>
      <td>0.791461</td>
      <td>0.247676</td>
      <td>-1.514654</td>
      <td>...</td>
      <td>0.247998</td>
      <td>0.771679</td>
      <td>0.909412</td>
      <td>-0.689281</td>
      <td>-0.327642</td>
      <td>-0.139097</td>
      <td>-0.055353</td>
      <td>-0.059752</td>
      <td>378.66</td>
      <td>0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>1.0</td>
      <td>-0.966272</td>
      <td>-0.185226</td>
      <td>1.792993</td>
      <td>-0.863291</td>
      <td>-0.010309</td>
      <td>1.247203</td>
      <td>0.237609</td>
      <td>0.377436</td>
      <td>-1.387024</td>
      <td>...</td>
      <td>-0.108300</td>
      <td>0.005274</td>
      <td>-0.190321</td>
      <td>-1.175575</td>
      <td>0.647376</td>
      <td>-0.221929</td>
      <td>0.062723</td>
      <td>0.061458</td>
      <td>123.50</td>
      <td>0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>2.0</td>
      <td>-1.158233</td>
      <td>0.877737</td>
      <td>1.548718</td>
      <td>0.403034</td>
      <td>-0.407193</td>
      <td>0.095921</td>
      <td>0.592941</td>
      <td>-0.270533</td>
      <td>0.817739</td>
      <td>...</td>
      <td>-0.009431</td>
      <td>0.798278</td>
      <td>-0.137458</td>
      <td>0.141267</td>
      <td>-0.206010</td>
      <td>0.502292</td>
      <td>0.219422</td>
      <td>0.215153</td>
      <td>69.99</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
<p>5 rows × 31 columns</p>
</div>
      <button class="colab-df-convert" onclick="convertToInteractive('df-1a8212d1-eee1-4c64-b0d4-64b317ab7d1d')" title="Convert this dataframe to an interactive table." style="display:none;">

  &lt;svg xmlns="http://www.w3.org/2000/svg" height="24px"viewBox="0 0 24 24"
       width="24px"&gt;
    <path d="M0 0h24v24H0V0z" fill="none" />
    <path d="M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z" /><path d="M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z" />
  &lt;/svg&gt;
      </button>

  <style>
    .colab-df-container {
      display:flex;
      flex-wrap:wrap;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

      <script>
        const buttonEl =
          document.querySelector('#df-1a8212d1-eee1-4c64-b0d4-64b317ab7d1d button.colab-df-convert');
        buttonEl.style.display =
          google.colab.kernel.accessAllowed ? 'block' : 'none';

        async function convertToInteractive(key) {
          const element = document.querySelector('#df-1a8212d1-eee1-4c64-b0d4-64b317ab7d1d');
          const dataTable =
            await google.colab.kernel.invokeFunction('convertToInteractive',
                                                     [key], {});
          if (!dataTable) return;

          const docLinkHtml = 'Like what you see? Visit the ' +
            '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
            + ' to learn more about interactive tables.';
          element.innerHTML = '';
          dataTable['output_type'] = 'display_data';
          await google.colab.output.renderOutput(dataTable, element);
          const docLink = document.createElement('div');
          docLink.innerHTML = docLinkHtml;
          element.appendChild(docLink);
        }
      </script>
    </div>
  </div>

<ul>
  <li>기초 통계량 확인</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">df</span><span class="p">.</span><span class="n">describe</span><span class="p">()</span>
</code></pre></div></div>

<div id="df-cf989260-5366-4a5d-baf3-2023c9cf1b66">
    <div class="colab-df-container">
      <div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Time</th>
      <th>V1</th>
      <th>V2</th>
      <th>V3</th>
      <th>V4</th>
      <th>V5</th>
      <th>V6</th>
      <th>V7</th>
      <th>V8</th>
      <th>V9</th>
      <th>...</th>
      <th>V21</th>
      <th>V22</th>
      <th>V23</th>
      <th>V24</th>
      <th>V25</th>
      <th>V26</th>
      <th>V27</th>
      <th>V28</th>
      <th>Amount</th>
      <th>Class</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>count</th>
      <td>284807.000000</td>
      <td>2.848070e+05</td>
      <td>2.848070e+05</td>
      <td>2.848070e+05</td>
      <td>2.848070e+05</td>
      <td>2.848070e+05</td>
      <td>2.848070e+05</td>
      <td>2.848070e+05</td>
      <td>2.848070e+05</td>
      <td>2.848070e+05</td>
      <td>...</td>
      <td>2.848070e+05</td>
      <td>2.848070e+05</td>
      <td>2.848070e+05</td>
      <td>2.848070e+05</td>
      <td>2.848070e+05</td>
      <td>2.848070e+05</td>
      <td>2.848070e+05</td>
      <td>2.848070e+05</td>
      <td>284807.000000</td>
      <td>284807.000000</td>
    </tr>
    <tr>
      <th>mean</th>
      <td>94813.859575</td>
      <td>1.168375e-15</td>
      <td>3.416908e-16</td>
      <td>-1.379537e-15</td>
      <td>2.074095e-15</td>
      <td>9.604066e-16</td>
      <td>1.487313e-15</td>
      <td>-5.556467e-16</td>
      <td>1.213481e-16</td>
      <td>-2.406331e-15</td>
      <td>...</td>
      <td>1.654067e-16</td>
      <td>-3.568593e-16</td>
      <td>2.578648e-16</td>
      <td>4.473266e-15</td>
      <td>5.340915e-16</td>
      <td>1.683437e-15</td>
      <td>-3.660091e-16</td>
      <td>-1.227390e-16</td>
      <td>88.349619</td>
      <td>0.001727</td>
    </tr>
    <tr>
      <th>std</th>
      <td>47488.145955</td>
      <td>1.958696e+00</td>
      <td>1.651309e+00</td>
      <td>1.516255e+00</td>
      <td>1.415869e+00</td>
      <td>1.380247e+00</td>
      <td>1.332271e+00</td>
      <td>1.237094e+00</td>
      <td>1.194353e+00</td>
      <td>1.098632e+00</td>
      <td>...</td>
      <td>7.345240e-01</td>
      <td>7.257016e-01</td>
      <td>6.244603e-01</td>
      <td>6.056471e-01</td>
      <td>5.212781e-01</td>
      <td>4.822270e-01</td>
      <td>4.036325e-01</td>
      <td>3.300833e-01</td>
      <td>250.120109</td>
      <td>0.041527</td>
    </tr>
    <tr>
      <th>min</th>
      <td>0.000000</td>
      <td>-5.640751e+01</td>
      <td>-7.271573e+01</td>
      <td>-4.832559e+01</td>
      <td>-5.683171e+00</td>
      <td>-1.137433e+02</td>
      <td>-2.616051e+01</td>
      <td>-4.355724e+01</td>
      <td>-7.321672e+01</td>
      <td>-1.343407e+01</td>
      <td>...</td>
      <td>-3.483038e+01</td>
      <td>-1.093314e+01</td>
      <td>-4.480774e+01</td>
      <td>-2.836627e+00</td>
      <td>-1.029540e+01</td>
      <td>-2.604551e+00</td>
      <td>-2.256568e+01</td>
      <td>-1.543008e+01</td>
      <td>0.000000</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>25%</th>
      <td>54201.500000</td>
      <td>-9.203734e-01</td>
      <td>-5.985499e-01</td>
      <td>-8.903648e-01</td>
      <td>-8.486401e-01</td>
      <td>-6.915971e-01</td>
      <td>-7.682956e-01</td>
      <td>-5.540759e-01</td>
      <td>-2.086297e-01</td>
      <td>-6.430976e-01</td>
      <td>...</td>
      <td>-2.283949e-01</td>
      <td>-5.423504e-01</td>
      <td>-1.618463e-01</td>
      <td>-3.545861e-01</td>
      <td>-3.171451e-01</td>
      <td>-3.269839e-01</td>
      <td>-7.083953e-02</td>
      <td>-5.295979e-02</td>
      <td>5.600000</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>50%</th>
      <td>84692.000000</td>
      <td>1.810880e-02</td>
      <td>6.548556e-02</td>
      <td>1.798463e-01</td>
      <td>-1.984653e-02</td>
      <td>-5.433583e-02</td>
      <td>-2.741871e-01</td>
      <td>4.010308e-02</td>
      <td>2.235804e-02</td>
      <td>-5.142873e-02</td>
      <td>...</td>
      <td>-2.945017e-02</td>
      <td>6.781943e-03</td>
      <td>-1.119293e-02</td>
      <td>4.097606e-02</td>
      <td>1.659350e-02</td>
      <td>-5.213911e-02</td>
      <td>1.342146e-03</td>
      <td>1.124383e-02</td>
      <td>22.000000</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>75%</th>
      <td>139320.500000</td>
      <td>1.315642e+00</td>
      <td>8.037239e-01</td>
      <td>1.027196e+00</td>
      <td>7.433413e-01</td>
      <td>6.119264e-01</td>
      <td>3.985649e-01</td>
      <td>5.704361e-01</td>
      <td>3.273459e-01</td>
      <td>5.971390e-01</td>
      <td>...</td>
      <td>1.863772e-01</td>
      <td>5.285536e-01</td>
      <td>1.476421e-01</td>
      <td>4.395266e-01</td>
      <td>3.507156e-01</td>
      <td>2.409522e-01</td>
      <td>9.104512e-02</td>
      <td>7.827995e-02</td>
      <td>77.165000</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>max</th>
      <td>172792.000000</td>
      <td>2.454930e+00</td>
      <td>2.205773e+01</td>
      <td>9.382558e+00</td>
      <td>1.687534e+01</td>
      <td>3.480167e+01</td>
      <td>7.330163e+01</td>
      <td>1.205895e+02</td>
      <td>2.000721e+01</td>
      <td>1.559499e+01</td>
      <td>...</td>
      <td>2.720284e+01</td>
      <td>1.050309e+01</td>
      <td>2.252841e+01</td>
      <td>4.584549e+00</td>
      <td>7.519589e+00</td>
      <td>3.517346e+00</td>
      <td>3.161220e+01</td>
      <td>3.384781e+01</td>
      <td>25691.160000</td>
      <td>1.000000</td>
    </tr>
  </tbody>
</table>
<p>8 rows × 31 columns</p>
</div>
      <button class="colab-df-convert" onclick="convertToInteractive('df-cf989260-5366-4a5d-baf3-2023c9cf1b66')" title="Convert this dataframe to an interactive table." style="display:none;">

  &lt;svg xmlns="http://www.w3.org/2000/svg" height="24px"viewBox="0 0 24 24"
       width="24px"&gt;
    <path d="M0 0h24v24H0V0z" fill="none" />
    <path d="M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z" /><path d="M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z" />
  &lt;/svg&gt;
      </button>

  <style>
    .colab-df-container {
      display:flex;
      flex-wrap:wrap;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

      <script>
        const buttonEl =
          document.querySelector('#df-cf989260-5366-4a5d-baf3-2023c9cf1b66 button.colab-df-convert');
        buttonEl.style.display =
          google.colab.kernel.accessAllowed ? 'block' : 'none';

        async function convertToInteractive(key) {
          const element = document.querySelector('#df-cf989260-5366-4a5d-baf3-2023c9cf1b66');
          const dataTable =
            await google.colab.kernel.invokeFunction('convertToInteractive',
                                                     [key], {});
          if (!dataTable) return;

          const docLinkHtml = 'Like what you see? Visit the ' +
            '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
            + ' to learn more about interactive tables.';
          element.innerHTML = '';
          dataTable['output_type'] = 'display_data';
          await google.colab.output.renderOutput(dataTable, element);
          const docLink = document.createElement('div');
          docLink.innerHTML = docLinkHtml;
          element.appendChild(docLink);
        }
      </script>
    </div>
  </div>

<ul>
  <li>결측값 확인</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">df</span><span class="p">.</span><span class="n">isnull</span><span class="p">().</span><span class="nb">sum</span><span class="p">().</span><span class="nb">max</span><span class="p">()</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>0
</code></pre></div></div>

<ul>
  <li>컬럼 확인</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">df</span><span class="p">.</span><span class="n">columns</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Index(['Time', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10',
       'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20',
       'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'Amount',
       'Class'],
      dtype='object')
</code></pre></div></div>

<ul>
  <li>class 비율 확인하기</li>
</ul>

<p>데이터 불균형 문제가 심각하므로 이후에 이 문제를 해결해야한다.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"No Frauds: </span><span class="si">{</span><span class="nb">round</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s">'Class'</span><span class="p">].</span><span class="n">value_counts</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="p">)</span><span class="o">*</span><span class="mi">100</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span><span class="si">}</span><span class="s">% of the dataset"</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Frauds: </span><span class="si">{</span><span class="nb">round</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s">'Class'</span><span class="p">].</span><span class="n">value_counts</span><span class="p">()[</span><span class="mi">1</span><span class="p">]</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="p">)</span><span class="o">*</span><span class="mi">100</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span><span class="si">}</span><span class="s">% of the dataset"</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>No Frauds: 99.83% of the dataset
Frauds: 0.17% of the dataset
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">colors</span> <span class="o">=</span> <span class="p">[</span><span class="s">'#0101DF'</span><span class="p">,</span> <span class="s">'#DF0101'</span><span class="p">]</span>
<span class="n">sns</span><span class="p">.</span><span class="n">countplot</span><span class="p">(</span><span class="s">'Class'</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">df</span><span class="p">,</span> <span class="n">palette</span><span class="o">=</span><span class="n">colors</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">title</span><span class="p">(</span><span class="s">'Class Distributions </span><span class="se">\n</span><span class="s"> (0: No Fraud | 1: Fraud)'</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Text(0.5, 1.0, 'Class Distributions \n (0: No Fraud | 1: Fraud)')
</code></pre></div></div>

<p><img src="/myblog/images/output_20_1.png" alt="png" /></p>

<p>분포를 보면 컬럼들이 얼마나 왜곡되어 있는지 알 수 있고, 향후 이 글에서 구현될 기술로 분포의 왜곡을 줄일 수 있다.</p>

<ul>
  <li>Amount, time 분포 확인</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">18</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>

<span class="n">amount_val</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s">'Amount'</span><span class="p">].</span><span class="n">values</span>
<span class="n">time_val</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s">'Time'</span><span class="p">].</span><span class="n">values</span>

<span class="n">sns</span><span class="p">.</span><span class="n">distplot</span><span class="p">(</span><span class="n">amount_val</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="s">'r'</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">set_title</span><span class="p">(</span><span class="s">'Distribution of Transaction Amount'</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">set_xlim</span><span class="p">([</span><span class="nb">min</span><span class="p">(</span><span class="n">amount_val</span><span class="p">),</span> <span class="nb">max</span><span class="p">(</span><span class="n">amount_val</span><span class="p">)])</span>

<span class="n">sns</span><span class="p">.</span><span class="n">distplot</span><span class="p">(</span><span class="n">time_val</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="s">'b'</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="n">set_title</span><span class="p">(</span><span class="s">'Distribution of Transaction Time'</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="n">set_xlim</span><span class="p">([</span><span class="nb">min</span><span class="p">(</span><span class="n">time_val</span><span class="p">),</span> <span class="nb">max</span><span class="p">(</span><span class="n">time_val</span><span class="p">)])</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(0.0, 172792.0)
</code></pre></div></div>

<p><img src="/myblog/images/output_23_1.png" alt="png" /></p>

<p><strong>요약</strong></p>
<ul>
  <li>거래금액이 상대적으로 적다. 모든 금액의 평균은 대략 88달러였다.</li>
  <li>“Null” 값이 없으므로 결측값 처리 방법을 찾을 필요가 없다.</li>
  <li>거래의 대부분은 <strong>비사기</strong>(99.83%)였고, 나머지 0.17%가 <strong>사기</strong>였다.</li>
</ul>

<hr />

<h1 id="2-전처리-preprocessing">2. 전처리 (Preprocessing)</h1>

<h2 id="21-표준화scaling와-분포distributing">2.1 표준화(Scaling)와 분포(Distributing)</h2>
<p>이번 단계에서는 먼저 <code class="language-plaintext highlighter-rouge">Time</code>, <code class="language-plaintext highlighter-rouge">Amount</code> 컬럼을 표준화한다. 두 컬럼도 다른 컬럼들 처럼 표준화 할 필요가 있다. 한편, class의 불균형 문제를 해결하기 위해 데이터 프레임의 <code class="language-plaintext highlighter-rouge">하위 샘플(sub sample)</code>도 생성해야 하며, 이는 알고리즘이 사기 여부를 결정하는 패턴을 더 잘 이해하는데 도움을 줄 수 있다.</p>

<p><strong>하위 샘플(sub sample) 이란?</strong></p>
<ul>
  <li>우리의 하위 샘플은 사기:비사기 비율이 50:50인 데이터 프레임이 될 것이다. 즉, 우리의 하위 샘플은 동일한 양의 class를 갖는다.</li>
</ul>

<p><strong>하위 샘플을 생성하는 이유?</strong></p>
<ul>
  <li>이 글의 시작 부분에서 원본 데이터 프레임의 불균형이 심하다는 것을 알았다. 원본 데이터 프레임을 사용하면 다음과 같은 문제가 발생한다.</li>
  <li><strong>과적합:</strong> 우리의 분류 모델은 대부분의 경우 사기가 없다고 추측할 것이다. 우리가 우리 모델을 위해 원하는 것은 사기가 발생했을 때 확실한 판단을 하도록 하는 것이다.</li>
  <li><strong>잘못된 상관 관계:</strong> 비록 “V” 변수들이 무엇을 의미하는지 모르지만, 클래스와 “V” 변수 사이의 진정한 상관관계를 볼 수 없는 불균형 데이터 프레임을 가지면, 이러한 각 변수가 결과에 어떻게 영향을 미치는지 아는데 유용할 것이다.</li>
</ul>

<p><strong>요약</strong></p>
<ul>
  <li>scaled Amount, scaled Time 컬럼을 추가한다.</li>
  <li>데이터셋에는 492건의 <code class="language-plaintext highlighter-rouge">사기</code> 데이터가 있으므로 무작위로 492건의 <code class="language-plaintext highlighter-rouge">비사기</code> 데이터를 얻어 새로운 하위 데이터 프레임을 만든다.</li>
  <li>492건의 <code class="language-plaintext highlighter-rouge">사기</code> 및 <code class="language-plaintext highlighter-rouge">비사기</code> 데이터를 합쳐 새로운 하위 샘플을 만든다.</li>
</ul>

<p><br /></p>

<ul>
  <li>scaling</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span><span class="p">,</span> <span class="n">RobustScaler</span>

<span class="c1">#  RobustScaler가 이상치가 더 적게 발생한다. (less prone to outliers)
</span>
<span class="n">std_scaler</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span>
<span class="n">rob_scaler</span> <span class="o">=</span> <span class="n">RobustScaler</span><span class="p">()</span>

<span class="n">df</span><span class="p">[</span><span class="s">'scaled_amount'</span><span class="p">]</span> <span class="o">=</span> <span class="n">rob_scaler</span><span class="p">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s">'Amount'</span><span class="p">].</span><span class="n">values</span><span class="p">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
<span class="n">df</span><span class="p">[</span><span class="s">'scaled_time'</span><span class="p">]</span> <span class="o">=</span> <span class="n">rob_scaler</span><span class="p">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s">'Time'</span><span class="p">].</span><span class="n">values</span><span class="p">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>

<span class="n">df</span><span class="p">.</span><span class="n">drop</span><span class="p">([</span><span class="s">'Time'</span><span class="p">,</span> <span class="s">'Amount'</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">scaled_amount</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s">'scaled_amount'</span><span class="p">]</span>
<span class="n">scaled_time</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s">'scaled_time'</span><span class="p">]</span>

<span class="n">df</span><span class="p">.</span><span class="n">drop</span><span class="p">([</span><span class="s">'scaled_amount'</span><span class="p">,</span> <span class="s">'scaled_time'</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">df</span><span class="p">.</span><span class="n">insert</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="s">'scaled_amount'</span><span class="p">,</span> <span class="n">scaled_amount</span><span class="p">)</span>
<span class="n">df</span><span class="p">.</span><span class="n">insert</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="s">'scaled_time'</span><span class="p">,</span> <span class="n">scaled_time</span><span class="p">)</span>

<span class="n">df</span><span class="p">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div></div>

<div id="df-c3b4dd7b-9091-4502-ad16-f014986b7c56">
    <div class="colab-df-container">
      <div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>scaled_amount</th>
      <th>scaled_time</th>
      <th>V1</th>
      <th>V2</th>
      <th>V3</th>
      <th>V4</th>
      <th>V5</th>
      <th>V6</th>
      <th>V7</th>
      <th>V8</th>
      <th>...</th>
      <th>V20</th>
      <th>V21</th>
      <th>V22</th>
      <th>V23</th>
      <th>V24</th>
      <th>V25</th>
      <th>V26</th>
      <th>V27</th>
      <th>V28</th>
      <th>Class</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1.783274</td>
      <td>-0.994983</td>
      <td>-1.359807</td>
      <td>-0.072781</td>
      <td>2.536347</td>
      <td>1.378155</td>
      <td>-0.338321</td>
      <td>0.462388</td>
      <td>0.239599</td>
      <td>0.098698</td>
      <td>...</td>
      <td>0.251412</td>
      <td>-0.018307</td>
      <td>0.277838</td>
      <td>-0.110474</td>
      <td>0.066928</td>
      <td>0.128539</td>
      <td>-0.189115</td>
      <td>0.133558</td>
      <td>-0.021053</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>-0.269825</td>
      <td>-0.994983</td>
      <td>1.191857</td>
      <td>0.266151</td>
      <td>0.166480</td>
      <td>0.448154</td>
      <td>0.060018</td>
      <td>-0.082361</td>
      <td>-0.078803</td>
      <td>0.085102</td>
      <td>...</td>
      <td>-0.069083</td>
      <td>-0.225775</td>
      <td>-0.638672</td>
      <td>0.101288</td>
      <td>-0.339846</td>
      <td>0.167170</td>
      <td>0.125895</td>
      <td>-0.008983</td>
      <td>0.014724</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>4.983721</td>
      <td>-0.994972</td>
      <td>-1.358354</td>
      <td>-1.340163</td>
      <td>1.773209</td>
      <td>0.379780</td>
      <td>-0.503198</td>
      <td>1.800499</td>
      <td>0.791461</td>
      <td>0.247676</td>
      <td>...</td>
      <td>0.524980</td>
      <td>0.247998</td>
      <td>0.771679</td>
      <td>0.909412</td>
      <td>-0.689281</td>
      <td>-0.327642</td>
      <td>-0.139097</td>
      <td>-0.055353</td>
      <td>-0.059752</td>
      <td>0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>1.418291</td>
      <td>-0.994972</td>
      <td>-0.966272</td>
      <td>-0.185226</td>
      <td>1.792993</td>
      <td>-0.863291</td>
      <td>-0.010309</td>
      <td>1.247203</td>
      <td>0.237609</td>
      <td>0.377436</td>
      <td>...</td>
      <td>-0.208038</td>
      <td>-0.108300</td>
      <td>0.005274</td>
      <td>-0.190321</td>
      <td>-1.175575</td>
      <td>0.647376</td>
      <td>-0.221929</td>
      <td>0.062723</td>
      <td>0.061458</td>
      <td>0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.670579</td>
      <td>-0.994960</td>
      <td>-1.158233</td>
      <td>0.877737</td>
      <td>1.548718</td>
      <td>0.403034</td>
      <td>-0.407193</td>
      <td>0.095921</td>
      <td>0.592941</td>
      <td>-0.270533</td>
      <td>...</td>
      <td>0.408542</td>
      <td>-0.009431</td>
      <td>0.798278</td>
      <td>-0.137458</td>
      <td>0.141267</td>
      <td>-0.206010</td>
      <td>0.502292</td>
      <td>0.219422</td>
      <td>0.215153</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
<p>5 rows × 31 columns</p>
</div>
      <button class="colab-df-convert" onclick="convertToInteractive('df-c3b4dd7b-9091-4502-ad16-f014986b7c56')" title="Convert this dataframe to an interactive table." style="display:none;">

  &lt;svg xmlns="http://www.w3.org/2000/svg" height="24px"viewBox="0 0 24 24"
       width="24px"&gt;
    <path d="M0 0h24v24H0V0z" fill="none" />
    <path d="M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z" /><path d="M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z" />
  &lt;/svg&gt;
      </button>

  <style>
    .colab-df-container {
      display:flex;
      flex-wrap:wrap;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

      <script>
        const buttonEl =
          document.querySelector('#df-c3b4dd7b-9091-4502-ad16-f014986b7c56 button.colab-df-convert');
        buttonEl.style.display =
          google.colab.kernel.accessAllowed ? 'block' : 'none';

        async function convertToInteractive(key) {
          const element = document.querySelector('#df-c3b4dd7b-9091-4502-ad16-f014986b7c56');
          const dataTable =
            await google.colab.kernel.invokeFunction('convertToInteractive',
                                                     [key], {});
          if (!dataTable) return;

          const docLinkHtml = 'Like what you see? Visit the ' +
            '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
            + ' to learn more about interactive tables.';
          element.innerHTML = '';
          dataTable['output_type'] = 'display_data';
          await google.colab.output.renderOutput(dataTable, element);
          const docLink = document.createElement('div');
          docLink.innerHTML = docLinkHtml;
          element.appendChild(docLink);
        }
      </script>
    </div>
  </div>

<h2 id="22-데이터-분할-spliting-the-data">2.2 데이터 분할 (Spliting the Data)</h2>
<p>랜덤 언더샘플링 기법을 진행하기 전 원본 데이터 프레임을 분리해야 한다. 테스트로 랜덤 언더샘플링, 오버샘플링 기술을 구현할 때 데이터를 분할한다. 하지만 우리는 이 기술들에 의해 생성된 테스트셋이 아닌 원본 데이터의 테스트셋으로 모델을 평가해야한다. 모델이 패턴을 감지할 수 있도록 언더샘플, 오버샘플 데이터프레임에 모델을 학습시키고, 원본 테스트셋에서 평가하는 것이 우리의 목표이기 때문이다.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">StratifiedShuffleSplit</span>

<span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"No Frauds: </span><span class="si">{</span><span class="nb">round</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s">'Class'</span><span class="p">].</span><span class="n">value_counts</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="p">)</span><span class="o">*</span><span class="mi">100</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span><span class="si">}</span><span class="s">% of the dataset"</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Frauds: </span><span class="si">{</span><span class="nb">round</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s">'Class'</span><span class="p">].</span><span class="n">value_counts</span><span class="p">()[</span><span class="mi">1</span><span class="p">]</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="p">)</span><span class="o">*</span><span class="mi">100</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span><span class="si">}</span><span class="s">% of the dataset"</span><span class="p">)</span>
<span class="k">print</span><span class="p">()</span>

<span class="n">X</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="n">drop</span><span class="p">(</span><span class="s">'Class'</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s">'Class'</span><span class="p">]</span>

<span class="n">sss</span> <span class="o">=</span> <span class="n">StratifiedKFold</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>

<span class="c1"># train, test 분리 
</span><span class="k">for</span> <span class="n">train_index</span><span class="p">,</span> <span class="n">test_index</span> <span class="ow">in</span> <span class="n">sss</span><span class="p">.</span><span class="n">split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
  <span class="k">print</span><span class="p">(</span><span class="s">'Train:'</span><span class="p">,</span> <span class="n">train_index</span><span class="p">,</span> <span class="s">'Test:'</span><span class="p">,</span> <span class="n">test_index</span><span class="p">,)</span>
  <span class="n">original_Xtrain</span><span class="p">,</span> <span class="n">original_Xtest</span> <span class="o">=</span> <span class="n">X</span><span class="p">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">train_index</span><span class="p">],</span> <span class="n">X</span><span class="p">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">test_index</span><span class="p">]</span>
  <span class="n">original_ytrain</span><span class="p">,</span> <span class="n">original_ytest</span> <span class="o">=</span> <span class="n">y</span><span class="p">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">train_index</span><span class="p">],</span> <span class="n">y</span><span class="p">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">test_index</span><span class="p">]</span> 

<span class="c1"># array로 변환 
</span><span class="n">original_Xtrain</span> <span class="o">=</span> <span class="n">original_Xtrain</span><span class="p">.</span><span class="n">values</span>
<span class="n">original_Xtest</span> <span class="o">=</span> <span class="n">original_Xtest</span><span class="p">.</span><span class="n">values</span>
<span class="n">original_ytrain</span> <span class="o">=</span> <span class="n">original_ytrain</span><span class="p">.</span><span class="n">values</span>
<span class="n">original_ytest</span> <span class="o">=</span> <span class="n">original_ytest</span><span class="p">.</span><span class="n">values</span> 

<span class="c1"># train, test의 label 분포가 유사한지 확인한다. 
</span><span class="n">train_unique_label</span><span class="p">,</span> <span class="n">train_counts_label</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">unique</span><span class="p">(</span><span class="n">original_ytrain</span><span class="p">,</span> <span class="n">return_counts</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">test_unique_label</span><span class="p">,</span> <span class="n">test_counts_label</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">unique</span><span class="p">(</span><span class="n">original_ytest</span><span class="p">,</span> <span class="n">return_counts</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">'-'</span> <span class="o">*</span> <span class="mi">100</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="s">'Label Distribution: </span><span class="se">\n</span><span class="s">'</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">train_counts_label</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">original_ytrain</span><span class="p">))</span>
<span class="k">print</span><span class="p">(</span><span class="n">test_counts_label</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">original_ytest</span><span class="p">))</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>No Frauds: 99.83% of the dataset
Frauds: 0.17% of the dataset

Train: [ 56953  56954  56955 ... 284804 284805 284806] Test: [    0     1     2 ... 59039 59380 59968]
Train: [     0      1      2 ... 284804 284805 284806] Test: [ 56953  56954  56955 ... 113922 113923 113924]
Train: [     0      1      2 ... 284804 284805 284806] Test: [113764 113925 113926 ... 170892 170893 170894]
Train: [     0      1      2 ... 284804 284805 284806] Test: [166690 166692 167046 ... 227845 227846 227847]
Train: [     0      1      2 ... 227845 227846 227847] Test: [227429 227701 227848 ... 284804 284805 284806]
----------------------------------------------------------------------------------------------------
Label Distribution: 

[0.99827076 0.00172924]
[0.99827952 0.00172048]
</code></pre></div></div>

<p>* 5-fold로 데이터셋을 나누는 for문에서 계속 덮어씌우도록 작성을 하고 결국 마지막 데이터셋만 사용한다. 뒤에서도 이러는데 이렇게 작성한 이유가 궁금하다. <br />
* -&gt; 댓글에서 같은 질문이 있는데 작성자님이 오류인 것 같고 혼란스럽다고 했지만 아직 해결은 안 난 것 같다.</p>

<h1 id="3랜덤-언더-샘플링under-sampling-및-오버-샘플링over-sampling">3.랜덤 언더 샘플링(Under Sampling) 및 오버 샘플링(Over Sampling)</h1>

<p>균형 잡힌 데이터셋을 생성하기 위해, 데이터를 제거하여 모델의 과적합을 방지하는 <code class="language-plaintext highlighter-rouge">"랜덤 언더샘플링 (Random Under-Sampling)"</code>을 구현한다.</p>

<p><strong>단계</strong><br />
1) 우리의 클래스가 얼마나 불균형한지 결정한다. (클래스 컬럼에 <code class="language-plaintext highlighter-rouge">value_counts</code> 함수를 적용)<br />
2) 사기 거래의 개수에 맞춰 사기 492, 비사기 492건으로 만든다. (50:50) 이를 통해 클래스에 대한 50:50 비율의 하위 샘플을 갖게된다.<br />
3) 이 스크립트를 실행할 때마다 모델이 특정 정확도를 유지할 수 있는지 확인하기 위해 데이터를 섞는다.</p>

<dl>
  <dt><strong>참고</strong></dt>
  <dd>랜덤 언더샘플링 (Random Under-Sampling)의 주요 문제는 정보 손실이 크다는 것이다. 때문에 분류 모델이 원하는 만큼 정확하게 학습되지 않을 위험이 존재한다. (284,315개의 비사기 거래 중 492개의 비사기 거래만을 사용하게 된다.)</dd>
</dl>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">print</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s">'Class'</span><span class="p">].</span><span class="n">value_counts</span><span class="p">())</span>

<span class="c1"># 하위 샘플(sub sample) 생성 전 데이터 섞기 
</span><span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="n">sample</span><span class="p">(</span><span class="n">frac</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="c1"># 사기 class, 비사기 class 비율 50:50인 데이터프레임 생성 
</span><span class="n">fraud_df</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="n">loc</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="s">'Class'</span><span class="p">]</span><span class="o">==</span><span class="mi">1</span><span class="p">]</span>
<span class="n">non_fraud_df</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="n">loc</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="s">'Class'</span><span class="p">]</span><span class="o">==</span><span class="mi">0</span><span class="p">][:</span><span class="mi">492</span><span class="p">]</span>

<span class="n">normal_distributed_df</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">concat</span><span class="p">([</span><span class="n">fraud_df</span><span class="p">,</span> <span class="n">non_fraud_df</span><span class="p">])</span>

<span class="c1"># 데이터프레임 섞기 
</span><span class="n">new_df</span> <span class="o">=</span> <span class="n">normal_distributed_df</span><span class="p">.</span><span class="n">sample</span><span class="p">(</span><span class="n">frac</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>

<span class="n">new_df</span><span class="p">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>0    284315
1       492
Name: Class, dtype: int64
</code></pre></div></div>

<div id="df-4c7ff76c-5f04-4b68-b537-3ef506e437c7">
    <div class="colab-df-container">
      <div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>scaled_amount</th>
      <th>scaled_time</th>
      <th>V1</th>
      <th>V2</th>
      <th>V3</th>
      <th>V4</th>
      <th>V5</th>
      <th>V6</th>
      <th>V7</th>
      <th>V8</th>
      <th>...</th>
      <th>V20</th>
      <th>V21</th>
      <th>V22</th>
      <th>V23</th>
      <th>V24</th>
      <th>V25</th>
      <th>V26</th>
      <th>V27</th>
      <th>V28</th>
      <th>Class</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>281645</th>
      <td>-0.279746</td>
      <td>1.006074</td>
      <td>0.669369</td>
      <td>0.802239</td>
      <td>-0.548859</td>
      <td>-0.461751</td>
      <td>1.103532</td>
      <td>-0.877397</td>
      <td>1.152531</td>
      <td>-0.446391</td>
      <td>...</td>
      <td>-0.052753</td>
      <td>-0.294856</td>
      <td>-0.573588</td>
      <td>0.208144</td>
      <td>0.651524</td>
      <td>-0.988035</td>
      <td>-0.034410</td>
      <td>-0.142753</td>
      <td>-0.182496</td>
      <td>0</td>
    </tr>
    <tr>
      <th>151006</th>
      <td>-0.293440</td>
      <td>0.113606</td>
      <td>-26.457745</td>
      <td>16.497472</td>
      <td>-30.177317</td>
      <td>8.904157</td>
      <td>-17.892600</td>
      <td>-1.227904</td>
      <td>-31.197329</td>
      <td>-11.438920</td>
      <td>...</td>
      <td>2.812241</td>
      <td>-8.755698</td>
      <td>3.460893</td>
      <td>0.896538</td>
      <td>0.254836</td>
      <td>-0.738097</td>
      <td>-0.966564</td>
      <td>-7.263482</td>
      <td>-1.324884</td>
      <td>1</td>
    </tr>
    <tr>
      <th>252962</th>
      <td>1.935304</td>
      <td>0.838179</td>
      <td>1.608340</td>
      <td>-0.833553</td>
      <td>-0.234511</td>
      <td>0.494109</td>
      <td>-1.133410</td>
      <td>-0.810632</td>
      <td>-0.350734</td>
      <td>-0.003276</td>
      <td>...</td>
      <td>0.028270</td>
      <td>0.049013</td>
      <td>-0.153223</td>
      <td>0.282484</td>
      <td>0.478331</td>
      <td>-0.554943</td>
      <td>-1.001841</td>
      <td>0.020994</td>
      <td>-0.005208</td>
      <td>0</td>
    </tr>
    <tr>
      <th>252124</th>
      <td>-0.296653</td>
      <td>0.833774</td>
      <td>-1.928613</td>
      <td>4.601506</td>
      <td>-7.124053</td>
      <td>5.716088</td>
      <td>1.026579</td>
      <td>-3.189073</td>
      <td>-2.261897</td>
      <td>1.185096</td>
      <td>...</td>
      <td>0.328796</td>
      <td>0.602291</td>
      <td>-0.541287</td>
      <td>-0.354639</td>
      <td>-0.701492</td>
      <td>-0.030973</td>
      <td>0.034070</td>
      <td>0.573393</td>
      <td>0.294686</td>
      <td>1</td>
    </tr>
    <tr>
      <th>56703</th>
      <td>-0.296793</td>
      <td>-0.436413</td>
      <td>1.176716</td>
      <td>0.557091</td>
      <td>-0.490800</td>
      <td>0.756424</td>
      <td>0.249192</td>
      <td>-0.781871</td>
      <td>0.228750</td>
      <td>-0.040840</td>
      <td>...</td>
      <td>-0.102772</td>
      <td>-0.062166</td>
      <td>-0.128168</td>
      <td>-0.040176</td>
      <td>0.110040</td>
      <td>0.437891</td>
      <td>0.368809</td>
      <td>-0.018287</td>
      <td>0.031173</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
<p>5 rows × 31 columns</p>
</div>
      <button class="colab-df-convert" onclick="convertToInteractive('df-4c7ff76c-5f04-4b68-b537-3ef506e437c7')" title="Convert this dataframe to an interactive table." style="display:none;">

  &lt;svg xmlns="http://www.w3.org/2000/svg" height="24px"viewBox="0 0 24 24"
       width="24px"&gt;
    <path d="M0 0h24v24H0V0z" fill="none" />
    <path d="M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z" /><path d="M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z" />
  &lt;/svg&gt;
      </button>

  <style>
    .colab-df-container {
      display:flex;
      flex-wrap:wrap;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

      <script>
        const buttonEl =
          document.querySelector('#df-4c7ff76c-5f04-4b68-b537-3ef506e437c7 button.colab-df-convert');
        buttonEl.style.display =
          google.colab.kernel.accessAllowed ? 'block' : 'none';

        async function convertToInteractive(key) {
          const element = document.querySelector('#df-4c7ff76c-5f04-4b68-b537-3ef506e437c7');
          const dataTable =
            await google.colab.kernel.invokeFunction('convertToInteractive',
                                                     [key], {});
          if (!dataTable) return;

          const docLinkHtml = 'Like what you see? Visit the ' +
            '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
            + ' to learn more about interactive tables.';
          element.innerHTML = '';
          dataTable['output_type'] = 'display_data';
          await google.colab.output.renderOutput(dataTable, element);
          const docLink = document.createElement('div');
          docLink.innerHTML = docLinkHtml;
          element.appendChild(docLink);
        }
      </script>
    </div>
  </div>

<h2 id="31-분포distributing-및-상관-관계correlating">3.1 분포(Distributing) 및 상관 관계(Correlating)</h2>
<p>이제 데이터 프레임의 균형을 올바르게 맞추었으므로, 분석 및 데이터 전처리를 더 진행할 수 있다.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">print</span><span class="p">(</span><span class="s">'Distribution of the Classes in the subsample dataset'</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">new_df</span><span class="p">[</span><span class="s">'Class'</span><span class="p">].</span><span class="n">value_counts</span><span class="p">()</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">new_df</span><span class="p">))</span>

<span class="n">sns</span><span class="p">.</span><span class="n">countplot</span><span class="p">(</span><span class="s">'Class'</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">new_df</span><span class="p">,</span> <span class="n">palette</span><span class="o">=</span><span class="n">colors</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">title</span><span class="p">(</span><span class="s">'Equally Distribution Classes'</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Distribution of the Classes in the subsample dataset
0    0.5
1    0.5
Name: Class, dtype: float64
</code></pre></div></div>

<p><img src="/myblog/images/output_37_1.png" alt="png" /></p>

<p><strong>상관 행렬(correlation Matrices)</strong></p>
<ul>
  <li>상관 행렬은 우리의 데이터를 이해하는 본질이다. 특정 거래가 사기인지 여부에 큰 영향을 미치는 변수가 있는지 분석해야 한다. 사기 거래와 관련하여 어떤 변수가 높은 양 또는 음의 상관관계를 가지고 있는지 확인하기 위해 올바른 데이터프레임 (하위 샘플)을 사용하는 것이 중요하다.</li>
</ul>

<p><strong>참고</strong></p>
<ul>
  <li>우리는 상관 행렬에서 하위 샘플(sub sample)을 사용해야 한다. 그렇지 않으면 원본 데이터 프레임의 높은 클래스 불균형으로 인해 문제점이 생긴다. 원본 데이터 프레임을 사용한다면, 우리의 상관 행렬이 우리 클래스 사이의 높은 불균형에 의해 영향을 받을 것이다.</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">f</span><span class="p">,</span> <span class="p">(</span><span class="n">ax1</span><span class="p">,</span> <span class="n">ax2</span><span class="p">)</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">24</span><span class="p">,</span> <span class="mi">20</span><span class="p">))</span>

<span class="n">corr</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="n">corr</span><span class="p">()</span>
<span class="n">sns</span><span class="p">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">corr</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s">'coolwarm_r'</span><span class="p">,</span> <span class="n">annot_kws</span><span class="o">=</span><span class="p">{</span><span class="s">'size'</span><span class="p">:</span><span class="mi">20</span><span class="p">},</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax1</span><span class="p">)</span>
<span class="n">ax1</span><span class="p">.</span><span class="n">set_title</span><span class="p">(</span><span class="s">"Imbalanced Correlation Matrix </span><span class="se">\n</span><span class="s"> (don't use for reference)"</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>

<span class="n">sub_sample_corr</span> <span class="o">=</span> <span class="n">new_df</span><span class="p">.</span><span class="n">corr</span><span class="p">()</span>
<span class="n">sns</span><span class="p">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">sub_sample_corr</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s">'coolwarm_r'</span><span class="p">,</span> <span class="n">annot_kws</span><span class="o">=</span><span class="p">{</span><span class="s">'size'</span><span class="p">:</span><span class="mi">20</span><span class="p">},</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax2</span><span class="p">)</span>
<span class="n">ax2</span><span class="p">.</span><span class="n">set_title</span><span class="p">(</span><span class="s">'SubSample  Correlation Matrix </span><span class="se">\n</span><span class="s"> (use for reference)'</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div>

<p><img src="/myblog/images/output_39_0.png" alt="png" /></p>

<ul>
  <li>boxplot</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># 클래스와 음의 상관관계인 변수들의 boxplot: 변수의 값이 작을수록 사기 클래스일 가능성이 높다. 
</span><span class="n">f</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">ncols</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>

<span class="n">sns</span><span class="p">.</span><span class="n">boxplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s">'Class'</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s">'V17'</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">new_df</span><span class="p">,</span> <span class="n">palette</span><span class="o">=</span><span class="n">colors</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">set_title</span><span class="p">(</span><span class="s">'V17 vs Class Negative Correlation'</span><span class="p">)</span>

<span class="n">sns</span><span class="p">.</span><span class="n">boxplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s">'Class'</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s">'V14'</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">new_df</span><span class="p">,</span> <span class="n">palette</span><span class="o">=</span><span class="n">colors</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="n">set_title</span><span class="p">(</span><span class="s">'V14 vs Class Negative Correlation'</span><span class="p">)</span>

<span class="n">sns</span><span class="p">.</span><span class="n">boxplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s">'Class'</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s">'V12'</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">new_df</span><span class="p">,</span> <span class="n">palette</span><span class="o">=</span><span class="n">colors</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">axes</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">2</span><span class="p">].</span><span class="n">set_title</span><span class="p">(</span><span class="s">'V12 vs Class Negative Correlation'</span><span class="p">)</span>

<span class="n">sns</span><span class="p">.</span><span class="n">boxplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s">'Class'</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s">'V10'</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">new_df</span><span class="p">,</span> <span class="n">palette</span><span class="o">=</span><span class="n">colors</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">axes</span><span class="p">[</span><span class="mi">3</span><span class="p">])</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">3</span><span class="p">].</span><span class="n">set_title</span><span class="p">(</span><span class="s">'V10 vs Class Negative Correlation'</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Text(0.5, 1.0, 'V10 vs Class Negative Correlation')
</code></pre></div></div>

<p><img src="/myblog/images/output_41_1.png" alt="png" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># 클래스와 양의 상관관계인 변수들의 boxplot: 변수의 값이 클수록 사기 클래스일 가능성이 높다. 
</span><span class="n">f</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">ncols</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>

<span class="n">sns</span><span class="p">.</span><span class="n">boxplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s">'Class'</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s">'V11'</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">new_df</span><span class="p">,</span> <span class="n">palette</span><span class="o">=</span><span class="n">colors</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">set_title</span><span class="p">(</span><span class="s">'V11 vs Class Negative Correlation'</span><span class="p">)</span>

<span class="n">sns</span><span class="p">.</span><span class="n">boxplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s">'Class'</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s">'V4'</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">new_df</span><span class="p">,</span> <span class="n">palette</span><span class="o">=</span><span class="n">colors</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="n">set_title</span><span class="p">(</span><span class="s">'V4 vs Class Negative Correlation'</span><span class="p">)</span>

<span class="n">sns</span><span class="p">.</span><span class="n">boxplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s">'Class'</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s">'V2'</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">new_df</span><span class="p">,</span> <span class="n">palette</span><span class="o">=</span><span class="n">colors</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">axes</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">2</span><span class="p">].</span><span class="n">set_title</span><span class="p">(</span><span class="s">'V2 vs Class Negative Correlation'</span><span class="p">)</span>

<span class="n">sns</span><span class="p">.</span><span class="n">boxplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s">'Class'</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s">'V19'</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">new_df</span><span class="p">,</span> <span class="n">palette</span><span class="o">=</span><span class="n">colors</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">axes</span><span class="p">[</span><span class="mi">3</span><span class="p">])</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">3</span><span class="p">].</span><span class="n">set_title</span><span class="p">(</span><span class="s">'V19 vs Class Negative Correlation'</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Text(0.5, 1.0, 'V19 vs Class Negative Correlation')
</code></pre></div></div>

<p><img src="/myblog/images/output_42_1.png" alt="png" /></p>

<p><strong>요약 및 설명</strong></p>
<ul>
  <li>음의 상관: V17, V14, V12 및 V10은 음의 상관 관계입니다. 이러한 값이 얼마나 낮을수록 최종 결과는 부정 거래일 가능성이 더 높습니다.</li>
  <li>양의 상관: V2, V4, V11 및 V19는 양의 상관 관계에 있습니다. 이러한 값이 얼마나 높을수록 최종 결과는 부정 거래일 가능성이 더 높습니다.</li>
  <li>상자 그림: 우리는 상자 그림을 사용하여 부정 행위 및 비부정 행위에서 이러한 특징의 분포를 더 잘 이해할 것이다.</li>
</ul>

<h2 id="32-이상-탐지anomaly-detection">3.2 이상 탐지(Anomaly Detection)</h2>
<p>클래스와의 상관관계가 높은 변수에서 <code class="language-plaintext highlighter-rouge">"극한 이상치 (extreme outliers)</code>를 제거하는 것이 목표이다. 이는 우리 모델의 정확도에 긍정적인 영향을 미칠 것이다.</p>

<p><br /></p>

<p><strong>이상치 탐지 방법</strong></p>
<ul>
  <li>Interquartile Range(IQR): 우리는 제3사분위수와 제1사분위수의 차이로 IQR를 계산한다. 우리의 목표는 제3사분위수와 제2사분위수를 초과하는 임계값을 만드는 것이다. 일부 인스턴스가 이 임계값을 초과할 경우 삭제될 것이다.</li>
  <li>Boxplots: 제1사분위수와 제3사분위수(제곱의 양쪽 끝)를 쉽게 볼 수 있을 뿐만 아니라 극단 특이치(하위 및 상위 극한을 벗어난 점)도 쉽게 볼 수 있다.</li>
</ul>

<p><strong>Outlier Removal Tradeoff</strong></p>
<ul>
  <li>특이치를 제거하기 위한 임계값이 어디까지인지 주의해야한다. 숫자(예: 1.5)에 (사분위수 범위)를 곱하여 임계값을 결정한다. 이 임계값이 높을수록 이상치는 더 적게 탐지되고(높은 수 ex: 3을 곱함) 이 임계값이 낮을수록 더 많은 특이치를 탐지한다.</li>
  <li>the tradeoff: 임계값이 낮을수록 이상치가 더 많이 제거되지만, 우리는 이상치보다 “극한 이상치”에 더 초점을 맞추도록 한다. 우리의 모델이 더 낮은 정확도를 갖게 될 정보 손실의 위험을 최소화하기 위함이다. 이 임계값을 사용하여 분류 모델의 정확도에 어떤 영향을 미치는지 확인할 수 있다.</li>
</ul>

<p><strong>요약</strong></p>
<ul>
  <li>분포 시각화: 먼저 일부 이상치를 제거하는 데 사용할 형상의 분포를 시각화 한다.</li>
  <li>임계값 결정: IQR을 곱하기 위해 사용할 숫자를 결정한 후(더 적은 이상치가 제거될수록) Q25 - 임계값(하한 극단 임계값)을 기판으로 하고 Q75 + 임계값(상한 극단 임계값)을 추가하여 상한 및 하한 임계값을 결정하는 작업을 진행한다.</li>
  <li>조건부 드롭: 마지막으로 양쪽 극단에서 “임계값”을 초과하면 인스턴스가 제거된다는 조건부 드롭을 생성한다.</li>
  <li>상자 그림 표현: 상자 그림을 통해 “극한 이상치”의 수가 상당한 양으로 감소했음을 시각화한다.</li>
</ul>

<p><strong>참고</strong></p>
<ul>
  <li>특이치 감소를 구현한 후 정확도가 3% 이상 향상되었다. 일부 특이치는 모델의 정확도를 왜곡할 수 있지만, 극단적인 양의 정보 손실을 피해야 합니다. 그렇지 않으면 모델이 적합하지 않을 위험이 있다.</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">scipy.stats</span> <span class="kn">import</span> <span class="n">norm</span> 

<span class="n">f</span><span class="p">,</span> <span class="p">(</span><span class="n">ax1</span><span class="p">,</span> <span class="n">ax2</span><span class="p">,</span> <span class="n">ax3</span><span class="p">)</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>

<span class="n">v14_fraud_dist</span> <span class="o">=</span> <span class="n">new_df</span><span class="p">[</span><span class="s">'V14'</span><span class="p">].</span><span class="n">loc</span><span class="p">[</span><span class="n">new_df</span><span class="p">[</span><span class="s">'Class'</span><span class="p">]</span><span class="o">==</span><span class="mi">1</span><span class="p">].</span><span class="n">values</span> 
<span class="n">sns</span><span class="p">.</span><span class="n">distplot</span><span class="p">(</span><span class="n">v14_fraud_dist</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax1</span><span class="p">,</span> <span class="n">fit</span><span class="o">=</span><span class="n">norm</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s">'#FB8861'</span><span class="p">)</span>
<span class="n">ax1</span><span class="p">.</span><span class="n">set_title</span><span class="p">(</span><span class="s">'V14 Distribution </span><span class="se">\n</span><span class="s"> (Fraud Transactions)'</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>

<span class="n">v12_fraud_dist</span> <span class="o">=</span> <span class="n">new_df</span><span class="p">[</span><span class="s">'V12'</span><span class="p">].</span><span class="n">loc</span><span class="p">[</span><span class="n">new_df</span><span class="p">[</span><span class="s">'Class'</span><span class="p">]</span><span class="o">==</span><span class="mi">1</span><span class="p">].</span><span class="n">values</span> 
<span class="n">sns</span><span class="p">.</span><span class="n">distplot</span><span class="p">(</span><span class="n">v12_fraud_dist</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax2</span><span class="p">,</span> <span class="n">fit</span><span class="o">=</span><span class="n">norm</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s">'#56F9BB'</span><span class="p">)</span>
<span class="n">ax2</span><span class="p">.</span><span class="n">set_title</span><span class="p">(</span><span class="s">'V14 Distribution </span><span class="se">\n</span><span class="s"> (Fraud Transactions)'</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>

<span class="n">v10_fraud_dist</span> <span class="o">=</span> <span class="n">new_df</span><span class="p">[</span><span class="s">'V10'</span><span class="p">].</span><span class="n">loc</span><span class="p">[</span><span class="n">new_df</span><span class="p">[</span><span class="s">'Class'</span><span class="p">]</span><span class="o">==</span><span class="mi">1</span><span class="p">].</span><span class="n">values</span> 
<span class="n">sns</span><span class="p">.</span><span class="n">distplot</span><span class="p">(</span><span class="n">v10_fraud_dist</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax3</span><span class="p">,</span> <span class="n">fit</span><span class="o">=</span><span class="n">norm</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s">'#C5B3F9'</span><span class="p">)</span>
<span class="n">ax1</span><span class="p">.</span><span class="n">set_title</span><span class="p">(</span><span class="s">'V10 Distribution </span><span class="se">\n</span><span class="s"> (Fraud Transactions)'</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Text(0.5, 1.0, 'V10 Distribution \n (Fraud Transactions)')
</code></pre></div></div>

<p><img src="/myblog/images/output_45_1.png" alt="png" /></p>

<p>V14는 변수 V12 및 V10에 비해 가우스 분포를 갖는 유일한 변수이다.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># V14 변수의 이상치 제거 (가장 높은 음의 상관관계를 가진 변수)
</span><span class="n">v14_fraud</span> <span class="o">=</span> <span class="n">new_df</span><span class="p">[</span><span class="s">'V14'</span><span class="p">].</span><span class="n">loc</span><span class="p">[</span><span class="n">new_df</span><span class="p">[</span><span class="s">'Class'</span><span class="p">]</span><span class="o">==</span><span class="mi">1</span><span class="p">].</span><span class="n">values</span> 
<span class="n">q25</span><span class="p">,</span> <span class="n">q75</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">percentile</span><span class="p">(</span><span class="n">v14_fraud</span><span class="p">,</span> <span class="mi">25</span><span class="p">),</span> <span class="n">np</span><span class="p">.</span><span class="n">percentile</span><span class="p">(</span><span class="n">v14_fraud</span><span class="p">,</span> <span class="mi">75</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">'Quartile 25: {} | Quartile 75: {}'</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">q25</span><span class="p">,</span> <span class="n">q75</span><span class="p">))</span>
<span class="n">v14_iqr</span> <span class="o">=</span> <span class="n">q75</span> <span class="o">-</span> <span class="n">q25</span>
<span class="k">print</span><span class="p">(</span><span class="s">'iqr{}'</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">v14_iqr</span><span class="p">))</span>

<span class="n">v14_cut_off</span> <span class="o">=</span> <span class="n">v14_iqr</span> <span class="o">*</span> <span class="mf">1.5</span>
<span class="n">v14_lower</span><span class="p">,</span> <span class="n">v14_upper</span> <span class="o">=</span> <span class="n">q25</span> <span class="o">-</span> <span class="n">v14_cut_off</span><span class="p">,</span> <span class="n">q75</span> <span class="o">+</span> <span class="n">v14_cut_off</span>  
<span class="k">print</span><span class="p">(</span><span class="s">'Cut off: {}'</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">v14_cut_off</span><span class="p">))</span>
<span class="k">print</span><span class="p">(</span><span class="s">'V14 Lower: {}'</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">v14_lower</span><span class="p">))</span>
<span class="k">print</span><span class="p">(</span><span class="s">'V14 Upper: {}'</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">v14_upper</span><span class="p">))</span>

<span class="n">outliers</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">v14_fraud</span> <span class="k">if</span> <span class="n">x</span> <span class="o">&lt;</span> <span class="n">v14_lower</span> <span class="ow">or</span> <span class="n">x</span> <span class="o">&gt;</span> <span class="n">v14_upper</span><span class="p">]</span>
<span class="k">print</span><span class="p">(</span><span class="s">"Feature V14 Outliers for Fraud Cases: {}"</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">outliers</span><span class="p">)))</span>
<span class="k">print</span><span class="p">(</span><span class="s">"V14 outliers:{}"</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">outliers</span><span class="p">))</span>

<span class="n">new_df</span> <span class="o">=</span> <span class="n">new_df</span><span class="p">.</span><span class="n">drop</span><span class="p">(</span><span class="n">new_df</span><span class="p">[(</span><span class="n">new_df</span><span class="p">[</span><span class="s">'V14'</span><span class="p">]</span> <span class="o">&gt;</span> <span class="n">v14_upper</span><span class="p">)</span> <span class="o">|</span> <span class="p">(</span><span class="n">new_df</span><span class="p">[</span><span class="s">'V14'</span><span class="p">]</span> <span class="o">&lt;</span> <span class="n">v14_lower</span><span class="p">)].</span><span class="n">index</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">'Number of Instances after outliers removal: {}'</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">new_df</span><span class="p">)))</span>
<span class="k">print</span><span class="p">(</span><span class="s">'-'</span> <span class="o">*</span> <span class="mi">100</span><span class="p">)</span>


<span class="c1"># V12 변수의 이상치 제거 
</span><span class="n">v12_fraud</span> <span class="o">=</span> <span class="n">new_df</span><span class="p">[</span><span class="s">'V12'</span><span class="p">].</span><span class="n">loc</span><span class="p">[</span><span class="n">new_df</span><span class="p">[</span><span class="s">'Class'</span><span class="p">]</span><span class="o">==</span><span class="mi">1</span><span class="p">].</span><span class="n">values</span> 
<span class="n">q25</span><span class="p">,</span> <span class="n">q75</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">percentile</span><span class="p">(</span><span class="n">v12_fraud</span><span class="p">,</span> <span class="mi">25</span><span class="p">),</span> <span class="n">np</span><span class="p">.</span><span class="n">percentile</span><span class="p">(</span><span class="n">v12_fraud</span><span class="p">,</span> <span class="mi">75</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">'Quartile 25: {} | Quartile 75: {}'</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">q25</span><span class="p">,</span> <span class="n">q75</span><span class="p">))</span>
<span class="n">v12_iqr</span> <span class="o">=</span> <span class="n">q75</span> <span class="o">-</span> <span class="n">q25</span>
<span class="k">print</span><span class="p">(</span><span class="s">'iqr{}'</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">v12_iqr</span><span class="p">))</span>

<span class="n">v12_cut_off</span> <span class="o">=</span> <span class="n">v12_iqr</span> <span class="o">*</span> <span class="mf">1.5</span>
<span class="n">v12_lower</span><span class="p">,</span> <span class="n">v12_upper</span> <span class="o">=</span> <span class="n">q25</span> <span class="o">-</span> <span class="n">v12_cut_off</span><span class="p">,</span> <span class="n">q75</span> <span class="o">+</span> <span class="n">v12_cut_off</span>  
<span class="k">print</span><span class="p">(</span><span class="s">'Cut off: {}'</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">v12_cut_off</span><span class="p">))</span>
<span class="k">print</span><span class="p">(</span><span class="s">'V12 Lower: {}'</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">v12_lower</span><span class="p">))</span>
<span class="k">print</span><span class="p">(</span><span class="s">'V12 Upper: {}'</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">v12_upper</span><span class="p">))</span>

<span class="n">outliers</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">v12_fraud</span> <span class="k">if</span> <span class="n">x</span> <span class="o">&lt;</span> <span class="n">v12_lower</span> <span class="ow">or</span> <span class="n">x</span> <span class="o">&gt;</span> <span class="n">v12_upper</span><span class="p">]</span>
<span class="k">print</span><span class="p">(</span><span class="s">"Feature V12 Outliers for Fraud Cases: {}"</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">outliers</span><span class="p">)))</span>
<span class="k">print</span><span class="p">(</span><span class="s">"V12 outliers:{}"</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">outliers</span><span class="p">))</span>

<span class="n">new_df</span> <span class="o">=</span> <span class="n">new_df</span><span class="p">.</span><span class="n">drop</span><span class="p">(</span><span class="n">new_df</span><span class="p">[(</span><span class="n">new_df</span><span class="p">[</span><span class="s">'V12'</span><span class="p">]</span> <span class="o">&gt;</span> <span class="n">v12_upper</span><span class="p">)</span> <span class="o">|</span> <span class="p">(</span><span class="n">new_df</span><span class="p">[</span><span class="s">'V12'</span><span class="p">]</span> <span class="o">&lt;</span> <span class="n">v12_lower</span><span class="p">)].</span><span class="n">index</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">'Number of Instances after outliers removal: {}'</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">new_df</span><span class="p">)))</span>
<span class="k">print</span><span class="p">(</span><span class="s">'-'</span> <span class="o">*</span> <span class="mi">100</span><span class="p">)</span>


<span class="c1"># V10 변수의 이상치 제거 
</span><span class="n">v10_fraud</span> <span class="o">=</span> <span class="n">new_df</span><span class="p">[</span><span class="s">'V10'</span><span class="p">].</span><span class="n">loc</span><span class="p">[</span><span class="n">new_df</span><span class="p">[</span><span class="s">'Class'</span><span class="p">]</span><span class="o">==</span><span class="mi">1</span><span class="p">].</span><span class="n">values</span> 
<span class="n">q25</span><span class="p">,</span> <span class="n">q75</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">percentile</span><span class="p">(</span><span class="n">v10_fraud</span><span class="p">,</span> <span class="mi">25</span><span class="p">),</span> <span class="n">np</span><span class="p">.</span><span class="n">percentile</span><span class="p">(</span><span class="n">v10_fraud</span><span class="p">,</span> <span class="mi">75</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">'Quartile 25: {} | Quartile 75: {}'</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">q25</span><span class="p">,</span> <span class="n">q75</span><span class="p">))</span>
<span class="n">v10_iqr</span> <span class="o">=</span> <span class="n">q75</span> <span class="o">-</span> <span class="n">q25</span>
<span class="k">print</span><span class="p">(</span><span class="s">'iqr{}'</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">v10_iqr</span><span class="p">))</span>

<span class="n">v10_cut_off</span> <span class="o">=</span> <span class="n">v10_iqr</span> <span class="o">*</span> <span class="mf">1.5</span>
<span class="n">v10_lower</span><span class="p">,</span> <span class="n">v10_upper</span> <span class="o">=</span> <span class="n">q25</span> <span class="o">-</span> <span class="n">v10_cut_off</span><span class="p">,</span> <span class="n">q75</span> <span class="o">+</span> <span class="n">v10_cut_off</span>  
<span class="k">print</span><span class="p">(</span><span class="s">'Cut off: {}'</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">v10_cut_off</span><span class="p">))</span>
<span class="k">print</span><span class="p">(</span><span class="s">'V10 Lower: {}'</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">v10_lower</span><span class="p">))</span>
<span class="k">print</span><span class="p">(</span><span class="s">'V10 Upper: {}'</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">v10_upper</span><span class="p">))</span>

<span class="n">outliers</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">v10_fraud</span> <span class="k">if</span> <span class="n">x</span> <span class="o">&lt;</span> <span class="n">v10_lower</span> <span class="ow">or</span> <span class="n">x</span> <span class="o">&gt;</span> <span class="n">v10_upper</span><span class="p">]</span>
<span class="k">print</span><span class="p">(</span><span class="s">"Feature V10 Outliers for Fraud Cases: {}"</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">outliers</span><span class="p">)))</span>
<span class="k">print</span><span class="p">(</span><span class="s">"V10 outliers:{}"</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">outliers</span><span class="p">))</span>

<span class="n">new_df</span> <span class="o">=</span> <span class="n">new_df</span><span class="p">.</span><span class="n">drop</span><span class="p">(</span><span class="n">new_df</span><span class="p">[(</span><span class="n">new_df</span><span class="p">[</span><span class="s">'V10'</span><span class="p">]</span> <span class="o">&gt;</span> <span class="n">v10_upper</span><span class="p">)</span> <span class="o">|</span> <span class="p">(</span><span class="n">new_df</span><span class="p">[</span><span class="s">'V10'</span><span class="p">]</span> <span class="o">&lt;</span> <span class="n">v10_lower</span><span class="p">)].</span><span class="n">index</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">'Number of Instances after outliers removal: {}'</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">new_df</span><span class="p">)))</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Quartile 25: -9.692722964972386 | Quartile 75: -4.282820849486865
iqr5.409902115485521
Cut off: 8.114853173228282
V14 Lower: -17.807576138200666
V14 Upper: 3.8320323237414167
Feature V14 Outliers for Fraud Cases: 4
V14 outliers:[-18.0499976898594, -18.8220867423816, -18.4937733551053, -19.2143254902614]
Number of Instances after outliers removal: 980
----------------------------------------------------------------------------------------------------
Quartile 25: -8.67303320439115 | Quartile 75: -2.893030568676315
iqr5.780002635714835
Cut off: 8.670003953572252
V12 Lower: -17.3430371579634
V12 Upper: 5.776973384895937
Feature V12 Outliers for Fraud Cases: 4
V12 outliers:[-18.4311310279993, -18.5536970096458, -18.6837146333443, -18.0475965708216]
Number of Instances after outliers removal: 976
----------------------------------------------------------------------------------------------------
Quartile 25: -7.466658535821847 | Quartile 75: -2.5118611381562523
iqr4.954797397665595
Cut off: 7.432196096498393
V10 Lower: -14.89885463232024
V10 Upper: 4.92033495834214
Feature V10 Outliers for Fraud Cases: 27
V10 outliers:[-22.1870885620007, -24.5882624372475, -15.1241628144947, -19.836148851696, -15.5637913387301, -15.3460988468775, -16.3035376590131, -23.2282548357516, -16.2556117491401, -22.1870885620007, -16.7460441053944, -18.2711681738888, -18.9132433348732, -15.2399619587112, -24.4031849699728, -16.6496281595399, -17.1415136412892, -15.5637913387301, -22.1870885620007, -14.9246547735487, -20.9491915543611, -15.1237521803455, -16.6011969664137, -15.2399619587112, -14.9246547735487, -22.1870885620007, -15.2318333653018]
Number of Instances after outliers removal: 945
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">f</span><span class="p">,(</span><span class="n">ax1</span><span class="p">,</span> <span class="n">ax2</span><span class="p">,</span> <span class="n">ax3</span><span class="p">)</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span><span class="mi">6</span><span class="p">))</span>

<span class="n">colors</span> <span class="o">=</span> <span class="p">[</span><span class="s">'#B3F9C5'</span><span class="p">,</span> <span class="s">'#f9c5b3'</span><span class="p">]</span>
<span class="c1"># Boxplots with outliers removed
# Feature V14
</span><span class="n">sns</span><span class="p">.</span><span class="n">boxplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s">"Class"</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s">"V14"</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">new_df</span><span class="p">,</span><span class="n">ax</span><span class="o">=</span><span class="n">ax1</span><span class="p">,</span> <span class="n">palette</span><span class="o">=</span><span class="n">colors</span><span class="p">)</span>
<span class="n">ax1</span><span class="p">.</span><span class="n">set_title</span><span class="p">(</span><span class="s">"V14 Feature </span><span class="se">\n</span><span class="s"> Reduction of outliers"</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>
<span class="n">ax1</span><span class="p">.</span><span class="n">annotate</span><span class="p">(</span><span class="s">'Fewer extreme </span><span class="se">\n</span><span class="s"> outliers'</span><span class="p">,</span> <span class="n">xy</span><span class="o">=</span><span class="p">(</span><span class="mf">0.98</span><span class="p">,</span> <span class="o">-</span><span class="mf">17.8</span><span class="p">),</span> <span class="n">xytext</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="o">-</span><span class="mi">12</span><span class="p">),</span>
            <span class="n">arrowprops</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">facecolor</span><span class="o">=</span><span class="s">'black'</span><span class="p">),</span>
            <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>

<span class="c1"># Feature 12
</span><span class="n">sns</span><span class="p">.</span><span class="n">boxplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s">"Class"</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s">"V12"</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">new_df</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax2</span><span class="p">,</span> <span class="n">palette</span><span class="o">=</span><span class="n">colors</span><span class="p">)</span>
<span class="n">ax2</span><span class="p">.</span><span class="n">set_title</span><span class="p">(</span><span class="s">"V12 Feature </span><span class="se">\n</span><span class="s"> Reduction of outliers"</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>
<span class="n">ax2</span><span class="p">.</span><span class="n">annotate</span><span class="p">(</span><span class="s">'Fewer extreme </span><span class="se">\n</span><span class="s"> outliers'</span><span class="p">,</span> <span class="n">xy</span><span class="o">=</span><span class="p">(</span><span class="mf">0.98</span><span class="p">,</span> <span class="o">-</span><span class="mf">17.3</span><span class="p">),</span> <span class="n">xytext</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="o">-</span><span class="mi">12</span><span class="p">),</span>
            <span class="n">arrowprops</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">facecolor</span><span class="o">=</span><span class="s">'black'</span><span class="p">),</span>
            <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>

<span class="c1"># Feature V10
</span><span class="n">sns</span><span class="p">.</span><span class="n">boxplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s">"Class"</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s">"V10"</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">new_df</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax3</span><span class="p">,</span> <span class="n">palette</span><span class="o">=</span><span class="n">colors</span><span class="p">)</span>
<span class="n">ax3</span><span class="p">.</span><span class="n">set_title</span><span class="p">(</span><span class="s">"V10 Feature </span><span class="se">\n</span><span class="s"> Reduction of outliers"</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>
<span class="n">ax3</span><span class="p">.</span><span class="n">annotate</span><span class="p">(</span><span class="s">'Fewer extreme </span><span class="se">\n</span><span class="s"> outliers'</span><span class="p">,</span> <span class="n">xy</span><span class="o">=</span><span class="p">(</span><span class="mf">0.98</span><span class="p">,</span> <span class="o">-</span><span class="mf">14.8</span><span class="p">),</span> <span class="n">xytext</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="o">-</span><span class="mi">12</span><span class="p">),</span>
            <span class="n">arrowprops</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">facecolor</span><span class="o">=</span><span class="s">'black'</span><span class="p">),</span>
            <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>


<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div>

<p><img src="/myblog/images/output_48_0.png" alt="png" /></p>

<h2 id="33-차원-축소-및-클러스터링t-sne">3.3 차원 축소 및 클러스터링(t-SNE)</h2>
<dl>
  <dt><strong>t-SNE의 이해</strong></dt>
  <dd>이 알고리즘을 이해하려면 다음의 용어들을 이해해야 한다.
    <ul>
      <li>유클리드 거리</li>
      <li>조건부 확률</li>
      <li>정규 분포 및 t-분포</li>
    </ul>
  </dd>
</dl>

<p>* Joshua Starmer가 t-SNE에 대하여 명확하게 설명한 간단한 안내 비디오를 <a href="https://www.youtube.com/watch?v=NEaUSP4YerM">StatQuest: t-SNE, Clearly Explained</a> 에서 볼 수 있다.</p>

<p><strong>요약</strong></p>
<ul>
  <li>t-SNE 알고리즘은 우리의 데이터셋에서 사기 및 비사기 클래스를 꽤 정확하게 클러스터링할 수 있다.</li>
  <li>하위 샘플(sub sample)은 매우 작지만, t-SNE 알고리즘은 모든 시나리오에서 클러스터를 꽤 정확하게 감지할 수 있다. (t-SNE를 실행하기 전에 데이터 세트를 섞는다.)</li>
  <li>이는 추가 예측 모델이 사기, 비사기 클래스를 분리하는 데 있어 상당히 우수한 성능을 발휘할 것임을 시사한다.</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># 언더샘플 데이터인 new_df를 사용한다. (더 적은 데이터임을 기억하자.)
</span><span class="n">X</span> <span class="o">=</span> <span class="n">new_df</span><span class="p">.</span><span class="n">drop</span><span class="p">(</span><span class="s">'Class'</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">new_df</span><span class="p">[</span><span class="s">'Class'</span><span class="p">]</span>

<span class="c1"># t-SNE Implementation 
</span><span class="n">t0</span> <span class="o">=</span> <span class="n">time</span><span class="p">.</span><span class="n">time</span><span class="p">()</span>
<span class="n">X_reduced_tsne</span> <span class="o">=</span> <span class="n">TSNE</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">).</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X</span><span class="p">.</span><span class="n">values</span><span class="p">)</span>
<span class="n">t1</span> <span class="o">=</span> <span class="n">time</span><span class="p">.</span><span class="n">time</span><span class="p">()</span>
<span class="k">print</span><span class="p">(</span><span class="s">'t-SNE took {:.2} s'</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">t1</span><span class="o">-</span><span class="n">t0</span><span class="p">))</span>

<span class="c1"># PCA Implementation 
</span><span class="n">t0</span> <span class="o">=</span> <span class="n">time</span><span class="p">.</span><span class="n">time</span><span class="p">()</span>
<span class="n">X_reduced_pca</span> <span class="o">=</span> <span class="n">PCA</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">).</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X</span><span class="p">.</span><span class="n">values</span><span class="p">)</span>
<span class="n">t1</span> <span class="o">=</span> <span class="n">time</span><span class="p">.</span><span class="n">time</span><span class="p">()</span>
<span class="k">print</span><span class="p">(</span><span class="s">"PCA took {:.2} s"</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">t1</span><span class="o">-</span><span class="n">t0</span><span class="p">))</span>

<span class="c1"># TruncateedSVD 
</span><span class="n">t0</span> <span class="o">=</span> <span class="n">time</span><span class="p">.</span><span class="n">time</span><span class="p">()</span>
<span class="n">X_reduced_svd</span> <span class="o">=</span> <span class="n">TruncatedSVD</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">algorithm</span><span class="o">=</span><span class="s">'randomized'</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">).</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X</span><span class="p">.</span><span class="n">values</span><span class="p">)</span>
<span class="n">t1</span> <span class="o">=</span> <span class="n">time</span><span class="p">.</span><span class="n">time</span><span class="p">()</span>
<span class="k">print</span><span class="p">(</span><span class="s">"Truncated SVD took {:.2} s"</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">t1</span><span class="o">-</span><span class="n">t0</span><span class="p">))</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>t-SNE took 1.4e+01 s
PCA took 0.017 s
Truncated SVD took 0.0072 s
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">f</span><span class="p">,</span> <span class="p">(</span><span class="n">ax1</span><span class="p">,</span> <span class="n">ax2</span><span class="p">,</span> <span class="n">ax3</span><span class="p">)</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">24</span><span class="p">,</span><span class="mi">6</span><span class="p">))</span>
<span class="c1"># labels = ['No Fraud', 'Fraud']
</span><span class="n">f</span><span class="p">.</span><span class="n">suptitle</span><span class="p">(</span><span class="s">'Clusters using Dimensionality Reduction'</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>


<span class="n">blue_patch</span> <span class="o">=</span> <span class="n">mpatches</span><span class="p">.</span><span class="n">Patch</span><span class="p">(</span><span class="n">color</span><span class="o">=</span><span class="s">'#0A0AFF'</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s">'No Fraud'</span><span class="p">)</span>
<span class="n">red_patch</span> <span class="o">=</span> <span class="n">mpatches</span><span class="p">.</span><span class="n">Patch</span><span class="p">(</span><span class="n">color</span><span class="o">=</span><span class="s">'#AF0000'</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s">'Fraud'</span><span class="p">)</span>


<span class="c1"># t-SNE scatter plot
</span><span class="n">ax1</span><span class="p">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X_reduced_tsne</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span> <span class="n">X_reduced_tsne</span><span class="p">[:,</span><span class="mi">1</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="p">(</span><span class="n">y</span> <span class="o">==</span> <span class="mi">0</span><span class="p">),</span> <span class="n">cmap</span><span class="o">=</span><span class="s">'coolwarm'</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s">'No Fraud'</span><span class="p">,</span> <span class="n">linewidths</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">ax1</span><span class="p">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X_reduced_tsne</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span> <span class="n">X_reduced_tsne</span><span class="p">[:,</span><span class="mi">1</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="p">(</span><span class="n">y</span> <span class="o">==</span> <span class="mi">1</span><span class="p">),</span> <span class="n">cmap</span><span class="o">=</span><span class="s">'coolwarm'</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s">'Fraud'</span><span class="p">,</span> <span class="n">linewidths</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">ax1</span><span class="p">.</span><span class="n">set_title</span><span class="p">(</span><span class="s">'t-SNE'</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>

<span class="n">ax1</span><span class="p">.</span><span class="n">grid</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span>

<span class="n">ax1</span><span class="p">.</span><span class="n">legend</span><span class="p">(</span><span class="n">handles</span><span class="o">=</span><span class="p">[</span><span class="n">blue_patch</span><span class="p">,</span> <span class="n">red_patch</span><span class="p">])</span>


<span class="c1"># PCA scatter plot
</span><span class="n">ax2</span><span class="p">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X_reduced_pca</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span> <span class="n">X_reduced_pca</span><span class="p">[:,</span><span class="mi">1</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="p">(</span><span class="n">y</span> <span class="o">==</span> <span class="mi">0</span><span class="p">),</span> <span class="n">cmap</span><span class="o">=</span><span class="s">'coolwarm'</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s">'No Fraud'</span><span class="p">,</span> <span class="n">linewidths</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">ax2</span><span class="p">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X_reduced_pca</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span> <span class="n">X_reduced_pca</span><span class="p">[:,</span><span class="mi">1</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="p">(</span><span class="n">y</span> <span class="o">==</span> <span class="mi">1</span><span class="p">),</span> <span class="n">cmap</span><span class="o">=</span><span class="s">'coolwarm'</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s">'Fraud'</span><span class="p">,</span> <span class="n">linewidths</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">ax2</span><span class="p">.</span><span class="n">set_title</span><span class="p">(</span><span class="s">'PCA'</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>

<span class="n">ax2</span><span class="p">.</span><span class="n">grid</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span>

<span class="n">ax2</span><span class="p">.</span><span class="n">legend</span><span class="p">(</span><span class="n">handles</span><span class="o">=</span><span class="p">[</span><span class="n">blue_patch</span><span class="p">,</span> <span class="n">red_patch</span><span class="p">])</span>

<span class="c1"># TruncatedSVD scatter plot
</span><span class="n">ax3</span><span class="p">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X_reduced_svd</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span> <span class="n">X_reduced_svd</span><span class="p">[:,</span><span class="mi">1</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="p">(</span><span class="n">y</span> <span class="o">==</span> <span class="mi">0</span><span class="p">),</span> <span class="n">cmap</span><span class="o">=</span><span class="s">'coolwarm'</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s">'No Fraud'</span><span class="p">,</span> <span class="n">linewidths</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">ax3</span><span class="p">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X_reduced_svd</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span> <span class="n">X_reduced_svd</span><span class="p">[:,</span><span class="mi">1</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="p">(</span><span class="n">y</span> <span class="o">==</span> <span class="mi">1</span><span class="p">),</span> <span class="n">cmap</span><span class="o">=</span><span class="s">'coolwarm'</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s">'Fraud'</span><span class="p">,</span> <span class="n">linewidths</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">ax3</span><span class="p">.</span><span class="n">set_title</span><span class="p">(</span><span class="s">'Truncated SVD'</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>

<span class="n">ax3</span><span class="p">.</span><span class="n">grid</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span>

<span class="n">ax3</span><span class="p">.</span><span class="n">legend</span><span class="p">(</span><span class="n">handles</span><span class="o">=</span><span class="p">[</span><span class="n">blue_patch</span><span class="p">,</span> <span class="n">red_patch</span><span class="p">])</span>

<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div>

<p><img src="/myblog/images/output_51_0.png" alt="png" /></p>

<h2 id="34-classifiers">3.4 Classifiers</h2>
<p>네 가지 유형의 분류기를 학습하고, 사기 거래 탐지에 효과적인 분류기를 결정한다. train, test 데이터셋, label을 불리한다.</p>

<p><strong>요약</strong></p>
<ul>
  <li><strong>로지스틱 회귀 분석</strong> 분류기는 대부분의 경우 다른 세 분류기보다 정확하다. (Logistic Regression(로지스틱 회귀 분석)을 추가로 분석한다.)</li>
  <li><strong>GridSearchCV</strong>는 분류기에 대한 최상의 예측 점수를 제공하는 매개 변수를 결정하는 데 사용된다.</li>
  <li>로지스틱 회귀 분석에서는 가장 좋은 ROC(Receiving Operating Characteristic)를 갖는다. 즉, 로지스틱 회귀 분석에서는 사기, 비사기 트랜잭션을 상당히 정확하게 구분합니다.</li>
</ul>

<p><strong>학습 곡선</strong></p>
<ul>
  <li>training score와 cross validation score 사이의 차이가 클수록 모형이 과적합(고분산)할 가능성이 높다. : 오버피팅</li>
  <li>교육 및 교차 검증 세트 모두에서 점수가 낮은 경우 이는 모델이 적합하지 않음을 나타낸다(높은 편향). : 언더피팅</li>
  <li>로지스틱 회귀 분석 분류기는 교육 및 교차 검증 세트 모두에서 가장 높은 점수를 표시한다.</li>
</ul>

<p><br /></p>

<ul>
  <li>데이터셋</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>

<span class="c1"># 독립변수, 종속변수 분리
</span><span class="n">X</span> <span class="o">=</span> <span class="n">new_df</span><span class="p">.</span><span class="n">drop</span><span class="p">(</span><span class="s">'Class'</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">new_df</span><span class="p">[</span><span class="s">'Class'</span><span class="p">]</span>

<span class="c1"># 학습, 시험 데이터셋 분리 
</span><span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>

<span class="c1"># DataFrame -&gt; array
</span><span class="n">X_train</span> <span class="o">=</span> <span class="n">X_train</span><span class="p">.</span><span class="n">values</span> 
<span class="n">X_test</span> <span class="o">=</span> <span class="n">X_test</span><span class="p">.</span><span class="n">values</span> 
<span class="n">y_train</span> <span class="o">=</span> <span class="n">y_train</span><span class="p">.</span><span class="n">values</span> 
<span class="n">y_test</span> <span class="o">=</span> <span class="n">y_test</span><span class="p">.</span><span class="n">values</span> 
</code></pre></div></div>

<ul>
  <li>모델 학습</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># 모델 정의 
</span><span class="n">classifiers</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s">'LogisticRegression'</span><span class="p">:</span> <span class="n">LogisticRegression</span><span class="p">(),</span>
    <span class="s">'KNearest'</span><span class="p">:</span> <span class="n">KNeighborsClassifier</span><span class="p">(),</span>
    <span class="s">'Support Vector Classifier'</span><span class="p">:</span> <span class="n">SVC</span><span class="p">(),</span>
    <span class="s">'DecisionTreeClassifier'</span><span class="p">:</span> <span class="n">DecisionTreeClassifier</span><span class="p">()</span>
<span class="p">}</span>

<span class="c1"># 모델 학습 및 정확도 평가 
</span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">cross_val_score</span>

<span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">classifier</span> <span class="ow">in</span> <span class="n">classifiers</span><span class="p">.</span><span class="n">items</span><span class="p">():</span>
  <span class="n">classifier</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
  <span class="n">training_score</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">classifier</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span> 
  <span class="k">print</span><span class="p">(</span><span class="s">'Classifiers: '</span><span class="p">,</span> <span class="n">classifier</span><span class="p">.</span><span class="n">__class__</span><span class="p">.</span><span class="n">__name__</span><span class="p">,</span> <span class="s">'Has a training score of'</span><span class="p">,</span> <span class="nb">round</span><span class="p">(</span><span class="n">training_score</span><span class="p">.</span><span class="n">mean</span><span class="p">(),</span> <span class="mi">2</span><span class="p">)</span> <span class="o">*</span> <span class="mi">100</span><span class="p">,</span> <span class="s">"% accuracy score"</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Classifiers:  LogisticRegression Has a training score of 94.0 % accuracy score
Classifiers:  KNeighborsClassifier Has a training score of 94.0 % accuracy score
Classifiers:  SVC Has a training score of 94.0 % accuracy score
Classifiers:  DecisionTreeClassifier Has a training score of 91.0 % accuracy score
</code></pre></div></div>

<ul>
  <li>GridSearchCV</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># GridSearchCV를 통해 최적 하이퍼파라미터를 찾는다. 
</span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">GridSearchCV</span>

<span class="c1"># Logistic Regression
</span><span class="n">log_reg_params</span> <span class="o">=</span> <span class="p">{</span><span class="s">"penalty"</span><span class="p">:</span> <span class="p">[</span><span class="s">'l1'</span><span class="p">,</span> <span class="s">'l2'</span><span class="p">],</span> <span class="s">'C'</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.001</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">1000</span><span class="p">]}</span>
<span class="n">grid_log_reg</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">LogisticRegression</span><span class="p">(),</span> <span class="n">log_reg_params</span><span class="p">)</span>
<span class="n">grid_log_reg</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">log_reg</span> <span class="o">=</span> <span class="n">grid_log_reg</span><span class="p">.</span><span class="n">best_estimator_</span>

<span class="c1"># KNN 
</span><span class="n">knears_params</span> <span class="o">=</span> <span class="p">{</span><span class="s">'n_neighbors'</span><span class="p">:</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">1</span><span class="p">)),</span> <span class="s">'algorithm'</span><span class="p">:</span> <span class="p">[</span><span class="s">'auto'</span><span class="p">,</span> <span class="s">'ball_tree'</span><span class="p">,</span> <span class="s">'kd_tree'</span><span class="p">,</span> <span class="s">'brute'</span><span class="p">]}</span>
<span class="n">grid_knears</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">KNeighborsClassifier</span><span class="p">(),</span> <span class="n">knears_params</span><span class="p">)</span>
<span class="n">grid_knears</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">knears_neighbors</span> <span class="o">=</span> <span class="n">grid_knears</span><span class="p">.</span><span class="n">best_estimator_</span>

<span class="c1"># Support Vector Classifier 
</span><span class="n">svc_params</span> <span class="o">=</span> <span class="p">{</span><span class="s">'C'</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">,</span> <span class="mf">0.9</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="s">'kernel'</span><span class="p">:</span> <span class="p">[</span><span class="s">'rbf'</span><span class="p">,</span> <span class="s">'poly'</span><span class="p">,</span> <span class="s">'sigmoid'</span><span class="p">,</span> <span class="s">'linear'</span><span class="p">]}</span>
<span class="n">grid_svc</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">SVC</span><span class="p">(),</span> <span class="n">svc_params</span><span class="p">)</span>
<span class="n">grid_svc</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">svc</span> <span class="o">=</span> <span class="n">grid_svc</span><span class="p">.</span><span class="n">best_estimator_</span>

<span class="c1"># DecisionTree Classifier 
</span><span class="n">tree_params</span> <span class="o">=</span> <span class="p">{</span><span class="s">'criterion'</span><span class="p">:</span> <span class="p">[</span><span class="s">'gini'</span><span class="p">,</span> <span class="s">'entropy'</span><span class="p">],</span> <span class="s">'max_depth'</span><span class="p">:</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">1</span><span class="p">)),</span>
               <span class="s">'min_samples_leaf'</span><span class="p">:</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">1</span><span class="p">))}</span>
<span class="n">grid_tree</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">DecisionTreeClassifier</span><span class="p">(),</span> <span class="n">tree_params</span><span class="p">)</span>
<span class="n">grid_tree</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">tree_clf</span> <span class="o">=</span> <span class="n">grid_tree</span><span class="p">.</span><span class="n">best_estimator_</span> 
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">log_reg_score</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">log_reg</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">'Logistic Regression Cross Validation Score: '</span><span class="p">,</span> <span class="nb">round</span><span class="p">(</span><span class="n">log_reg_score</span><span class="p">.</span><span class="n">mean</span><span class="p">()</span><span class="o">*</span><span class="mi">100</span><span class="p">,</span> <span class="mi">2</span><span class="p">).</span><span class="n">astype</span><span class="p">(</span><span class="nb">str</span><span class="p">)</span> <span class="o">+</span> <span class="s">'%'</span><span class="p">)</span>

<span class="n">knears_score</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">knears_neighbors</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">'Knears Neighbors Cross Validation Score: '</span><span class="p">,</span> <span class="nb">round</span><span class="p">(</span><span class="n">knears_score</span><span class="p">.</span><span class="n">mean</span><span class="p">()</span><span class="o">*</span><span class="mi">100</span><span class="p">,</span> <span class="mi">2</span><span class="p">).</span><span class="n">astype</span><span class="p">(</span><span class="nb">str</span><span class="p">)</span> <span class="o">+</span> <span class="s">'%'</span><span class="p">)</span>

<span class="n">svc_score</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">svc</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">'Support Vector Classifier Cross Validation Score: '</span><span class="p">,</span> <span class="nb">round</span><span class="p">(</span><span class="n">svc_score</span><span class="p">.</span><span class="n">mean</span><span class="p">()</span><span class="o">*</span><span class="mi">100</span><span class="p">,</span> <span class="mi">2</span><span class="p">).</span><span class="n">astype</span><span class="p">(</span><span class="nb">str</span><span class="p">)</span> <span class="o">+</span> <span class="s">'%'</span><span class="p">)</span>

<span class="n">tree_score</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">tree_clf</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">'Decesion Tree Classifier Cross Validation Score: '</span><span class="p">,</span> <span class="nb">round</span><span class="p">(</span><span class="n">tree_score</span><span class="p">.</span><span class="n">mean</span><span class="p">()</span><span class="o">*</span><span class="mi">100</span><span class="p">,</span> <span class="mi">2</span><span class="p">).</span><span class="n">astype</span><span class="p">(</span><span class="nb">str</span><span class="p">)</span> <span class="o">+</span> <span class="s">'%'</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Logistic Regression Cross Validation Score:  94.18%
Knears Neighbors Cross Validation Score:  94.31%
Support Vector Classifier Cross Validation Score:  94.44%
Decesion Tree Classifier Cross Validation Score:  91.53%
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">undersample_X</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="n">drop</span><span class="p">(</span><span class="s">'Class'</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">undersample_y</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s">'Class'</span><span class="p">]</span>

<span class="k">for</span> <span class="n">train_index</span><span class="p">,</span> <span class="n">test_index</span> <span class="ow">in</span> <span class="n">sss</span><span class="p">.</span><span class="n">split</span><span class="p">(</span><span class="n">undersample_X</span><span class="p">,</span> <span class="n">undersample_y</span><span class="p">):</span>
  <span class="k">print</span><span class="p">(</span><span class="s">"Train:"</span><span class="p">,</span> <span class="n">train_index</span><span class="p">,</span> <span class="s">'Test:'</span><span class="p">,</span> <span class="n">test_index</span><span class="p">)</span>
  <span class="n">undersample_Xtrain</span><span class="p">,</span> <span class="n">undersample_Xtest</span> <span class="o">=</span> <span class="n">undersample_X</span><span class="p">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">train_index</span><span class="p">],</span> <span class="n">undersample_X</span><span class="p">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">test_index</span><span class="p">]</span>
  <span class="n">undersample_ytrain</span><span class="p">,</span> <span class="n">undersample_ytest</span> <span class="o">=</span> <span class="n">undersample_y</span><span class="p">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">train_index</span><span class="p">],</span> <span class="n">undersample_y</span><span class="p">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">test_index</span><span class="p">]</span>

<span class="n">undersample_Xtrain</span> <span class="o">=</span> <span class="n">undersample_Xtrain</span><span class="p">.</span><span class="n">values</span> 
<span class="n">undersample_Xtest</span> <span class="o">=</span> <span class="n">undersample_Xtest</span><span class="p">.</span><span class="n">values</span> 
<span class="n">undersample_ytrain</span> <span class="o">=</span> <span class="n">undersample_ytrain</span><span class="p">.</span><span class="n">values</span>
<span class="n">undersample_ytest</span> <span class="o">=</span> <span class="n">undersample_ytest</span><span class="p">.</span><span class="n">values</span> 

<span class="n">undersample_accuracy</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">undersample_precision</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">undersample_recall</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">undersample_f1</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">undersample_auc</span> <span class="o">=</span> <span class="p">[]</span> 

<span class="c1"># NearMiss Technique 
# NearMiss 분포 (우리가 사용하지 않을 이 변수들의 분포가 어떤지 확인하기 위해)
</span><span class="n">X_nearmiss</span><span class="p">,</span> <span class="n">y_nearmiss</span> <span class="o">=</span> <span class="n">NearMiss</span><span class="p">().</span><span class="n">fit_resample</span><span class="p">(</span><span class="n">undersample_X</span><span class="p">.</span><span class="n">values</span><span class="p">,</span> <span class="n">undersample_y</span><span class="p">.</span><span class="n">values</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">'NearMiss Label Distribution: {}'</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">Counter</span><span class="p">(</span><span class="n">y_nearmiss</span><span class="p">)))</span>

<span class="c1"># 올바른 방법으로 cross validating 
</span><span class="k">for</span> <span class="n">train</span><span class="p">,</span> <span class="n">test</span> <span class="ow">in</span> <span class="n">sss</span><span class="p">.</span><span class="n">split</span><span class="p">(</span><span class="n">undersample_Xtrain</span><span class="p">,</span> <span class="n">undersample_ytrain</span><span class="p">):</span> 
  <span class="n">undersample_pipeline</span> <span class="o">=</span> <span class="n">imbalanced_make_pipeline</span><span class="p">(</span><span class="n">NearMiss</span><span class="p">(</span><span class="n">sampling_strategy</span><span class="o">=</span><span class="s">'majority'</span><span class="p">),</span> <span class="n">log_reg</span><span class="p">)</span>
  <span class="n">undersample_model</span> <span class="o">=</span> <span class="n">undersample_pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">undersample_Xtrain</span><span class="p">[</span><span class="n">train</span><span class="p">],</span> <span class="n">undersample_ytrain</span><span class="p">[</span><span class="n">train</span><span class="p">])</span> <span class="c1"># 언더샘플링 모델 학습 
</span>  <span class="n">undersample_prediction</span> <span class="o">=</span> <span class="n">undersample_model</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">undersample_Xtrain</span><span class="p">[</span><span class="n">test</span><span class="p">])</span> <span class="c1"># 언더샘플링 모델 평가 (validation set) 
</span>
  <span class="n">undersample_accuracy</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">undersample_pipeline</span><span class="p">.</span><span class="n">score</span><span class="p">(</span><span class="n">original_Xtrain</span><span class="p">[</span><span class="n">test</span><span class="p">],</span> <span class="n">original_ytrain</span><span class="p">[</span><span class="n">test</span><span class="p">]))</span>
  <span class="n">undersample_precision</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">precision_score</span><span class="p">(</span><span class="n">original_ytrain</span><span class="p">[</span><span class="n">test</span><span class="p">],</span> <span class="n">undersample_prediction</span><span class="p">))</span>
  <span class="n">undersample_recall</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">recall_score</span><span class="p">(</span><span class="n">original_ytrain</span><span class="p">[</span><span class="n">test</span><span class="p">],</span> <span class="n">undersample_prediction</span><span class="p">))</span>
  <span class="n">undersample_f1</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">f1_score</span><span class="p">(</span><span class="n">original_ytrain</span><span class="p">[</span><span class="n">test</span><span class="p">],</span> <span class="n">undersample_prediction</span><span class="p">))</span>
  <span class="n">undersample_auc</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">roc_auc_score</span><span class="p">(</span><span class="n">original_ytrain</span><span class="p">[</span><span class="n">test</span><span class="p">],</span> <span class="n">undersample_prediction</span><span class="p">))</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Train: [ 56953  56954  56955 ... 284804 284805 284806] Test: [    0     1     2 ... 59039 59380 59968]
Train: [     0      1      2 ... 284804 284805 284806] Test: [ 56953  56954  56955 ... 113922 113923 113924]
Train: [     0      1      2 ... 284804 284805 284806] Test: [113764 113925 113926 ... 170892 170893 170894]
Train: [     0      1      2 ... 284804 284805 284806] Test: [166690 166692 167046 ... 227845 227846 227847]
Train: [     0      1      2 ... 227845 227846 227847] Test: [227429 227701 227848 ... 284804 284805 284806]
NearMiss Label Distribution: Counter({0: 492, 1: 492})
</code></pre></div></div>

<ul>
  <li>undersample_Xtrain, undersample_ytrain과 original_Xtrain, original_ytrain은 같은 데이터셋이고 같은 데이터셋이어야하는게 맞는데 나눠서 사용하는 이유가 궁금하다.</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">ShuffleSplit</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">learning_curve</span>

<span class="k">def</span> <span class="nf">plot_learning_curve</span><span class="p">(</span><span class="n">estimator1</span><span class="p">,</span> <span class="n">estimator2</span><span class="p">,</span> <span class="n">estimator3</span><span class="p">,</span> <span class="n">estimator4</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">ylim</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span>
                        <span class="n">n_jobs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">train_sizes</span><span class="o">=</span><span class="n">np</span><span class="p">.</span><span class="n">linspace</span><span class="p">(.</span><span class="mi">1</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mi">5</span><span class="p">)):</span>
    <span class="n">f</span><span class="p">,</span> <span class="p">((</span><span class="n">ax1</span><span class="p">,</span> <span class="n">ax2</span><span class="p">),</span> <span class="p">(</span><span class="n">ax3</span><span class="p">,</span> <span class="n">ax4</span><span class="p">))</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span><span class="mi">14</span><span class="p">),</span> <span class="n">sharey</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">ylim</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
        <span class="n">plt</span><span class="p">.</span><span class="n">ylim</span><span class="p">(</span><span class="o">*</span><span class="n">ylim</span><span class="p">)</span>
    <span class="c1"># First Estimator
</span>    <span class="n">train_sizes</span><span class="p">,</span> <span class="n">train_scores</span><span class="p">,</span> <span class="n">test_scores</span> <span class="o">=</span> <span class="n">learning_curve</span><span class="p">(</span>
        <span class="n">estimator1</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="n">cv</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=</span><span class="n">n_jobs</span><span class="p">,</span> <span class="n">train_sizes</span><span class="o">=</span><span class="n">train_sizes</span><span class="p">)</span>
    <span class="n">train_scores_mean</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">mean</span><span class="p">(</span><span class="n">train_scores</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">train_scores_std</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">std</span><span class="p">(</span><span class="n">train_scores</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">test_scores_mean</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">mean</span><span class="p">(</span><span class="n">test_scores</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">test_scores_std</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">std</span><span class="p">(</span><span class="n">test_scores</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">ax1</span><span class="p">.</span><span class="n">fill_between</span><span class="p">(</span><span class="n">train_sizes</span><span class="p">,</span> <span class="n">train_scores_mean</span> <span class="o">-</span> <span class="n">train_scores_std</span><span class="p">,</span>
                     <span class="n">train_scores_mean</span> <span class="o">+</span> <span class="n">train_scores_std</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
                     <span class="n">color</span><span class="o">=</span><span class="s">"#ff9124"</span><span class="p">)</span>
    <span class="n">ax1</span><span class="p">.</span><span class="n">fill_between</span><span class="p">(</span><span class="n">train_sizes</span><span class="p">,</span> <span class="n">test_scores_mean</span> <span class="o">-</span> <span class="n">test_scores_std</span><span class="p">,</span>
                     <span class="n">test_scores_mean</span> <span class="o">+</span> <span class="n">test_scores_std</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s">"#2492ff"</span><span class="p">)</span>
    <span class="n">ax1</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">train_sizes</span><span class="p">,</span> <span class="n">train_scores_mean</span><span class="p">,</span> <span class="s">'o-'</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s">"#ff9124"</span><span class="p">,</span>
             <span class="n">label</span><span class="o">=</span><span class="s">"Training score"</span><span class="p">)</span>
    <span class="n">ax1</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">train_sizes</span><span class="p">,</span> <span class="n">test_scores_mean</span><span class="p">,</span> <span class="s">'o-'</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s">"#2492ff"</span><span class="p">,</span>
             <span class="n">label</span><span class="o">=</span><span class="s">"Cross-validation score"</span><span class="p">)</span>
    <span class="n">ax1</span><span class="p">.</span><span class="n">set_title</span><span class="p">(</span><span class="s">"Logistic Regression Learning Curve"</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>
    <span class="n">ax1</span><span class="p">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s">'Training size (m)'</span><span class="p">)</span>
    <span class="n">ax1</span><span class="p">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s">'Score'</span><span class="p">)</span>
    <span class="n">ax1</span><span class="p">.</span><span class="n">grid</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span>
    <span class="n">ax1</span><span class="p">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s">"best"</span><span class="p">)</span>
    
    <span class="c1"># Second Estimator 
</span>    <span class="n">train_sizes</span><span class="p">,</span> <span class="n">train_scores</span><span class="p">,</span> <span class="n">test_scores</span> <span class="o">=</span> <span class="n">learning_curve</span><span class="p">(</span>
        <span class="n">estimator2</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="n">cv</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=</span><span class="n">n_jobs</span><span class="p">,</span> <span class="n">train_sizes</span><span class="o">=</span><span class="n">train_sizes</span><span class="p">)</span>
    <span class="n">train_scores_mean</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">mean</span><span class="p">(</span><span class="n">train_scores</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">train_scores_std</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">std</span><span class="p">(</span><span class="n">train_scores</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">test_scores_mean</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">mean</span><span class="p">(</span><span class="n">test_scores</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">test_scores_std</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">std</span><span class="p">(</span><span class="n">test_scores</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">ax2</span><span class="p">.</span><span class="n">fill_between</span><span class="p">(</span><span class="n">train_sizes</span><span class="p">,</span> <span class="n">train_scores_mean</span> <span class="o">-</span> <span class="n">train_scores_std</span><span class="p">,</span>
                     <span class="n">train_scores_mean</span> <span class="o">+</span> <span class="n">train_scores_std</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
                     <span class="n">color</span><span class="o">=</span><span class="s">"#ff9124"</span><span class="p">)</span>
    <span class="n">ax2</span><span class="p">.</span><span class="n">fill_between</span><span class="p">(</span><span class="n">train_sizes</span><span class="p">,</span> <span class="n">test_scores_mean</span> <span class="o">-</span> <span class="n">test_scores_std</span><span class="p">,</span>
                     <span class="n">test_scores_mean</span> <span class="o">+</span> <span class="n">test_scores_std</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s">"#2492ff"</span><span class="p">)</span>
    <span class="n">ax2</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">train_sizes</span><span class="p">,</span> <span class="n">train_scores_mean</span><span class="p">,</span> <span class="s">'o-'</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s">"#ff9124"</span><span class="p">,</span>
             <span class="n">label</span><span class="o">=</span><span class="s">"Training score"</span><span class="p">)</span>
    <span class="n">ax2</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">train_sizes</span><span class="p">,</span> <span class="n">test_scores_mean</span><span class="p">,</span> <span class="s">'o-'</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s">"#2492ff"</span><span class="p">,</span>
             <span class="n">label</span><span class="o">=</span><span class="s">"Cross-validation score"</span><span class="p">)</span>
    <span class="n">ax2</span><span class="p">.</span><span class="n">set_title</span><span class="p">(</span><span class="s">"Knears Neighbors Learning Curve"</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>
    <span class="n">ax2</span><span class="p">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s">'Training size (m)'</span><span class="p">)</span>
    <span class="n">ax2</span><span class="p">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s">'Score'</span><span class="p">)</span>
    <span class="n">ax2</span><span class="p">.</span><span class="n">grid</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span>
    <span class="n">ax2</span><span class="p">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s">"best"</span><span class="p">)</span>
    
    <span class="c1"># Third Estimator
</span>    <span class="n">train_sizes</span><span class="p">,</span> <span class="n">train_scores</span><span class="p">,</span> <span class="n">test_scores</span> <span class="o">=</span> <span class="n">learning_curve</span><span class="p">(</span>
        <span class="n">estimator3</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="n">cv</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=</span><span class="n">n_jobs</span><span class="p">,</span> <span class="n">train_sizes</span><span class="o">=</span><span class="n">train_sizes</span><span class="p">)</span>
    <span class="n">train_scores_mean</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">mean</span><span class="p">(</span><span class="n">train_scores</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">train_scores_std</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">std</span><span class="p">(</span><span class="n">train_scores</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">test_scores_mean</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">mean</span><span class="p">(</span><span class="n">test_scores</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">test_scores_std</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">std</span><span class="p">(</span><span class="n">test_scores</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">ax3</span><span class="p">.</span><span class="n">fill_between</span><span class="p">(</span><span class="n">train_sizes</span><span class="p">,</span> <span class="n">train_scores_mean</span> <span class="o">-</span> <span class="n">train_scores_std</span><span class="p">,</span>
                     <span class="n">train_scores_mean</span> <span class="o">+</span> <span class="n">train_scores_std</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
                     <span class="n">color</span><span class="o">=</span><span class="s">"#ff9124"</span><span class="p">)</span>
    <span class="n">ax3</span><span class="p">.</span><span class="n">fill_between</span><span class="p">(</span><span class="n">train_sizes</span><span class="p">,</span> <span class="n">test_scores_mean</span> <span class="o">-</span> <span class="n">test_scores_std</span><span class="p">,</span>
                     <span class="n">test_scores_mean</span> <span class="o">+</span> <span class="n">test_scores_std</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s">"#2492ff"</span><span class="p">)</span>
    <span class="n">ax3</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">train_sizes</span><span class="p">,</span> <span class="n">train_scores_mean</span><span class="p">,</span> <span class="s">'o-'</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s">"#ff9124"</span><span class="p">,</span>
             <span class="n">label</span><span class="o">=</span><span class="s">"Training score"</span><span class="p">)</span>
    <span class="n">ax3</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">train_sizes</span><span class="p">,</span> <span class="n">test_scores_mean</span><span class="p">,</span> <span class="s">'o-'</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s">"#2492ff"</span><span class="p">,</span>
             <span class="n">label</span><span class="o">=</span><span class="s">"Cross-validation score"</span><span class="p">)</span>
    <span class="n">ax3</span><span class="p">.</span><span class="n">set_title</span><span class="p">(</span><span class="s">"Support Vector Classifier </span><span class="se">\n</span><span class="s"> Learning Curve"</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>
    <span class="n">ax3</span><span class="p">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s">'Training size (m)'</span><span class="p">)</span>
    <span class="n">ax3</span><span class="p">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s">'Score'</span><span class="p">)</span>
    <span class="n">ax3</span><span class="p">.</span><span class="n">grid</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span>
    <span class="n">ax3</span><span class="p">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s">"best"</span><span class="p">)</span>
    
    <span class="c1"># Fourth Estimator
</span>    <span class="n">train_sizes</span><span class="p">,</span> <span class="n">train_scores</span><span class="p">,</span> <span class="n">test_scores</span> <span class="o">=</span> <span class="n">learning_curve</span><span class="p">(</span>
        <span class="n">estimator4</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="n">cv</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=</span><span class="n">n_jobs</span><span class="p">,</span> <span class="n">train_sizes</span><span class="o">=</span><span class="n">train_sizes</span><span class="p">)</span>
    <span class="n">train_scores_mean</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">mean</span><span class="p">(</span><span class="n">train_scores</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">train_scores_std</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">std</span><span class="p">(</span><span class="n">train_scores</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">test_scores_mean</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">mean</span><span class="p">(</span><span class="n">test_scores</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">test_scores_std</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">std</span><span class="p">(</span><span class="n">test_scores</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">ax4</span><span class="p">.</span><span class="n">fill_between</span><span class="p">(</span><span class="n">train_sizes</span><span class="p">,</span> <span class="n">train_scores_mean</span> <span class="o">-</span> <span class="n">train_scores_std</span><span class="p">,</span>
                     <span class="n">train_scores_mean</span> <span class="o">+</span> <span class="n">train_scores_std</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
                     <span class="n">color</span><span class="o">=</span><span class="s">"#ff9124"</span><span class="p">)</span>
    <span class="n">ax4</span><span class="p">.</span><span class="n">fill_between</span><span class="p">(</span><span class="n">train_sizes</span><span class="p">,</span> <span class="n">test_scores_mean</span> <span class="o">-</span> <span class="n">test_scores_std</span><span class="p">,</span>
                     <span class="n">test_scores_mean</span> <span class="o">+</span> <span class="n">test_scores_std</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s">"#2492ff"</span><span class="p">)</span>
    <span class="n">ax4</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">train_sizes</span><span class="p">,</span> <span class="n">train_scores_mean</span><span class="p">,</span> <span class="s">'o-'</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s">"#ff9124"</span><span class="p">,</span>
             <span class="n">label</span><span class="o">=</span><span class="s">"Training score"</span><span class="p">)</span>
    <span class="n">ax4</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">train_sizes</span><span class="p">,</span> <span class="n">test_scores_mean</span><span class="p">,</span> <span class="s">'o-'</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s">"#2492ff"</span><span class="p">,</span>
             <span class="n">label</span><span class="o">=</span><span class="s">"Cross-validation score"</span><span class="p">)</span>
    <span class="n">ax4</span><span class="p">.</span><span class="n">set_title</span><span class="p">(</span><span class="s">"Decision Tree Classifier </span><span class="se">\n</span><span class="s"> Learning Curve"</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>
    <span class="n">ax4</span><span class="p">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s">'Training size (m)'</span><span class="p">)</span>
    <span class="n">ax4</span><span class="p">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s">'Score'</span><span class="p">)</span>
    <span class="n">ax4</span><span class="p">.</span><span class="n">grid</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span>
    <span class="n">ax4</span><span class="p">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s">"best"</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">plt</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">cv</span> <span class="o">=</span> <span class="n">ShuffleSplit</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="n">plot_learning_curve</span><span class="p">(</span><span class="n">log_reg</span><span class="p">,</span> <span class="n">knears_neighbors</span><span class="p">,</span> <span class="n">svc</span><span class="p">,</span> <span class="n">tree_clf</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="p">(</span><span class="mf">0.87</span><span class="p">,</span> <span class="mf">1.01</span><span class="p">),</span> <span class="n">cv</span><span class="o">=</span><span class="n">cv</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&lt;module 'matplotlib.pyplot' from '/usr/local/lib/python3.7/dist-packages/matplotlib/pyplot.py'&gt;
</code></pre></div></div>

<p><img src="/myblog/images/output_63_1.png" alt="png" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">roc_curve</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">cross_val_predict</span>
<span class="c1"># Create a DataFrame with all the scores and the classifiers names.
</span>
<span class="n">log_reg_pred</span> <span class="o">=</span> <span class="n">cross_val_predict</span><span class="p">(</span><span class="n">log_reg</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
                             <span class="n">method</span><span class="o">=</span><span class="s">"decision_function"</span><span class="p">)</span> <span class="c1"># decision_function: 각 샘플의 점수를 반환 (양수: label1, 음수: label0)
</span>
<span class="n">knears_pred</span> <span class="o">=</span> <span class="n">cross_val_predict</span><span class="p">(</span><span class="n">knears_neighbors</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>

<span class="n">svc_pred</span> <span class="o">=</span> <span class="n">cross_val_predict</span><span class="p">(</span><span class="n">svc</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
                             <span class="n">method</span><span class="o">=</span><span class="s">"decision_function"</span><span class="p">)</span>

<span class="n">tree_pred</span> <span class="o">=</span> <span class="n">cross_val_predict</span><span class="p">(</span><span class="n">tree_clf</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
</code></pre></div></div>

<p>* KNN, DT에서 predict_proba를 쓰지 않아도 되는지 궁금하다</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">roc_auc_score</span>

<span class="k">print</span><span class="p">(</span><span class="s">'Logistic Regression: '</span><span class="p">,</span> <span class="n">roc_auc_score</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="n">log_reg_pred</span><span class="p">))</span>
<span class="k">print</span><span class="p">(</span><span class="s">'KNears Neighbors: '</span><span class="p">,</span> <span class="n">roc_auc_score</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="n">knears_pred</span><span class="p">))</span>
<span class="k">print</span><span class="p">(</span><span class="s">'Support Vector Classifier: '</span><span class="p">,</span> <span class="n">roc_auc_score</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="n">svc_pred</span><span class="p">))</span>
<span class="k">print</span><span class="p">(</span><span class="s">'Decision Tree Classifier: '</span><span class="p">,</span> <span class="n">roc_auc_score</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="n">tree_pred</span><span class="p">))</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Logistic Regression:  0.9829945818477864
KNears Neighbors:  0.9412074338171303
Support Vector Classifier:  0.9794292692512844
Decision Tree Classifier:  0.9125796580668707
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
<span class="n">log_fpr</span><span class="p">,</span> <span class="n">log_tpr</span><span class="p">,</span> <span class="n">log_thresold</span> <span class="o">=</span> <span class="n">roc_curve</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="n">log_reg_pred</span><span class="p">)</span>
<span class="n">knear_fpr</span><span class="p">,</span> <span class="n">knear_tpr</span><span class="p">,</span> <span class="n">knear_threshold</span> <span class="o">=</span> <span class="n">roc_curve</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="n">knears_pred</span><span class="p">)</span>
<span class="n">svc_fpr</span><span class="p">,</span> <span class="n">svc_tpr</span><span class="p">,</span> <span class="n">svc_threshold</span> <span class="o">=</span> <span class="n">roc_curve</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="n">svc_pred</span><span class="p">)</span>
<span class="n">tree_fpr</span><span class="p">,</span> <span class="n">tree_tpr</span><span class="p">,</span> <span class="n">tree_threshold</span> <span class="o">=</span> <span class="n">roc_curve</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="n">tree_pred</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">graph_roc_curve_multiple</span><span class="p">(</span><span class="n">log_fpr</span><span class="p">,</span> <span class="n">log_tpr</span><span class="p">,</span> <span class="n">knear_fpr</span><span class="p">,</span> <span class="n">knear_tpr</span><span class="p">,</span> <span class="n">svc_fpr</span><span class="p">,</span> <span class="n">svc_tpr</span><span class="p">,</span> <span class="n">tree_fpr</span><span class="p">,</span> <span class="n">tree_tpr</span><span class="p">):</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span><span class="mi">8</span><span class="p">))</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">title</span><span class="p">(</span><span class="s">'ROC Curve </span><span class="se">\n</span><span class="s"> Top 4 Classifiers'</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">18</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">log_fpr</span><span class="p">,</span> <span class="n">log_tpr</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s">'Logistic Regression Classifier Score: {:.4f}'</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">roc_auc_score</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="n">log_reg_pred</span><span class="p">)))</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">knear_fpr</span><span class="p">,</span> <span class="n">knear_tpr</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s">'KNears Neighbors Classifier Score: {:.4f}'</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">roc_auc_score</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="n">knears_pred</span><span class="p">)))</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">svc_fpr</span><span class="p">,</span> <span class="n">svc_tpr</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s">'Support Vector Classifier Score: {:.4f}'</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">roc_auc_score</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="n">svc_pred</span><span class="p">)))</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">tree_fpr</span><span class="p">,</span> <span class="n">tree_tpr</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s">'Decision Tree Classifier Score: {:.4f}'</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">roc_auc_score</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="n">tree_pred</span><span class="p">)))</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="s">'k--'</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">axis</span><span class="p">([</span><span class="o">-</span><span class="mf">0.01</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">'False Positive Rate'</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">16</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">'True Positive Rate'</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">16</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">annotate</span><span class="p">(</span><span class="s">'Minimum ROC Score of 50% </span><span class="se">\n</span><span class="s"> (This is the minimum score to get)'</span><span class="p">,</span> <span class="n">xy</span><span class="o">=</span><span class="p">(</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">),</span> <span class="n">xytext</span><span class="o">=</span><span class="p">(</span><span class="mf">0.6</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">),</span>
                <span class="n">arrowprops</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">facecolor</span><span class="o">=</span><span class="s">'#6E726D'</span><span class="p">,</span> <span class="n">shrink</span><span class="o">=</span><span class="mf">0.05</span><span class="p">),</span>
                <span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">legend</span><span class="p">()</span>
    
<span class="n">graph_roc_curve_multiple</span><span class="p">(</span><span class="n">log_fpr</span><span class="p">,</span> <span class="n">log_tpr</span><span class="p">,</span> <span class="n">knear_fpr</span><span class="p">,</span> <span class="n">knear_tpr</span><span class="p">,</span> <span class="n">svc_fpr</span><span class="p">,</span> <span class="n">svc_tpr</span><span class="p">,</span> <span class="n">tree_fpr</span><span class="p">,</span> <span class="n">tree_tpr</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div>

<p><img src="/myblog/images/output_67_0.png" alt="png" /></p>

<h3 id="35-로지스틱-회귀-분석">3.5 로지스틱 회귀 분석</h3>
<p>로지스틱 회귀 분류기에 대해 더 자세히 알아본다.</p>

<p><strong>용어</strong></p>
<ul>
  <li>True Positives: 사기 거래로 올바르게 분류</li>
  <li>False Positives: 사기 거래로 잘못 분류</li>
  <li>True Negative: 비사기 거래로 올바르게 분류</li>
  <li>False Negative: 비사기 거래로 잘못 분류</li>
  <li>Precision(정밀도): True Positives / (True Positives + False Positives) [긍정으로 예측한 것 중 real 긍정 예측]</li>
  <li>Recall(민감도): True Positives / (True Positives + False Negatives) [전체 real 긍정 중 real 긍정 예측]</li>
  <li>정밀도는 사기 거래를 탐지하는 데 있어 모델이 얼마나 정밀(얼마나 확실한지)한지 판단한다. 반면 리콜은 우리의 모델이 감지할 수 있는 사기 사례의 양이다.</li>
  <li>Precision(정밀도) &amp; Recall(민감도) Trade-off: 모델이 더 정밀할수록(선택적) 감지되는 사례가 줄어듭니다. (예) 우리 모델의 정밀도가 95%라고 가정하면, 95% 이상 정확한 사기 건수가 5건에 불과하다고 하자. 그렇다면 우리 모델이 90%의 확률로 사기로 간주하는 사례가 5건 더 있다고 하자, 정밀도를 90%로 낮추면 우리 모델이 감지할 수 있는 사례가 5개 더 많아질 것이다.</li>
</ul>

<p><strong>요약</strong></p>
<ul>
  <li>그럼에도 불구하고 정밀도는 0.90에서 0.92 사이로 떨어지기 시작하지만, 우리의 정밀도는 여전히 꽤 높고 여전히 감소하는 민감도가 있다.</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">logistic_roc_curve</span><span class="p">(</span><span class="n">log_fpr</span><span class="p">,</span> <span class="n">log_tpr</span><span class="p">):</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span><span class="mi">8</span><span class="p">))</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">title</span><span class="p">(</span><span class="s">'Logistic Regression ROC Curve'</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">16</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">log_fpr</span><span class="p">,</span> <span class="n">log_tpr</span><span class="p">,</span> <span class="s">'b-'</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="s">'r--'</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">'False Positive Rate'</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">16</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">'True Positive Rate'</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">16</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">axis</span><span class="p">([</span><span class="o">-</span><span class="mf">0.01</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">])</span>
    
    
<span class="n">logistic_roc_curve</span><span class="p">(</span><span class="n">log_fpr</span><span class="p">,</span> <span class="n">log_tpr</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div>

<p><img src="/myblog/images/output_69_0.png" alt="png" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">precision_recall_curve</span>
<span class="n">precision</span><span class="p">,</span> <span class="n">recall</span><span class="p">,</span> <span class="n">threshold</span> <span class="o">=</span> <span class="n">precision_recall_curve</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="n">log_reg_pred</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">recall_score</span><span class="p">,</span> <span class="n">precision_score</span><span class="p">,</span> <span class="n">f1_score</span><span class="p">,</span> <span class="n">accuracy_score</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">log_reg</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="s">'---'</span> <span class="o">*</span> <span class="mi">45</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">'Overfitting: </span><span class="se">\n</span><span class="s">'</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">'Recall Score: {:.2f}'</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">recall_score</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)))</span>
<span class="k">print</span><span class="p">(</span><span class="s">'Precision Score: {:.2f}'</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">precision_score</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)))</span>
<span class="k">print</span><span class="p">(</span><span class="s">'F1 Score: {:.2f}'</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">f1_score</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)))</span>
<span class="k">print</span><span class="p">(</span><span class="s">'Accuracy Score: {:.2f}'</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)))</span>
<span class="k">print</span><span class="p">(</span><span class="s">'---'</span> <span class="o">*</span> <span class="mi">45</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="s">'---'</span> <span class="o">*</span> <span class="mi">45</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">'How it should be:</span><span class="se">\n</span><span class="s">'</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">"Accuracy Score: {:.2f}"</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">mean</span><span class="p">(</span><span class="n">undersample_accuracy</span><span class="p">)))</span>
<span class="k">print</span><span class="p">(</span><span class="s">"Precision Score: {:.2f}"</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">mean</span><span class="p">(</span><span class="n">undersample_precision</span><span class="p">)))</span>
<span class="k">print</span><span class="p">(</span><span class="s">"Recall Score: {:.2f}"</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">mean</span><span class="p">(</span><span class="n">undersample_recall</span><span class="p">)))</span>
<span class="k">print</span><span class="p">(</span><span class="s">"F1 Score: {:.2f}"</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">mean</span><span class="p">(</span><span class="n">undersample_f1</span><span class="p">)))</span>
<span class="k">print</span><span class="p">(</span><span class="s">'---'</span> <span class="o">*</span> <span class="mi">45</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>---------------------------------------------------------------------------------------------------------------------------------------
Overfitting: 

Recall Score: 0.93
Precision Score: 0.79
F1 Score: 0.85
Accuracy Score: 0.85
---------------------------------------------------------------------------------------------------------------------------------------
---------------------------------------------------------------------------------------------------------------------------------------
How it should be:

Accuracy Score: 0.81
Precision Score: 0.00
Recall Score: 0.17
F1 Score: 0.00
---------------------------------------------------------------------------------------------------------------------------------------
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">undersample_y_score</span> <span class="o">=</span> <span class="n">log_reg</span><span class="p">.</span><span class="n">decision_function</span><span class="p">(</span><span class="n">original_Xtest</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">average_precision_score</span>

<span class="n">undersample_average_precision</span> <span class="o">=</span> <span class="n">average_precision_score</span><span class="p">(</span><span class="n">original_ytest</span><span class="p">,</span> <span class="n">undersample_y_score</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="s">'Average precision-recall score: {0:0.2f}'</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">undersample_average_precision</span><span class="p">))</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Average precision-recall score: 0.04
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">precision_recall_curve</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>

<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span><span class="mi">6</span><span class="p">))</span>

<span class="n">precision</span><span class="p">,</span> <span class="n">recall</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">precision_recall_curve</span><span class="p">(</span><span class="n">original_ytest</span><span class="p">,</span> <span class="n">undersample_y_score</span><span class="p">)</span>

<span class="n">plt</span><span class="p">.</span><span class="n">step</span><span class="p">(</span><span class="n">recall</span><span class="p">,</span> <span class="n">precision</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s">'#004a93'</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span>
         <span class="n">where</span><span class="o">=</span><span class="s">'post'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">fill_between</span><span class="p">(</span><span class="n">recall</span><span class="p">,</span> <span class="n">precision</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="s">'post'</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span>
                 <span class="n">color</span><span class="o">=</span><span class="s">'#48a6ff'</span><span class="p">)</span>

<span class="n">plt</span><span class="p">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">'Recall'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">'Precision'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">ylim</span><span class="p">([</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.05</span><span class="p">])</span>
<span class="n">plt</span><span class="p">.</span><span class="n">xlim</span><span class="p">([</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">])</span>
<span class="n">plt</span><span class="p">.</span><span class="n">title</span><span class="p">(</span><span class="s">'UnderSampling Precision-Recall curve: </span><span class="se">\n</span><span class="s"> Average Precision-Recall Score ={0:0.2f}'</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span>
          <span class="n">undersample_average_precision</span><span class="p">),</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">16</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Text(0.5, 1.0, 'UnderSampling Precision-Recall curve: \n Average Precision-Recall Score =0.04')
</code></pre></div></div>

<p><img src="/myblog/images/output_74_1.png" alt="png" /></p>

<h2 id="36-smote를-사용한-오버샘플링over-smpling">3.6 SMOTE를 사용한 오버샘플링(Over Smpling)</h2>

<p><strong>SMOTE (Over-Sampling)</strong><br />
<!-- <img src="https://raw.githubusercontent.com/rikunert/SMOTE_visualisation/master/SMOTE_R_visualisation_3.png" width=800>    -->
SMOTE는 Synthetic Minority Over-sampling 기법이다. 랜덤 언더샘플링과 달리, SMOTE는 클래스의 균형을 같게 하기 위해 새로운 합성 점(synthetic points)를 만든다. 이는 “클래스 불균형 문제”를 해결하기 위한 또 다른 대안이다.</p>

<p><strong>SMOTE 이해</strong></p>
<ul>
  <li>계층 불균형 해결: SMOTE는 소수 계층과 다수 계층 사이의 동등한 균형에 도달하기 위해 소수 계층으로부터 합성 포인트를 만든다.</li>
  <li>합성점의 위치: SMOTE는 소수계급의 가장 가까운 이웃 사이의 거리를 선택하고, 이 거리들 사이에 합성점을 생성한다.</li>
  <li>최종 효과: 랜덤 언더샘플링과 달리 행을 삭제할 필요가 없으므로 더 많은 정보가 유지된다.</li>
  <li>
    <table>
      <tbody>
        <tr>
          <td>정확도</td>
          <td> </td>
          <td>시간 트레이드오프: SMOTE는 무작위 언더샘플링보다 정확할 가능성이 높지만, 앞서 언급한 바와 같이 행이 제거되지 않기 때문에 훈련하는 데 더 많은 시간이 걸릴 것이다.</td>
        </tr>
      </tbody>
    </table>
  </li>
</ul>

<p><strong>교차 유효성 검사 과적합 실수</strong></p>
<ul>
  <li>
    <p>교차 검증 중 과적합: 우리의 언더샘플 분석에서 범한 일반적인 실수가 있다. 데이터를 언더샘플링하거나 오버샘플링하려는 경우 교차 검증 전에 이 작업을 수행해서는 안된다. 교차 검증을 구현하기 전에 검증 세트에 직접 영향을 미쳐 “데이터 누출” 문제가 발생하기 때문이다. 다음 섹션에서는 놀라운 정밀도와 리콜 점수를 확인할 수 있지만 실제로는 우리의 데이터가 과적합되었다!</p>
  </li>
  <li>
    <p>틀린 방법</p>
  </li>
</ul>

<p><img src="/myblog/images/01.credit_1.png" alt="image.png" /></p>

<p>앞에서 언급했듯이, 우리의 경우 소수 클래스(“사기”)를 얻고 교차 검증 전에 합성 포인트를 생성하면 교차 검증 프로세스의 “검증 세트”에 일정한 영향을 미친다. 교차 검증이 어떻게 작동하는지 기억해야한다. 데이터를 5개의 배치로 분할한다고 가정하면, 데이터 세트의 4/5가 교육 세트이고 1/5이 검증 세트인데, 테스트 세트를 만지면 안 된다.</p>

<p>따라서 다음과 같이 이전이 아닌 교차 검증 중에 합성 데이터 지점을 생성해야 한다.</p>

<ul>
  <li>맞는 방법</li>
</ul>

<p><img src="/myblog/images/01.credit_2.png" alt="image.png" /></p>

<p>위에서 보듯이 SMOTE는 교차 검증 프로세스 이전이 아니라 교차 검증 중에 발생해야한다. 합성 데이터는 검증 세트에 영향을 주지 않고 교육 세트에 대해서만 생성된다.</p>

<p><strong>[References]</strong><br />
-DEALING WITH IMBALANCED DATA: UNDERSAMPLING, OVERSAMPLING AND PROPER CROSS-VALIDATION<br />
-SMOTE explained for noobs<br />
-Machine Learning - Over-&amp; Undersampling - Python/ Scikit/ Scikit-Imblearn</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">imblearn.over_sampling</span> <span class="kn">import</span> <span class="n">SMOTE</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span><span class="p">,</span> <span class="n">RandomizedSearchCV</span>

<span class="k">print</span><span class="p">(</span><span class="s">'Length of X (train): {} | Length of y (train): {}'</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">original_Xtrain</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">original_ytrain</span><span class="p">)))</span>
<span class="k">print</span><span class="p">(</span><span class="s">'Length of X (test): {} | Length of y (test): {}'</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">original_Xtest</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">original_ytest</span><span class="p">)))</span>

<span class="c1"># 리스트에 점수를 추가하고 평균을 구한다.
</span><span class="n">accuracy_lst</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">precision_lst</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">recall_lst</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">f1_lst</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">auc_lst</span> <span class="o">=</span> <span class="p">[]</span>

<span class="c1"># Classifier with optimal parameters
# log_reg_sm = grid_log_reg.best_estimator_
</span><span class="n">log_reg_sm</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">()</span>




<span class="n">rand_log_reg</span> <span class="o">=</span> <span class="n">RandomizedSearchCV</span><span class="p">(</span><span class="n">LogisticRegression</span><span class="p">(),</span> <span class="n">log_reg_params</span><span class="p">,</span> <span class="n">n_iter</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>


<span class="c1"># Implementing SMOTE Technique 
# Cross Validating the right way
# Parameters
</span><span class="n">log_reg_params</span> <span class="o">=</span> <span class="p">{</span><span class="s">"penalty"</span><span class="p">:</span> <span class="p">[</span><span class="s">'l1'</span><span class="p">,</span> <span class="s">'l2'</span><span class="p">],</span> <span class="s">'C'</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.001</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">1000</span><span class="p">]}</span>
<span class="k">for</span> <span class="n">train</span><span class="p">,</span> <span class="n">test</span> <span class="ow">in</span> <span class="n">sss</span><span class="p">.</span><span class="n">split</span><span class="p">(</span><span class="n">original_Xtrain</span><span class="p">,</span> <span class="n">original_ytrain</span><span class="p">):</span>
    <span class="n">pipeline</span> <span class="o">=</span> <span class="n">imbalanced_make_pipeline</span><span class="p">(</span><span class="n">SMOTE</span><span class="p">(</span><span class="n">sampling_strategy</span><span class="o">=</span><span class="s">'minority'</span><span class="p">),</span> <span class="n">rand_log_reg</span><span class="p">)</span> <span class="c1"># SMOTE happens during Cross Validation not before..
</span>    <span class="n">model</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">original_Xtrain</span><span class="p">[</span><span class="n">train</span><span class="p">],</span> <span class="n">original_ytrain</span><span class="p">[</span><span class="n">train</span><span class="p">])</span>
    <span class="n">best_est</span> <span class="o">=</span> <span class="n">rand_log_reg</span><span class="p">.</span><span class="n">best_estimator_</span>
    <span class="n">prediction</span> <span class="o">=</span> <span class="n">best_est</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">original_Xtrain</span><span class="p">[</span><span class="n">test</span><span class="p">])</span>
    
    <span class="n">accuracy_lst</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">pipeline</span><span class="p">.</span><span class="n">score</span><span class="p">(</span><span class="n">original_Xtrain</span><span class="p">[</span><span class="n">test</span><span class="p">],</span> <span class="n">original_ytrain</span><span class="p">[</span><span class="n">test</span><span class="p">]))</span>
    <span class="n">precision_lst</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">precision_score</span><span class="p">(</span><span class="n">original_ytrain</span><span class="p">[</span><span class="n">test</span><span class="p">],</span> <span class="n">prediction</span><span class="p">))</span>
    <span class="n">recall_lst</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">recall_score</span><span class="p">(</span><span class="n">original_ytrain</span><span class="p">[</span><span class="n">test</span><span class="p">],</span> <span class="n">prediction</span><span class="p">))</span>
    <span class="n">f1_lst</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">f1_score</span><span class="p">(</span><span class="n">original_ytrain</span><span class="p">[</span><span class="n">test</span><span class="p">],</span> <span class="n">prediction</span><span class="p">))</span>
    <span class="n">auc_lst</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">roc_auc_score</span><span class="p">(</span><span class="n">original_ytrain</span><span class="p">[</span><span class="n">test</span><span class="p">],</span> <span class="n">prediction</span><span class="p">))</span>
    
<span class="k">print</span><span class="p">(</span><span class="s">'---'</span> <span class="o">*</span> <span class="mi">45</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">''</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">"accuracy: {}"</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">mean</span><span class="p">(</span><span class="n">accuracy_lst</span><span class="p">)))</span>
<span class="k">print</span><span class="p">(</span><span class="s">"precision: {}"</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">mean</span><span class="p">(</span><span class="n">precision_lst</span><span class="p">)))</span>
<span class="k">print</span><span class="p">(</span><span class="s">"recall: {}"</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">mean</span><span class="p">(</span><span class="n">recall_lst</span><span class="p">)))</span>
<span class="k">print</span><span class="p">(</span><span class="s">"f1: {}"</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">mean</span><span class="p">(</span><span class="n">f1_lst</span><span class="p">)))</span>
<span class="k">print</span><span class="p">(</span><span class="s">'---'</span> <span class="o">*</span> <span class="mi">45</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Length of X (train): 227846 | Length of y (train): 227846
Length of X (test): 56961 | Length of y (test): 56961
---------------------------------------------------------------------------------------------------------------------------------------

accuracy: 0.9417990800284043
precision: 0.06121501623610478
recall: 0.9162934112301201
f1: 0.113010549626039
---------------------------------------------------------------------------------------------------------------------------------------
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">labels</span> <span class="o">=</span> <span class="p">[</span><span class="s">'No Fraud'</span><span class="p">,</span> <span class="s">'Fraud'</span><span class="p">]</span>
<span class="n">smote_prediction</span> <span class="o">=</span> <span class="n">best_est</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">original_Xtest</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">original_ytest</span><span class="p">,</span> <span class="n">smote_prediction</span><span class="p">,</span> <span class="n">target_names</span><span class="o">=</span><span class="n">labels</span><span class="p">))</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>              precision    recall  f1-score   support

    No Fraud       1.00      0.99      0.99     56863
       Fraud       0.10      0.86      0.17        98

    accuracy                           0.99     56961
   macro avg       0.55      0.92      0.58     56961
weighted avg       1.00      0.99      0.99     56961
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">y_score</span> <span class="o">=</span> <span class="n">best_est</span><span class="p">.</span><span class="n">decision_function</span><span class="p">(</span><span class="n">original_Xtest</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">average_precision</span> <span class="o">=</span> <span class="n">average_precision_score</span><span class="p">(</span><span class="n">original_ytest</span><span class="p">,</span> <span class="n">y_score</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="s">'Average precision-recall score: {0:0.2f}'</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span>
      <span class="n">average_precision</span><span class="p">))</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Average precision-recall score: 0.70
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span><span class="mi">6</span><span class="p">))</span>

<span class="n">precision</span><span class="p">,</span> <span class="n">recall</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">precision_recall_curve</span><span class="p">(</span><span class="n">original_ytest</span><span class="p">,</span> <span class="n">y_score</span><span class="p">)</span>

<span class="n">plt</span><span class="p">.</span><span class="n">step</span><span class="p">(</span><span class="n">recall</span><span class="p">,</span> <span class="n">precision</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s">'r'</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span>
         <span class="n">where</span><span class="o">=</span><span class="s">'post'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">fill_between</span><span class="p">(</span><span class="n">recall</span><span class="p">,</span> <span class="n">precision</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="s">'post'</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span>
                 <span class="n">color</span><span class="o">=</span><span class="s">'#F59B00'</span><span class="p">)</span>

<span class="n">plt</span><span class="p">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">'Recall'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">'Precision'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">ylim</span><span class="p">([</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.05</span><span class="p">])</span>
<span class="n">plt</span><span class="p">.</span><span class="n">xlim</span><span class="p">([</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">])</span>
<span class="n">plt</span><span class="p">.</span><span class="n">title</span><span class="p">(</span><span class="s">'OverSampling Precision-Recall curve: </span><span class="se">\n</span><span class="s"> Average Precision-Recall Score ={0:0.2f}'</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span>
          <span class="n">average_precision</span><span class="p">),</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">16</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Text(0.5, 1.0, 'OverSampling Precision-Recall curve: \n Average Precision-Recall Score =0.70')
</code></pre></div></div>

<p><img src="/myblog/images/output_83_1.png" alt="png" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># SMOTE Technique (OverSampling) After splitting and Cross Validating
</span><span class="n">sm</span> <span class="o">=</span> <span class="n">SMOTE</span><span class="p">(</span><span class="s">'minority'</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="c1"># Xsm_train, ysm_train = sm.fit_sample(X_train, y_train)
</span>

<span class="c1"># This will be the data were we are going to 
</span><span class="n">Xsm_train</span><span class="p">,</span> <span class="n">ysm_train</span> <span class="o">=</span> <span class="n">sm</span><span class="p">.</span><span class="n">fit_resample</span><span class="p">(</span><span class="n">original_Xtrain</span><span class="p">,</span> <span class="n">original_ytrain</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># We Improve the score by 2% points approximately 
# Implement GridSearchCV and the other models.
</span>
<span class="c1"># Logistic Regression
</span><span class="n">t0</span> <span class="o">=</span> <span class="n">time</span><span class="p">.</span><span class="n">time</span><span class="p">()</span>
<span class="n">log_reg_sm</span> <span class="o">=</span> <span class="n">grid_log_reg</span><span class="p">.</span><span class="n">best_estimator_</span>
<span class="n">log_reg_sm</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">Xsm_train</span><span class="p">,</span> <span class="n">ysm_train</span><span class="p">)</span>
<span class="n">t1</span> <span class="o">=</span> <span class="n">time</span><span class="p">.</span><span class="n">time</span><span class="p">()</span>
<span class="k">print</span><span class="p">(</span><span class="s">"Fitting oversample data took :{} sec"</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">t1</span> <span class="o">-</span> <span class="n">t0</span><span class="p">))</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Fitting oversample data took :14.712885856628418 sec
</code></pre></div></div>

<h1 id="4테스팅">4.테스팅</h1>

<h2 id="41-로지스틱-회귀-분석을-사용한-검정testing">4.1 로지스틱 회귀 분석을 사용한 검정(Testing)</h2>
<p><strong>혼동행렬 Confusion Matrix</strong></p>
<ul>
  <li>Positive/Negative: 클래스(레이블)의 타입 [“No”, “Yes”]</li>
  <li>True/False: 모델의 분류가 맞으면 True, 틀리면 False</li>
</ul>

<p><br /></p>

<ul>
  <li>
    <p>True Negatives (Top-Left Square): 비사기거래 class로 올바르게 분류한 개수</p>
  </li>
  <li>
    <p>False Negatives (Top-Right Square): 사기거래 class로 틀리게 분류한 개수 (실제로는 비사기거래 클래스)</p>
  </li>
  <li>
    <p>False Positives (Bottom-Left Square): 비사기거래 class로 틀리게 분류한 개수 (실제로는 사기거래)</p>
  </li>
  <li>
    <p>True Positives (Bottom-Right Square): 사기거래 class로 올바르게 분류한 개수</p>
  </li>
</ul>

<p><strong>요약</strong></p>
<ul>
  <li>랜덤 언더 샘플링: 우리는 랜덤 언더샘플링 하위 집합에서 분류 모델의 최종 성능을 평가한다. 이 데이터는 원래 데이터 프레임의 데이터가 아니다.</li>
  <li>분류 모델: 가장 우수한 성능을 보인 모델은 로지스틱 회귀 분석 및 서포트벡터머신(SVM)이었다.</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">confusion_matrix</span>

<span class="c1"># SMOTE기법을 사용한 Logistic Regression 모델로 예측 
</span><span class="n">y_pred_log_reg</span> <span class="o">=</span> <span class="n">log_reg_sm</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="c1"># 언더샘플링으로 학습한 다른 모델들로 예측 
</span><span class="n">y_pred_knear</span> <span class="o">=</span> <span class="n">knears_neighbors</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="n">y_pred_svc</span> <span class="o">=</span> <span class="n">svc</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="n">y_pred_tree</span> <span class="o">=</span> <span class="n">tree_clf</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span> 

<span class="n">log_reg_cf</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred_log_reg</span><span class="p">)</span>
<span class="n">kneighbors_cf</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred_knear</span><span class="p">)</span>
<span class="n">svc_cf</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred_svc</span><span class="p">)</span>
<span class="n">tree_cf</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred_tree</span><span class="p">)</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">22</span><span class="p">,</span> <span class="mi">12</span><span class="p">))</span>

<span class="n">sns</span><span class="p">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">log_reg_cf</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">],</span> <span class="n">annot</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">plt</span><span class="p">.</span><span class="n">cm</span><span class="p">.</span><span class="n">copper</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">].</span><span class="n">set_title</span><span class="p">(</span><span class="s">"Logistic Regression </span><span class="se">\n</span><span class="s"> Confusion Matrix"</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">].</span><span class="n">set_xticklabels</span><span class="p">([</span><span class="s">'0(pred))'</span><span class="p">,</span> <span class="s">'1(pred)'</span><span class="p">],</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">,</span> <span class="n">rotation</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">].</span><span class="n">set_yticklabels</span><span class="p">([</span><span class="s">'0'</span><span class="p">,</span> <span class="s">'1'</span><span class="p">],</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">,</span> <span class="n">rotation</span><span class="o">=</span><span class="mi">360</span><span class="p">)</span>

<span class="n">sns</span><span class="p">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">kneighbors_cf</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">1</span><span class="p">],</span> <span class="n">annot</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">plt</span><span class="p">.</span><span class="n">cm</span><span class="p">.</span><span class="n">copper</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">1</span><span class="p">].</span><span class="n">set_title</span><span class="p">(</span><span class="s">"KNearsNeighbors </span><span class="se">\n</span><span class="s"> Confusion Matrix"</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">1</span><span class="p">].</span><span class="n">set_xticklabels</span><span class="p">([</span><span class="s">'0(pred)'</span><span class="p">,</span> <span class="s">'1(pred)'</span><span class="p">],</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">,</span> <span class="n">rotation</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">1</span><span class="p">].</span><span class="n">set_yticklabels</span><span class="p">([</span><span class="s">'0'</span><span class="p">,</span> <span class="s">'1'</span><span class="p">],</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">,</span> <span class="n">rotation</span><span class="o">=</span><span class="mi">360</span><span class="p">)</span>

<span class="n">sns</span><span class="p">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">svc_cf</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="mi">0</span><span class="p">],</span> <span class="n">annot</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">plt</span><span class="p">.</span><span class="n">cm</span><span class="p">.</span><span class="n">copper</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="mi">0</span><span class="p">].</span><span class="n">set_title</span><span class="p">(</span><span class="s">"Suppor Vector Classifier </span><span class="se">\n</span><span class="s"> Confusion Matrix"</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="mi">0</span><span class="p">].</span><span class="n">set_xticklabels</span><span class="p">([</span><span class="s">'0(pred)'</span><span class="p">,</span> <span class="s">'1(pred)'</span><span class="p">],</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">,</span> <span class="n">rotation</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="mi">0</span><span class="p">].</span><span class="n">set_yticklabels</span><span class="p">([</span><span class="s">'0'</span><span class="p">,</span> <span class="s">'1'</span><span class="p">],</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">,</span> <span class="n">rotation</span><span class="o">=</span><span class="mi">360</span><span class="p">)</span>

<span class="n">sns</span><span class="p">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">tree_cf</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="mi">1</span><span class="p">],</span> <span class="n">annot</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">plt</span><span class="p">.</span><span class="n">cm</span><span class="p">.</span><span class="n">copper</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="mi">1</span><span class="p">].</span><span class="n">set_title</span><span class="p">(</span><span class="s">"DecisionTree Classifier </span><span class="se">\n</span><span class="s"> Confusion Matrix"</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="mi">1</span><span class="p">].</span><span class="n">set_xticklabels</span><span class="p">([</span><span class="s">'0(pred)'</span><span class="p">,</span> <span class="s">'1(pred)'</span><span class="p">],</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">,</span> <span class="n">rotation</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="mi">1</span><span class="p">].</span><span class="n">set_yticklabels</span><span class="p">([</span><span class="s">'0'</span><span class="p">,</span> <span class="s">'1'</span><span class="p">],</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">,</span> <span class="n">rotation</span><span class="o">=</span><span class="mi">360</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[Text(0, 0.5, '0'), Text(0, 1.5, '1')]
</code></pre></div></div>

<p><img src="/myblog/images/output_88_1.png" alt="png" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">classification_report</span>


<span class="k">print</span><span class="p">(</span><span class="s">'Logistic Regression:'</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred_log_reg</span><span class="p">))</span>

<span class="k">print</span><span class="p">(</span><span class="s">'KNears Neighbors:'</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred_knear</span><span class="p">))</span>

<span class="k">print</span><span class="p">(</span><span class="s">'Support Vector Classifier:'</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred_svc</span><span class="p">))</span>

<span class="k">print</span><span class="p">(</span><span class="s">'Support Vector Classifier:'</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred_tree</span><span class="p">))</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Logistic Regression:
              precision    recall  f1-score   support

           0       0.97      0.97      0.97        90
           1       0.97      0.97      0.97        99

    accuracy                           0.97       189
   macro avg       0.97      0.97      0.97       189
weighted avg       0.97      0.97      0.97       189

KNears Neighbors:
              precision    recall  f1-score   support

           0       0.94      0.91      0.93        90
           1       0.92      0.95      0.94        99

    accuracy                           0.93       189
   macro avg       0.93      0.93      0.93       189
weighted avg       0.93      0.93      0.93       189

Support Vector Classifier:
              precision    recall  f1-score   support

           0       0.97      0.94      0.96        90
           1       0.95      0.97      0.96        99

    accuracy                           0.96       189
   macro avg       0.96      0.96      0.96       189
weighted avg       0.96      0.96      0.96       189

Support Vector Classifier:
              precision    recall  f1-score   support

           0       0.96      0.86      0.91        90
           1       0.88      0.97      0.92        99

    accuracy                           0.92       189
   macro avg       0.92      0.91      0.91       189
weighted avg       0.92      0.92      0.91       189
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Logistic Regression의 마지막 시험 데이터셋 점수 
</span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">accuracy_score</span> 

<span class="c1"># 언더샘플링을 사용한 Logistic Regression 모델로 에측 
</span><span class="n">y_pred</span> <span class="o">=</span> <span class="n">log_reg</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span> 
<span class="n">undersample_score</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>

<span class="c1"># SMOTE 기법을 사용한 Logistic Regression 모델(rand_log_reg)로 예측 
</span><span class="n">y_pred_sm</span> <span class="o">=</span> <span class="n">best_est</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">original_Xtest</span><span class="p">)</span>
<span class="n">oversample_score</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">original_ytest</span><span class="p">,</span> <span class="n">y_pred_sm</span><span class="p">)</span>

<span class="n">d</span> <span class="o">=</span> <span class="p">{</span><span class="s">'Technique'</span><span class="p">:</span> <span class="p">[</span><span class="s">'Random UnderSampling'</span><span class="p">,</span> <span class="s">'Oversampling(SMOTE)'</span><span class="p">],</span> <span class="s">'Score'</span><span class="p">:</span> <span class="p">[</span><span class="n">undersample_score</span><span class="p">,</span> <span class="n">oversample_score</span><span class="p">]}</span>
<span class="n">final_df</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">d</span><span class="p">)</span>

<span class="n">final_df</span>
</code></pre></div></div>

<div id="df-cf841a76-5638-41cf-a335-9c37cdd99bb2">
    <div class="colab-df-container">
      <div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Technique</th>
      <th>Score</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Random UnderSampling</td>
      <td>0.968254</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Oversampling(SMOTE)</td>
      <td>0.986096</td>
    </tr>
  </tbody>
</table>
</div>
      <button class="colab-df-convert" onclick="convertToInteractive('df-cf841a76-5638-41cf-a335-9c37cdd99bb2')" title="Convert this dataframe to an interactive table." style="display:none;">

  &lt;svg xmlns="http://www.w3.org/2000/svg" height="24px"viewBox="0 0 24 24"
       width="24px"&gt;
    <path d="M0 0h24v24H0V0z" fill="none" />
    <path d="M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z" /><path d="M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z" />
  &lt;/svg&gt;
      </button>

  <style>
    .colab-df-container {
      display:flex;
      flex-wrap:wrap;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

      <script>
        const buttonEl =
          document.querySelector('#df-cf841a76-5638-41cf-a335-9c37cdd99bb2 button.colab-df-convert');
        buttonEl.style.display =
          google.colab.kernel.accessAllowed ? 'block' : 'none';

        async function convertToInteractive(key) {
          const element = document.querySelector('#df-cf841a76-5638-41cf-a335-9c37cdd99bb2');
          const dataTable =
            await google.colab.kernel.invokeFunction('convertToInteractive',
                                                     [key], {});
          if (!dataTable) return;

          const docLinkHtml = 'Like what you see? Visit the ' +
            '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
            + ' to learn more about interactive tables.';
          element.innerHTML = '';
          dataTable['output_type'] = 'display_data';
          await google.colab.output.renderOutput(dataTable, element);
          const docLink = document.createElement('div');
          docLink.innerHTML = docLinkHtml;
          element.appendChild(docLink);
        }
      </script>
    </div>
  </div>

<h2 id="42-신경망-테스팅언더샘플링-vs-오버샘플링">4.2 신경망 테스팅(언더샘플링 vs 오버샘플링)</h2>
<p>간단한 신경망 (hidden layer 1개) 을 구현하여 언더샘플링(sub_sample)과 오버샘플링(SMOTE)에서 구현한 두 로지스틱 회귀 모델 중 어떤 것이 사기거래 탐지에 더 나은 정확도를 가지고 있는지 확인한다.</p>

<p><strong>주요 목표</strong></p>
<ul>
  <li>우리의 주요 목표는 간단한 신경망이 무작위 언더샘플 및 오버샘플 데이터프레임에서 어떻게 행동하는지 탐색하고, 사기, 비사기거래를 정확히 예측할 수 있는지 확인하는 것이다.</li>
  <li>사기에만 집중하지 않는 이유는 다음과 같다. 본인의 카드로 물건을 구입하였는데, 은행의 알고리즘이 해당 구매를 사기라고 예측하여 차단 당하는 경우가 생길 수 있다. 따라서 사기 사건 적발에만 중점을 두어서는 안 되며, 비사기 거래를 정확히 분류하는 것도 강조해야 한다.</li>
</ul>

<p><strong>요약(keras || 랜덤 언더 샘플링)</strong></p>
<ul>
  <li>데이터 집합: 이 테스트의 마지막 단계에서 우리는 원본 데이터의 테스트 데이터를 사용하여 최종 결과를 예측하기 위해 무작위 언더샘플링 서브셋과 오버샘플링 데이터셋(SMOTE) 을 사용한 모델을 학습한다.</li>
  <li>신경망 구조: 앞서 언급한 바와 같이, 이것은 하나의 input layer(노드의 수가 변수의 개수와 동일)과 편향 노드, 32개의 노드를 가진 hidden layer, 그리고 두 가지 가능한 결과 0 또는 1로 구성된 하나의 output layer로 구성된 간단한 모델이 될 것이다(사기:1, 비사기:0).</li>
  <li>기타 특성: learning rate는 0.001이 될 것이고, 우리가 사용할 최적화 도구는 Adam Optimizer이고, 이 시나리오에서 사용되는 활성화 함수는 “ReLu”이며, 최종 출력에 대해서는 사기 또는 비사기의 확률을 제공하는 sparse categorical cross entropy를 사용할 것이다(예측은 둘 중 더 높은 확률을 가진 범주로 선택할 것이다).</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">keras</span>
<span class="kn">from</span> <span class="nn">keras</span> <span class="kn">import</span> <span class="n">backend</span> <span class="k">as</span> <span class="n">K</span>
<span class="kn">from</span> <span class="nn">keras.models</span> <span class="kn">import</span> <span class="n">Sequential</span>
<span class="kn">from</span> <span class="nn">keras.layers</span> <span class="kn">import</span> <span class="n">Activation</span>
<span class="kn">from</span> <span class="nn">keras.layers.core</span> <span class="kn">import</span> <span class="n">Dense</span>
<span class="kn">from</span> <span class="nn">keras.optimizers</span> <span class="kn">import</span> <span class="n">Adam</span>
<span class="kn">from</span> <span class="nn">keras.metrics</span> <span class="kn">import</span> <span class="n">categorical_crossentropy</span>

<span class="n">n_inputs</span> <span class="o">=</span> <span class="n">X_train</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>

<span class="n">undersample_model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">([</span>
    <span class="n">Dense</span><span class="p">(</span><span class="n">n_inputs</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="n">n_inputs</span><span class="p">,</span> <span class="p">),</span> <span class="n">activation</span><span class="o">=</span><span class="s">'relu'</span><span class="p">),</span>
    <span class="n">Dense</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">'relu'</span><span class="p">),</span>
    <span class="n">Dense</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">'softmax'</span><span class="p">)</span>
<span class="p">])</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">undersample_model</span><span class="p">.</span><span class="n">summary</span><span class="p">()</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Model: "sequential"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 dense (Dense)               (None, 30)                930       
                                                                 
 dense_1 (Dense)             (None, 32)                992       
                                                                 
 dense_2 (Dense)             (None, 2)                 66        
                                                                 
=================================================================
Total params: 1,988
Trainable params: 1,988
Non-trainable params: 0
_________________________________________________________________
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">undersample_model</span><span class="p">.</span><span class="nb">compile</span><span class="p">(</span><span class="n">Adam</span><span class="p">(</span><span class="n">lr</span><span class="o">=</span><span class="mf">0.001</span><span class="p">),</span> <span class="n">loss</span><span class="o">=</span><span class="s">'sparse_categorical_crossentropy'</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s">'accuracy'</span><span class="p">])</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">undersample_model</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">validation_split</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">25</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Epoch 1/20
25/25 - 2s - loss: 0.4808 - accuracy: 0.7715 - val_loss: 0.3570 - val_accuracy: 0.8882 - 2s/epoch - 69ms/step
Epoch 2/20
25/25 - 0s - loss: 0.3328 - accuracy: 0.8775 - val_loss: 0.2672 - val_accuracy: 0.9474 - 129ms/epoch - 5ms/step
Epoch 3/20
25/25 - 0s - loss: 0.2634 - accuracy: 0.9189 - val_loss: 0.2129 - val_accuracy: 0.9539 - 130ms/epoch - 5ms/step
Epoch 4/20
25/25 - 0s - loss: 0.2122 - accuracy: 0.9288 - val_loss: 0.1904 - val_accuracy: 0.9605 - 140ms/epoch - 6ms/step
Epoch 5/20
25/25 - 0s - loss: 0.1763 - accuracy: 0.9387 - val_loss: 0.1643 - val_accuracy: 0.9605 - 116ms/epoch - 5ms/step
Epoch 6/20
25/25 - 0s - loss: 0.1507 - accuracy: 0.9454 - val_loss: 0.1595 - val_accuracy: 0.9539 - 113ms/epoch - 5ms/step
Epoch 7/20
25/25 - 0s - loss: 0.1300 - accuracy: 0.9536 - val_loss: 0.1482 - val_accuracy: 0.9474 - 107ms/epoch - 4ms/step
Epoch 8/20
25/25 - 0s - loss: 0.1185 - accuracy: 0.9553 - val_loss: 0.1535 - val_accuracy: 0.9408 - 75ms/epoch - 3ms/step
Epoch 9/20
25/25 - 0s - loss: 0.1050 - accuracy: 0.9586 - val_loss: 0.1518 - val_accuracy: 0.9474 - 79ms/epoch - 3ms/step
Epoch 10/20
25/25 - 0s - loss: 0.0981 - accuracy: 0.9586 - val_loss: 0.1558 - val_accuracy: 0.9408 - 77ms/epoch - 3ms/step
Epoch 11/20
25/25 - 0s - loss: 0.0889 - accuracy: 0.9636 - val_loss: 0.1577 - val_accuracy: 0.9408 - 73ms/epoch - 3ms/step
Epoch 12/20
25/25 - 0s - loss: 0.0824 - accuracy: 0.9652 - val_loss: 0.1593 - val_accuracy: 0.9408 - 81ms/epoch - 3ms/step
Epoch 13/20
25/25 - 0s - loss: 0.0756 - accuracy: 0.9652 - val_loss: 0.1669 - val_accuracy: 0.9408 - 97ms/epoch - 4ms/step
Epoch 14/20
25/25 - 0s - loss: 0.0699 - accuracy: 0.9719 - val_loss: 0.1735 - val_accuracy: 0.9408 - 87ms/epoch - 3ms/step
Epoch 15/20
25/25 - 0s - loss: 0.0658 - accuracy: 0.9768 - val_loss: 0.1755 - val_accuracy: 0.9408 - 105ms/epoch - 4ms/step
Epoch 16/20
25/25 - 0s - loss: 0.0619 - accuracy: 0.9801 - val_loss: 0.1788 - val_accuracy: 0.9408 - 91ms/epoch - 4ms/step
Epoch 17/20
25/25 - 0s - loss: 0.0573 - accuracy: 0.9801 - val_loss: 0.1849 - val_accuracy: 0.9408 - 83ms/epoch - 3ms/step
Epoch 18/20
25/25 - 0s - loss: 0.0536 - accuracy: 0.9834 - val_loss: 0.1914 - val_accuracy: 0.9408 - 77ms/epoch - 3ms/step
Epoch 19/20
25/25 - 0s - loss: 0.0510 - accuracy: 0.9851 - val_loss: 0.1907 - val_accuracy: 0.9408 - 84ms/epoch - 3ms/step
Epoch 20/20
25/25 - 0s - loss: 0.0474 - accuracy: 0.9884 - val_loss: 0.1984 - val_accuracy: 0.9408 - 76ms/epoch - 3ms/step





&lt;keras.callbacks.History at 0x7fd234760090&gt;
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">undersample_predictions</span> <span class="o">=</span> <span class="n">undersample_model</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">original_Xtest</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">200</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">undersample_fraud_predictions</span> <span class="o">=</span> <span class="n">undersample_predictions</span><span class="p">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">itertools</span>

<span class="c1"># 혼동 행렬을 생성한다. 
</span><span class="k">def</span> <span class="nf">plot_confusion_matrix</span><span class="p">(</span><span class="n">cm</span><span class="p">,</span> <span class="n">classes</span><span class="p">,</span>
                          <span class="n">normalize</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span>
                          <span class="n">title</span><span class="o">=</span><span class="s">'Confusion matrix'</span><span class="p">,</span>
                          <span class="n">cmap</span><span class="o">=</span><span class="n">plt</span><span class="p">.</span><span class="n">cm</span><span class="p">.</span><span class="n">Blues</span><span class="p">):</span>
    <span class="s">"""
    This function prints and plots the confusion matrix.
    Normalization can be applied by setting `normalize=True`.
    """</span>
    <span class="k">if</span> <span class="n">normalize</span><span class="p">:</span>
        <span class="n">cm</span> <span class="o">=</span> <span class="n">cm</span><span class="p">.</span><span class="n">astype</span><span class="p">(</span><span class="s">'float'</span><span class="p">)</span> <span class="o">/</span> <span class="n">cm</span><span class="p">.</span><span class="nb">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)[:,</span> <span class="n">np</span><span class="p">.</span><span class="n">newaxis</span><span class="p">]</span>
        <span class="k">print</span><span class="p">(</span><span class="s">"Normalized confusion matrix"</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">print</span><span class="p">(</span><span class="s">'Confusion matrix, without normalization'</span><span class="p">)</span>

    <span class="k">print</span><span class="p">(</span><span class="n">cm</span><span class="p">)</span>

    <span class="n">plt</span><span class="p">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">cm</span><span class="p">,</span> <span class="n">interpolation</span><span class="o">=</span><span class="s">'nearest'</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">cmap</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">title</span><span class="p">(</span><span class="n">title</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">colorbar</span><span class="p">()</span>
    <span class="n">tick_marks</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">classes</span><span class="p">))</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">xticks</span><span class="p">(</span><span class="n">tick_marks</span><span class="p">,</span> <span class="n">classes</span><span class="p">,</span> <span class="n">rotation</span><span class="o">=</span><span class="mi">45</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">yticks</span><span class="p">(</span><span class="n">tick_marks</span><span class="p">,</span> <span class="n">classes</span><span class="p">)</span>

    <span class="n">fmt</span> <span class="o">=</span> <span class="s">'.2f'</span> <span class="k">if</span> <span class="n">normalize</span> <span class="k">else</span> <span class="s">'d'</span>
    <span class="n">thresh</span> <span class="o">=</span> <span class="n">cm</span><span class="p">.</span><span class="nb">max</span><span class="p">()</span> <span class="o">/</span> <span class="mf">2.</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">j</span> <span class="ow">in</span> <span class="n">itertools</span><span class="p">.</span><span class="n">product</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">cm</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span> <span class="nb">range</span><span class="p">(</span><span class="n">cm</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])):</span>
        <span class="n">plt</span><span class="p">.</span><span class="n">text</span><span class="p">(</span><span class="n">j</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="nb">format</span><span class="p">(</span><span class="n">cm</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">],</span> <span class="n">fmt</span><span class="p">),</span>
                 <span class="n">horizontalalignment</span><span class="o">=</span><span class="s">"center"</span><span class="p">,</span>
                 <span class="n">color</span><span class="o">=</span><span class="s">"white"</span> <span class="k">if</span> <span class="n">cm</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span> <span class="o">&gt;</span> <span class="n">thresh</span> <span class="k">else</span> <span class="s">"black"</span><span class="p">)</span>

    <span class="n">plt</span><span class="p">.</span><span class="n">tight_layout</span><span class="p">()</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">'True label'</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">'Predicted label'</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">undersample_cm</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">original_ytest</span><span class="p">,</span> <span class="n">undersample_fraud_predictions</span><span class="p">)</span>
<span class="n">actual_cm</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">original_ytest</span><span class="p">,</span> <span class="n">original_ytest</span><span class="p">)</span>
<span class="n">labels</span> <span class="o">=</span> <span class="p">[</span><span class="s">'No Fraud'</span><span class="p">,</span> <span class="s">'Fraud'</span><span class="p">]</span>

<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span><span class="mi">8</span><span class="p">))</span>

<span class="n">fig</span><span class="p">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">221</span><span class="p">)</span>
<span class="n">plot_confusion_matrix</span><span class="p">(</span><span class="n">undersample_cm</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s">"Random UnderSample </span><span class="se">\n</span><span class="s"> Confusion Matrix"</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">plt</span><span class="p">.</span><span class="n">cm</span><span class="p">.</span><span class="n">Reds</span><span class="p">)</span>

<span class="n">fig</span><span class="p">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">222</span><span class="p">)</span>
<span class="n">plot_confusion_matrix</span><span class="p">(</span><span class="n">actual_cm</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s">"Confusion Matrix </span><span class="se">\n</span><span class="s"> (with 100% accuracy)"</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">plt</span><span class="p">.</span><span class="n">cm</span><span class="p">.</span><span class="n">Greens</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Confusion matrix, without normalization
[[52444  4419]
 [    3    95]]
Confusion matrix, without normalization
[[56863     0]
 [    0    98]]
</code></pre></div></div>

<p><img src="/myblog/images/output_98_1.png" alt="png" /></p>

<table>
  <tbody>
    <tr>
      <td>**Keras</td>
      <td> </td>
      <td>OverSampling (SMOTE)**</td>
    </tr>
  </tbody>
</table>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">n_inputs</span> <span class="o">=</span> <span class="n">Xsm_train</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>

<span class="n">oversample_model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">([</span>
    <span class="n">Dense</span><span class="p">(</span><span class="n">n_inputs</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="n">n_inputs</span><span class="p">,</span> <span class="p">),</span> <span class="n">activation</span><span class="o">=</span><span class="s">'relu'</span><span class="p">),</span>
    <span class="n">Dense</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">'relu'</span><span class="p">),</span>
    <span class="n">Dense</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">'softmax'</span><span class="p">)</span>
<span class="p">])</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">oversample_model</span><span class="p">.</span><span class="nb">compile</span><span class="p">(</span><span class="n">Adam</span><span class="p">(</span><span class="n">lr</span><span class="o">=</span><span class="mf">0.001</span><span class="p">),</span> <span class="n">loss</span><span class="o">=</span><span class="s">'sparse_categorical_crossentropy'</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s">'accuracy'</span><span class="p">])</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">oversample_model</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">Xsm_train</span><span class="p">,</span> <span class="n">ysm_train</span><span class="p">,</span> <span class="n">validation_split</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">300</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Epoch 1/20
1214/1214 - 6s - loss: 0.0780 - accuracy: 0.9727 - val_loss: 0.0387 - val_accuracy: 0.9837 - 6s/epoch - 5ms/step
Epoch 2/20
1214/1214 - 4s - loss: 0.0191 - accuracy: 0.9944 - val_loss: 0.0111 - val_accuracy: 0.9989 - 4s/epoch - 3ms/step
Epoch 3/20
1214/1214 - 3s - loss: 0.0110 - accuracy: 0.9976 - val_loss: 0.0057 - val_accuracy: 0.9996 - 3s/epoch - 2ms/step
Epoch 4/20
1214/1214 - 3s - loss: 0.0074 - accuracy: 0.9984 - val_loss: 0.0031 - val_accuracy: 0.9999 - 3s/epoch - 2ms/step
Epoch 5/20
1214/1214 - 3s - loss: 0.0056 - accuracy: 0.9989 - val_loss: 0.0064 - val_accuracy: 0.9999 - 3s/epoch - 2ms/step
Epoch 6/20
1214/1214 - 3s - loss: 0.0044 - accuracy: 0.9991 - val_loss: 0.0052 - val_accuracy: 0.9999 - 3s/epoch - 2ms/step
Epoch 7/20
1214/1214 - 4s - loss: 0.0040 - accuracy: 0.9992 - val_loss: 0.0120 - val_accuracy: 0.9997 - 4s/epoch - 3ms/step
Epoch 8/20
1214/1214 - 4s - loss: 0.0031 - accuracy: 0.9994 - val_loss: 0.0030 - val_accuracy: 0.9998 - 4s/epoch - 3ms/step
Epoch 9/20
1214/1214 - 3s - loss: 0.0030 - accuracy: 0.9995 - val_loss: 0.0014 - val_accuracy: 1.0000 - 3s/epoch - 2ms/step
Epoch 10/20
1214/1214 - 3s - loss: 0.0024 - accuracy: 0.9995 - val_loss: 0.0014 - val_accuracy: 1.0000 - 3s/epoch - 2ms/step
Epoch 11/20
1214/1214 - 3s - loss: 0.0021 - accuracy: 0.9996 - val_loss: 0.0014 - val_accuracy: 1.0000 - 3s/epoch - 2ms/step
Epoch 12/20
1214/1214 - 3s - loss: 0.0020 - accuracy: 0.9996 - val_loss: 7.3873e-04 - val_accuracy: 1.0000 - 3s/epoch - 2ms/step
Epoch 13/20
1214/1214 - 3s - loss: 0.0017 - accuracy: 0.9997 - val_loss: 0.0012 - val_accuracy: 1.0000 - 3s/epoch - 2ms/step
Epoch 14/20
1214/1214 - 3s - loss: 0.0016 - accuracy: 0.9997 - val_loss: 6.8631e-04 - val_accuracy: 0.9999 - 3s/epoch - 2ms/step
Epoch 15/20
1214/1214 - 3s - loss: 0.0015 - accuracy: 0.9997 - val_loss: 8.9564e-04 - val_accuracy: 1.0000 - 3s/epoch - 2ms/step
Epoch 16/20
1214/1214 - 3s - loss: 0.0013 - accuracy: 0.9997 - val_loss: 0.0025 - val_accuracy: 0.9997 - 3s/epoch - 2ms/step
Epoch 17/20
1214/1214 - 3s - loss: 0.0016 - accuracy: 0.9997 - val_loss: 4.8170e-04 - val_accuracy: 1.0000 - 3s/epoch - 2ms/step
Epoch 18/20
1214/1214 - 3s - loss: 0.0011 - accuracy: 0.9997 - val_loss: 0.0022 - val_accuracy: 0.9994 - 3s/epoch - 2ms/step
Epoch 19/20
1214/1214 - 3s - loss: 9.5084e-04 - accuracy: 0.9998 - val_loss: 3.5280e-04 - val_accuracy: 1.0000 - 3s/epoch - 2ms/step
Epoch 20/20
1214/1214 - 3s - loss: 0.0013 - accuracy: 0.9997 - val_loss: 5.2458e-04 - val_accuracy: 1.0000 - 3s/epoch - 2ms/step





&lt;keras.callbacks.History at 0x7fd234020750&gt;
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">oversample_predictions</span> <span class="o">=</span> <span class="n">oversample_model</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">original_Xtest</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">200</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">oversample_fraud_predictions</span> <span class="o">=</span> <span class="n">oversample_predictions</span><span class="p">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">oversample_smote</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">original_ytest</span><span class="p">,</span> <span class="n">oversample_fraud_predictions</span><span class="p">)</span>
<span class="n">actual_cm</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">original_ytest</span><span class="p">,</span> <span class="n">original_ytest</span><span class="p">)</span>
<span class="n">labels</span> <span class="o">=</span> <span class="p">[</span><span class="s">'No Fraud'</span><span class="p">,</span> <span class="s">'Fraud'</span><span class="p">]</span>

<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span><span class="mi">8</span><span class="p">))</span>

<span class="n">fig</span><span class="p">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">221</span><span class="p">)</span>
<span class="n">plot_confusion_matrix</span><span class="p">(</span><span class="n">oversample_smote</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s">"OverSample (SMOTE) </span><span class="se">\n</span><span class="s"> Confusion Matrix"</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">plt</span><span class="p">.</span><span class="n">cm</span><span class="p">.</span><span class="n">Oranges</span><span class="p">)</span>

<span class="n">fig</span><span class="p">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">222</span><span class="p">)</span>
<span class="n">plot_confusion_matrix</span><span class="p">(</span><span class="n">actual_cm</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s">"Confusion Matrix </span><span class="se">\n</span><span class="s"> (with 100% accuracy)"</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">plt</span><span class="p">.</span><span class="n">cm</span><span class="p">.</span><span class="n">Greens</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Confusion matrix, without normalization
[[56838    25]
 [   27    71]]
Confusion matrix, without normalization
[[56863     0]
 [    0    98]]
</code></pre></div></div>

<p><img src="/myblog/images/output_104_1.png" alt="png" /></p>

<p><strong>결론</strong></p>
<ul>
  <li>불균형 데이터 세트에 SMOTE를 구현하면 레이블의 불균형을 해결할 수 있었다.</li>
  <li>그럼에도 불구하고, 여전히 때때로 오버샘플 데이터셋의 신경망이 언더샘플 데이터셋을 사용하는 모델보다 덜 정확한 부정 거래를 예측한다는 것을 말해야 한다.</li>
  <li>그러나 이상치 제거는 오버샘플 데이터셋이 아닌 랜덤 언더샘플 데이터셋에서만 구현되었다는 것을 기억해야한다.</li>
  <li>또한, 우리의 언더샘플 데이터셋에서 우리 모델은 비사기 거래를 사기 거래로 잘못 분류하는 사례가 많았다. 많은 비사기 거래 대해 올바르게 감지할 수 없다고 판단할 수 있다.</li>
  <li>우리의 모델이 어떠한 거래를 사기 거래로 분류했다는 이유로 정기 구매를 하던 사람들이 그들의 카드를 차단당했다고 상상해 보자. 이것은 금융 기관에 큰 불이익이 될 것이며, 고객 불만과 고객 불만이 늘어날 것이다.</li>
  <li>이 분석의 다음 단계는 오버샘플 데이터 세트에서 이상치를 제거하고 테스트 세트의 정확도가 향상되는지 확인하는 것이다.</li>
</ul>

<p><strong>참고:</strong> 마지막으로 두 가지 유형의 데이터 프레임에 데이터 셔플을 구현했기 때문에 예측과 정확성이 변경될 수 있다. 가장 중요한 것은 우리의 모델이 사기 및 사기 거래를 올바르게 분류할 수 있는지 확인하는 것이다.</p>

      <div class="c-article__footer u-clearfix">
        <div class="c-article__tag">
          
        </div>
        <div class="c-article__share">
          <a href="https://twitter.com/intent/tweet?text=Transcription%20%7C%7C%20[Kaggle]%20Credit%20card%20Fraud%20Detection&url=https://ag-su.github.io/2022/10/19/credit-card-fraud-detection/" title="Share
          on Twitter" rel="nofollow" target="_blank"><div data-icon='ei-sc-twitter' data-size='s'></div></a>
          <a href="https://facebook.com/sharer.php?u=https://ag-su.github.io/2022/10/19/credit-card-fraud-detection/" title="Share on Facebook" rel="nofollow" target="_blank"><div data-icon='ei-sc-facebook' data-size='s'></div></a>
          <a href="https://plus.google.com/share?url=https://ag-su.github.io/2022/10/19/credit-card-fraud-detection/" title="Share on Google+" rel="nofollow" target="_blank"><div data-icon='ei-sc-google-plus' data-size='s'></div></a>
        </div>
      </div>
      <div class="c-newsletter">
  <div class="c-newsletter__header">
    <h4 class="c-newsletter__title">Newsletter</h4>
    <div class="c-newsletter__subtitle">Subscribe to this blog and receive notifications of new posts by email.</div>
  </div>
  <form class="c-newsletter-form validate" action="#" method="POST" id="mc-embedded-subscribe-form" name="mc-embedded-subscribe-form" target="_blank" novalidate>
    <div class="c-newsletter-form__group">
      <label class="u-screen-reader-text" for="mce-EMAIL">Email address</label>
      <input class="c-newsletter__email required email" id="mce-EMAIL" type="email" name="EMAIL" placeholder="Your email address" autocomplete="on">
      <input class="c-newsletter__button" id="mc-embedded-subscribe" type="submit" name="subscribe" value="Subscribe">
    </div>
  </form>
</div> <!-- /.c-newsletter -->
      <div class="c-recent-post">
        <h4 class="c-recent__title">You might also enjoy</h4>
        <div class="c-recent__box">
        
        
          <div class="c-recent__item">
            <a class="c-recent__image" href="/2022/11/29/html-css-02/" style="background-image: url( /myblog/images/221129_1.png)"></a>
            <div class="c-recent__footer">
              <h4><a href="/2022/11/29/html-css-02/">Elice || 02. HTML, CSS 기초</a></h4>
              <div class="c-recent__date">
                <time datetime="2022-11-29T00:00:00+09:00">November 29, 2022</time>
              </div>
            </div>
          </div>
        
        
        
          <div class="c-recent__item">
            <a class="c-recent__image" href="/2022/11/28/html-01/" style="background-image: url( /myblog/images/221128/221128_1.png)"></a>
            <div class="c-recent__footer">
              <h4><a href="/2022/11/28/html-01/">Elice || 01. HTML 기초</a></h4>
              <div class="c-recent__date">
                <time datetime="2022-11-28T00:00:00+09:00">November 28, 2022</time>
              </div>
            </div>
          </div>
        
        
        
          <div class="c-recent__item">
            <a class="c-recent__image" href="/2022/07/25/cluster-filtering/" style="background-image: url( /myblog/images/08.thumbnail.png)"></a>
            <div class="c-recent__footer">
              <h4><a href="/2022/07/25/cluster-filtering/">Stock Research || 3.3. 클러스터링 분석을 통한 주가 상승추세 패턴 검출</a></h4>
              <div class="c-recent__date">
                <time datetime="2022-07-25T00:00:00+09:00">July 25, 2022</time>
              </div>
            </div>
          </div>
        
        
        
          <div class="c-recent__item">
            <a class="c-recent__image" href="/2022/07/22/tsne/" style="background-image: url( /myblog/images/07.thumbnail.png)"></a>
            <div class="c-recent__footer">
              <h4><a href="/2022/07/22/tsne/">Stock Research || 3.2. t-SNE를 사용한 주가데이터 2차원 시각화</a></h4>
              <div class="c-recent__date">
                <time datetime="2022-07-22T00:00:00+09:00">July 22, 2022</time>
              </div>
            </div>
          </div>
        
        
        </div>
      </div> <!-- /.c-recent-post -->
      
        <div class="c-comments">
  <div id="disqus_thread" class="article-comments"></div>
  <script>
    (function () {
      var d = document, s = d.createElement('script');
      s.src = '//mr-brown.disqus.com/embed.js';
      s.setAttribute('data-timestamp', +new Date());
      (d.head || d.body).appendChild(s);
    })();
  </script>
  <noscript>Please enable JavaScript to view the
    <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a>
  </noscript>
</div> <!-- /.c-comments -->
      
    </div> <!-- /.c-wrap-content -->
  </div> <!-- /.c-article__content -->
</article> <!-- /.c-article-page -->

</main> <!-- /.c-content -->
  </div> <!-- /.o-wrapper -->
  <div class="c-top" data-icon='ei-chevron-up' data-size='s' title="Scroll To Top"></div> <!-- /.c-top -->
  <script src="/myblog/js/jquery-3.3.1.min.js"></script>
<script src="/myblog/js/evil-icons.min.js"></script>
<script src="/myblog/js/jquery.fitvids.js"></script>
<script src="/myblog/js/simple-jekyll-search.min.js"></script>
<script src="/myblog/js/main.js"></script>
<!-- /javascripts -->
</body>
</html>